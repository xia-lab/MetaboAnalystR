[
    {
        "Question": "Can I analyze GC-MS spectra?",
        "Answer": "The Spectra Processing modules in MetaboAnalyst were mainly developed and optimized for high resolution LC-MS and MS/MS (DDA and SWATH-DIA) spectra processing. It has not been evaluated for GC-MS spectra processing. We recommend MZmine 3 (https://mzmine.github.io/download.html). You can also try GC-Autofit (https://gc-autofit.wishartlab.com)."
    },
    {
        "Question": "How to use and interpret PCA visualization?",
        "Answer": "The interactive PCA visualization summarizes all the data into the first 2 or 3 principal components (PCs). Each data point in the Scores Plot represents a sample. Samples that are close together are more similar to each other. The colors of these data points are based on the factor labels. Users can change the colors according to any of the two factor labels.\nEach data point in the Loadings Plot represents a feature. When Scores plot and Loadings plot are viewed from the identical perspective, the direction of separation on the scores plot can be explained by the corresponding features on the same directions - i.e. features on the two ends of the direction contribute more to the pattern of separation."
    },
    {
        "Question": "When should I use MetaboAnalyst?",
        "Answer": "The purpose of MetaboAnalyst is to provide a free, user-friendly, and easily accessible tool for analyzing data arising from high-throughput metabolomics data. It is designed to address two common types of problems: 1) to identify features that are significantly different between two conditions (biomarker discovery); 2) to use the metabolomic data to predict the conditions under study (classification). In addition, MetaboAnalyst also provide tools for compound identification and pathway mapping for annotating significant features. Note, MetaboAnalyst is designed for analyzing a large number of samples, very few samples (less than 10) will cause some functions to work improperly.\n\nSince 2024, the XiaLab team also provides Omics Data Science trainings, pro tools and enterprise solution to help sustain the communities & platforms. More details can be found: https://www.xialab.ca/translation.xhtml"
    },
    {
        "Question": "What is difference between R2 (R-square) and Q2 (Q-square) in (O)PLS-DA?",
        "Answer": "Both are used to measure the model fit and consistency. In particular, R2 is a measure of model fit to the original data, and Q2 provides an internal measure of consistency between the original and cross-validation predicted data. \n\nBoth are **optimistic** measures without proper reference standards. It is generally inadequate to use only R2 and Q2 to assess model reliability.   Double cross validation (using external cross validation) and permutation are highly recommended when sample size permits.  For more details, read [this excellent paper](https://pubmed.ncbi.nlm.nih.gov/22593721/)"
    },
    {
        "Question": "How to interpret the permutation result (PLS-DA)?",
        "Answer": "It is well known that when there are too many variables and a small sample size, many supervised classification algorithms tend to **overfit** the data. That is, even there is no actual difference between the groups, the program will still be able to discriminate them by picking some features that are \"different\" between these two group by pure chance! Of course, the classifier will be useless for new data since the pattern it detected is not real (not significant).\n\nThe purpose of a permutation test is to answer the question - \"what is the performance if the groups are formed randomly\". The program uses the same data set with its class labels reassigned randomly. It then builds a new classifer, its performance is then evaluated. The process will repeat many times to estimate the distribution of the performance measure (which not necessarily follows a normal distribution). By comparing the performance using the original label and the performance based on the randomly labeled data, one can see if the former is significantly different from the latter. For PLS-DA, the performance is measured using **prediction accuracy** or **group separation distance** using the \"B/W ratio\" (as suggested by [Bijlsma et al.](http://www.ncbi.nlm.nih.gov/pubmed/16408941)). The further away to the right of the distribution formed by randomly permuted data, the more significant the discrimination. The p-value is calculated as the proportion of the times that class separation based on randomly labeled sample is at least as good as the one based on the original data (one-sided p value)."
    },
    {
        "Question": "What are the differences between degree and betweenness centrality?",
        "Answer": "In a graph network, the degree of a node is the number of connections it has to other nodes , Degree centrality is defined as the number of links occurred upon a node. Nodes with higher node degree act as hubs in a network. For directed graph, there are two types of degree: in-degree for links come from other nodes, and out-degree for links initiated from the current node. Metabolic network is directed graph. Here we only consider the out-degree for node importance measure. It is assumed that nodes in upstream will have regulatory roles for the downstream nodes, not vice versa. In a graph network, the betweenness centrality measures number of shortest paths going through the node. Therefore, it take into consideration of global network structure, not only immediate neighbour of the current node. For example, nodes that occur between two dense clusters will have a high betweenness centrality, even its degree centrality is not high. Since metabolic network is directed, we use relative betweenness centrality for metabolite importance measure. In the illustration on the right, the nodes colored in **blue** have high betweenness centrality."
    },
    {
        "Question": "What's the difference between VIP and coefficient - based feature selection (PLS-DA)?",
        "Answer": "There are two variable importance measures in PLS-DA:\n\n* <b>Variable Importance in Projection (VIP)<\/b>, which is a weighted sum of squares of the PLS loadings taking into account the amount of explained Y-variation, in each dimension (i.e. VIP scores are calculated for each component).\n\n* <b>Weighted sum of absolute regression coefficients<\/b>. The weights are a function of the reduction of the sums of squares across the number of PLS components. Please note, for multiple-group (more than two) analysis, the same number of predictors will be built for each group. Therefore, the coefficient of each feature will be different depending on which group you want to predict. The average of the feature coefficients are used as the overall coefficient-based importance."
    },
    {
        "Question": "What is DSPC network and how does it work?",
        "Answer": "DSPC stands for debiased sparse partial correlation. It is an algorithm designed to build partial correlation networks based on a graphical LASSO model using a data-driven approach without mapping to any known metabolites interaction databases ([Jankova, 2015](https://projecteuclid.org/euclid.ejs/1433195859)). \n\nDSPC can distinguish between direct and indirect associations and provide insights into the structure of dependencies between metabolites. The main assumption of this DSPC method is that the amount of real metabolites interactions is far smaller than the sample size (i.e., the real partial correlation network among the metabolites is sparse). \n\nUnder this assumption, DSPC reconstructs a network and calculates partial correlation coefficients and p-values for each pair of metabolic features. Thus, DSPC makes it possible to uncover connectivity patterns among a large number of metabolic features by using fewer samples ([Basu et al., 2017](https://doi.org/10.1093/bioinformatics/btx012)). The inferred results can be visualized as weighted networks, where nodes represent the metabolic features, and the edges depict the correlations among them.\n\n![Screen Shot 2022-06-12 at 8.50.38 PM|589x499](upload://zJuOlcOV2duDSzYTNPeAExrpoTT.png)\n\n\nAn example DSPC network generated by MetaboAnalyst. Users can manually interact with the networks and manually re-arrange nodes and edges"
    },
    {
        "Question": "What is Q2 value (PLS-DA) and why my Q2 value is negative?",
        "Answer": "Q2 is an estimate of the predictive ability of the model, and is calculated via cross-validation (CV). In each CV, the predicted data are compared with the original data, and the sum of squared errors is calculated. The prediction error is then summed over all samples (Predicted Residual Sum of Squares or PRESS). For convenience, the PRESS is divided by the initial sum of squares and subtracted from 1 to resemble the scale of the R2. \n\nGood predictions will have low PRESS or high Q2. It is possible to have **negative Q2** (due to the subtraction step) , which means that your model is not at all predictive or is overfitted. For more details, refer to an excellent paper by ([Szymańska, et al](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3337399/)). \n\nAn example plot from PLS-DA CV result is shown below (note, Q2 becomes negative when top 4 or 5 components are used, indicating overfitting occurs)\n![pls_cv_0_dpi150|504x360](upload://x17Ego7CvOdvCbJ2MBny28d95yg.png)"
    },
    {
        "Question": "What is pathway topological analysis (Pathway Impact)?",
        "Answer": "The structure of biological pathways represents our knowledge about the complex relationships between molecules (activation, inhibition, reaction, etc.). However, neither over-representation analysis or pathway enrichment analysis take the pathway structure into consideration when determining which pathways are more likely to be involved in the conditions under study. \n\nIt is obvious that changes in the key positions of a network will trigger more severe impact on the pathway than changes on marginal or relatively isolated positions. As illustrated by the figure below - the red node (more connections) and blue node (bottleneck) are considered more important that terminal nodes. The program uses two well-established node centrality measures to estimate node importance -  degree centrality which emphasize red nodes, and betweenness centrality which emphasizes blue node. See detailed discussion on [degree and betweenness centrality](https://omicsforum.ca/t/what-are-the-difference-between-degree-centrality-and-betweenness-centrality/163). \n\nPlease note, for comparison among different pathways, the node importance values calculated from centrality measures are further normalized by the sum of the importance of the pathway. Therefore, the total/maximum importance of each pathway is 1; the importance measure of each metabolite node is actually the percentage w.r.t the total pathway importance, and the pathway impact is the cumulative percentage from the matched metabolite nodes."
    },
    {
        "Question": "How to detect and deal with outlier in MetaboAnalyst?",
        "Answer": "Unsupervised approaches: potential outliers can be identified from PCA or heatmaps through visualization. The scores plot can be used to identify sample outliers, while the loadings plot can be used to identify feature outliers. The potential outlier will distinguish itself as the one located far away from the major clusters formed by the remaining.\n\nSupervised approaches: Random Forest method (Statistical Analysis module) also provide information and visualization on potential outliers; the Prob. View (multivariate biomarker analysis) is also very useful for outlier detection (samples already predicted in the wrong group)\n\nTo deal with outliers, the first is to check if those samples / features are measured properly. In many cases, outliers are the result of operational errors during analytical process. If those values cannot be corrected, they should be removed from analysis. MetaboAnalyst provides **DataEditor** to enable easy removal of sample/feature outliers. Please note, you may need to re-normalize the data after outlier removal."
    },
    {
        "Question": "How to convert raw spectra data into centroid mode?",
        "Answer": "Using Proteowizard is highly recommended. \n\n1. If you are using **GUI of Proteowizard**, please set the parameters according to the screenshot below. \n![image|690x480](upload://rIBIYqLMW4XKuRnvGB39RMZ56fQ.png)\n**Note**: the \"peak Picking\" parameter has to be set as the first filtering condition to ensure the centroiding works properly.\n\n2. If you are using **docker version of Proteowizard**, please use the following command to run the conversion:\n```\ndocker run -it --rm -e WINEDEBUG=-all -v /YOUR/ABSOLUTE/DATA/DIR/:/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert *.raw --mzML --filter \"peakPicking true 1-\" --filter \"zeroSamples removeExtra\" --filter \"msLevel 1\" --64 --zlib\n```\n **Note**: Please modify \"*.raw\" based the extension of your vendor MS files."
    },
    {
        "Question": "The calculation of VIP score in PLS-DA module",
        "Answer": "Dear MetaboAnalyst team,\n\nThe VIP scores calculated by the MetaboAnalyst PLS-DA module differ from those obtained using other calculation modules, such as scikit-learn in Python and mixOmics in R. While the scores from scikit-learn and mixOmics are consistent, the MetaboAnalyst scores highlight influential features more prominently. Are your calculations different from those of other modules?\n\nHere is a test dataset with 6 samples and 8 features, and the feature XXXX is manually added with a dramatic difference between classes T and C.\n\nsample\tT1\tT2\tT3\tC1\tC2\tC3\nclass\tT\tT\tT\tC\tC\tC\nALBU\t8.27E9\t1.08E10\t4.63E9\t1.45E10\t2.37E10\t9.37E9\nTRFE\t9.11E8\t8.53E8\t5.34E8\t5.57E8\t1.51E9\t1.06E9\nCO3\t1.53E8\t1.05E8\t1.18E8\t2.95E8\t2.75E8\t8.10E7\nIGG1\t2.08E9\t1.06E9\t2.22E9\t2.61E8\t2.66E8\t1.87E9\nA2MG\t4.63E7\t3.45E7\t1.54E8\t1.03E8\t1.50E8\t1.18E8\nXXXX\t1.00E5\t8.00E4\t9.00E4\t8.00E8\t1.00E9\t9.00E7\nFIBB\t2.81E8\t1.89E8\t2.30E8\t2.48E8\t2.93E8\t3.60E8\nCO4B\t1.77E5\t3.97E5\t1.36E5\t2.19E6\t1.15E6\t3.51E5\n\nThe VIP scores calculated by scikit-learn/mixOmics and MetaboAnalyst are shown below. MetaboAnalyst highlights the feature XXXX with a VIP score of 2.74, while scikit-learn/mixOmics assigns a score of only 1.24. Additionally, the order of the features is different. \n\tsklearn/mixOmics\tMetaboAnalyst\nXXXX\t1.242534\t2.7451\nCO4B\t1.120459\t0.38577\nALBU\t1.086513\t0.10519\nFIBB\t1.029846\t0.041263\nIGG1\t1.001192\t0.53945\nCO3\t0.907570\t0.013373\nA2MG\t0.808401\t0.099583\nTRFE\t0.692824\t0.040896\n\n# Scikit-learn (v1.3.2) python script\nimport numpy as np\nfrom sklearn.cross_decomposition import PLSRegression, PLSCanonical\nimport pandas as pd\n\ndef vip_PLSR(model: PLSRegression):\n    t = model.x_scores_\n    w = model.x_rotations_\n    q = model.y_loadings_\n    p, h = w.shape\n    vips = np.zeros((p,))\n    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)\n    total_s = np.sum(s)\n    for i in range(p):\n        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n        vips[i] = np.sqrt(p*(s.T @ weight)/total_s)\n    return vips\n\ndef main():\n    df = pd.read_csv('demodata.tsv', sep='\\t', index_col=0)\n    X = np.array(df.T)\n    Y = np.array([0,0,0,1,1,1])\n\n    n_comp = 1\n    pls = PLSRegression(n_components=n_comp)\n    pls.fit(X, Y)\n    \n    vips = vip_PLSR(pls)\n    coef = pls.coef_[0]\n\n    for i, feature in enumerate(df.index):\n        print(feature, vips[i], coef[i])\n\nif __name__ == '__main__':\n    main()\n\n---------------------------\n# MixOmics R script:\nif (!require(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\nBiocManager::install(\"mixOmics\")\nlibrary(\"mixOmics\")\n\ndata <- read.table(\"demodata.tsv\", header = TRUE, row.names = 1, sep = \"\\t\")\nfeatures <- rownames(data)\n\ndata <- as.data.frame(sapply(data, function(x) as.numeric(as.character(x))))\nX <- t(data.matrix(data))\n\nresponse_variable <- factor(c(rep(0, 3), rep(1, 3)))\nY = as.numeric(response_variable)\n\nplsda_model <- mixOmics::plsda(X, Y, ncomp = 5)\n\nvip_scores <- vip(plsda_model)\nrownames(vip_scores) <- features\nprint(vip_scores)"
    },
    {
        "Question": "What are empirical compounds and how they are calculated (mummichog)?",
        "Answer": "In mummichog version 2.0, empirical compounds are intermediaries between m/z features and compounds. An empirical compound is a computational unit for a tentative metabolite, since the experimental measurement may not separate compounds of identical mass (isomers).  The steps for how they are formed are as follows:\n\n1. As  in version 1, all m/z features are matched to potential compounds considering different adducts. Then, per compound, all matching m/z features are split into Empirical Compounds based on whether they match within an expected retention time window. The retention time window (in seconds) is calculated as the maximum retention time * 0.02. This results in the initial Empirical Compounds list.\n\n2. Empirical Compounds are merged if they have the same m/z, matched form/ion, and retention time. This results in the merged Empirical Compounds list.\n\n3. Finally, if primary ions are enforced, only Empirical Compounds containing at least 1 primary ion are kept. Primary ions considered are 'M+H[1+]', 'M+Na[1+]', 'M-H2O+H[1+]', 'M-H[-]', 'M-2H[2-]', 'M-H2O-H[-]', 'M+H [1+]', 'M+Na [1+]', 'M-H2O+H [1+]', 'M-H [1-]', 'M-2H [2-]', and 'M-H2O-H [1-]'. This results in the final Empirical Compounds list.\n\n4. Next, pathway libraries are converted from \"Compound\" space to \"Empirical Compound\" space. This is done by converting all compounds in each pathway to all Empirical Compound matches. Then the mummichog/GSEA algorithms work as before to calculate pathway enrichment."
    },
    {
        "Question": "How does random forest work?",
        "Answer": "RF is a powerful non-parametric classification method and can be used for both classification and important variable selection (Breiman, 2001). RF uses an ensemble of classification trees, each of which is grown by random feature selection using bootstrap sampling from the original sample set. Class prediction is based on the majority vote of the ensemble. By default, 500 trees are used to build the RF classifier. During tree construction, about one-third of the instances are left out of the bootstrap sampling process. These “left-out” data are then used as test data to obtain an unbiased estimate of the classification error, known as the ‘out-of-bag’ (OOB) error. \n\nRF is a robust (not susceptible to overfitting issue) and versatile (regression, classification, dealing with missing values and interactions) method. The main drawback associated with RF is the model & results are hard to interpret. \n\nFor a more detailed description about  random forests, click [here](http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)."
    },
    {
        "Question": "How are the MS/MS matching score and similarity score calculated?",
        "Answer": "MetaboAnalyst supports MS/MS pattern matching-based compound identification since version 6.0, introducing two key scores for result evaluation: the matching score and the similarity score. The following provides an explanation of these two scores:\n\n1. **Similarity Score:** MetaboAnalyst employs the [dot-product](https://www.nature.com/articles/nmeth.3393#Sec2) or [spectral entropy](https://pubmed.ncbi.nlm.nih.gov/34857935/) method for its calculation. This score exclusively reflects the pattern similarity between the query spectrum and the reference spectrum.\n\n2. **Matching Score:** This score offers a comprehensive evaluation, taking into account MS/MS pattern similarity, m/z deviation (calculated by assessing differences between experimental and reference values based on the Gaussian distribution of m/z error), and the ratio of matched fragments.\n\nIn summary, while the similarity score concentrates solely on MS/MS pattern comparison, the matching score provides a more thorough evaluation of results by considering additional factors such as m/z deviation and the ratio of matched fragments."
    },
    {
        "Question": "How to deal with technical replicates?",
        "Answer": "This depends on the biological questions under investigation.  Within the context of MetabAnalyst support. Here are three steps:\n\n<b>1. Using technical replicates for QC<\/b>\nIf the purpose of technical replications is to see if there is systematic variance introduced by sample handling or instrumentation, the clustering programs such as PCA or hierarchical clustering  (in the <b>Statistics<\/b> module) can be used to investigate whether the same technical replicates tend to group together.\n\n<b>2. Merging technical replicates for analysis<\/b>\nTechnical replicates are not independent biological samples, and should not be used directly for statistical analysis, which will inflate the statistical power. After checking the clustering pattern of these technical replicates, a common practice is to merge all sample replications. Please download upload the data to MetaboAnalyst (under <b>Other Utilities => Merging Technical Replicates<\/b>). Users have the options to merge technical replicates based on \n<ul>\n<li>Mean<\/li>\n<li>Median<\/li>\n<li>Sum<\/li>\n<li>Minimum<\/li>\n<li>Maximum<\/li>\n<li>1st Quarter<\/li>\n<li>3rd Quarter<\/li>\n<\/ul>\n\n<b>3. Uploading to compatible modules<\/b>\nThe merged dataset is now suitable for statistical analysis and functional analysis in MetaboAnalyst which generally assumes all samples are independent biological replicates."
    },
    {
        "Question": "How does the mummichog algorithm work?",
        "Answer": "The mummichog algorithm ([Li et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3701697/)) has been developed to to perform pathway activity analysis directly from LC-MS untargeted metabolomics peak list data. \n\nThe algorithm is based on the assumption that even the mapping of LC-MS peaks to compounds is often inaccurate, it is still possible to identify meaningful functional changes by performing enrichment analysis based on those “fuzzy” annotations, as long as the annotation errors are random. Note, improving the annotation (i.e. high resolution MS, or better algorithm such as [NetID](https://pubmed.ncbi.nlm.nih.gov/34711973/)) will directly improve the pathway analysis results. \n\nBriefly, users provide a list of m/z features and their associated p-values (i.e., obtained from t-tests / ANOVA), together with a significance threshold (i.e. p-value 0.05) \n\nThree lists are then drawn from this initial list,\n\n1. **Lsig**, which is the list containing only all significant m/z features (determined by the user selected p-value cutoff);\n\n2. **Lref**, which is the list of all m/z features;\n\n3. **Lperm**, which is a list of randomly drawn m/z features from Lref, but the same length as Lsig.\n\nThe next steps are as follows:\n\n1. A list of randomly drawn m/z features are drawn from Lref to create Lperm. The m/z features are then mapped to potential metabolites, considering different adducts, protons, etc.\n\n2. The list of potential compounds are then mapped to the user’s selected library of pathways, and a p-value is calculated per pathway.\n\n3. Steps 1 and 2 are repeated many times to compute the null distribution of p-values (modeled as a gamma distribution).\n\n4. The Lsig is mapped to potential metabolites for pathway enrichment analysis, and the resulting p-values (Fisher’s or Hypergeometric, and EASE scores) per pathway for the Lsig compounds are then adjusted for the null-distribution."
    },
    {
        "Question": "What's the difference between \"fold change\" and \"paired fold change\" analyses?",
        "Answer": "The goal of fold change (FC) analysis is to compare the absolute value of change between two group means. Since column-wise normalization (i.e. log transformation and various scaling) will significantly change absolute values, FC calculation are using data **before** column-wise normalization was applied (i.e. at original scale). The significant features are those features whose FCs are beyond the given FC threshold (either up or down). \n* For unpaired analysis, FCs are calculated as the ratios between two **group means (M1/M2)** . \n* For paired analysis, FCs are calculated by computing the ratio between paired samples, (i.e. one FC per pair), and then compute their means (i.e. **pair means** )."
    },
    {
        "Question": "What are the different marks in the boxplot based on?",
        "Answer": "In a boxplot, the bottom and top of the box are always the 25th and 75th percentile (the lower and upper quartiles, or Q1 and Q3, respectively), and the band near the middle of the box is always the 50th percentile (the median or Q2). The upper whisker is located at the smaller of the maximum x value and Q3 + 1.5 * IQR (Interquantile Range), whereas the lower whisker is located at the larger of the smallest x value and Q1 - 1.5 * IQR.\n\n![Glucose_0_summary_dpi150|540x351](upload://iYbEgOaewZuEzgpJRtzZUhUMoxs.png)\n\nExample boxplots generated by MetaboAnalyst showing the concentration distributions of Glucose across four different groups (left: originial concentration; right: normalized concentration)"
    },
    {
        "Question": "How to select (and understand) important variables in ASCA?",
        "Answer": "ASCA identifies the **major trends associated with each experimental factor and their interactions**. The next step is to identify variables that are closely follow those detected trends as well as those that clearly diverge from the trends. The first ones would represent those variables that most co-coordinately respond in the experimental context; The second ones would be potential outliers. The variable selection strategy is based on the approach described by [Nueda, M.J. et al](http://dx.doi.org/10.1093/bioinformatics/btm251).\n\nAn example figure is shown below. Important variables are put into two categories: \n* 'well-modeled' refers to those that change co-coordinately to the major profile(s) depicted in the trajectory plots of the factor;\n* 'outliers' refer to those with relevant changes but different from the major profile(s)\n\nThese variables are selected based on the **Leverage** (a measure of the importance of a variable's contribution to the fitted ASCA-model - higher Leverage means more importance) and **SPE** (or squared prediction error, an evaluation of the goodness of fit of the model to a particular variable - higher SPE means less fit ). The Leverage value (between 0 and 1) is used to select 'well-modeled' variables; while SPE is used to select 'outliers'. SPE is controlled by alpha (between 0 and 1). Smaller Alpha will lead to higher SPE, which will select variables that diverge more significantly from the general trend.\n\n![](upload://fxR1Wm49UjXbelb7J53pF0pPzUw.png)"
    },
    {
        "Question": "How to understand the result from permutation tests (Biomarker Analysis)?",
        "Answer": "Permutation tests are performed to see if the biomarker models obtained based on the original data are any better than null models (i.e. models created using shuffled group labels). \n\nThe procedures are described below:\n  1. Re-assign the group labels randomly to each sample;\n  2. Perform model building and evaluation through cross validation (CV) based on shuffled labels. The performance is then recorded.\n     * **Specific for Biomarker Module:** perform balanced sub-sampling cross validation. Within each CV, perform feature ranking and select the top x features to build a classifier using the 2/3 training data, which is then tested on the 1/3 hold-out data. Note, the procedure is repeated only 3 times to save computational time.\n  3. Repeat steps 1 and 2 many times (say, 1000 times) \n  4. Compare the performance using the original phenotype label and the permuted labels. With sufficient sample size, the performance measures based on the permuted data will usually form a normal distribution. If the performance score of the original data lies outside the distribution, then the result is significant. An empirical p value is also usually given. For instance, in 1000 permutation tests, if none of the results are better than the original one, the p value will be reported as p < 0.001.\n\nWe have noticed that, when the data does not contain good signals (i.e. AUROC is < 0.65), or when the sample size is small with outliers, the permutation results could be unstable (switching between significant and insignificant in different runs). This is unavoidable due to the random subsampling nature of the procedure.\n\nRelated post [permutation tests in PLS-DA](https://omicsforum.ca/t/how-to-interpret-the-permutation-result-pls-da/96)"
    },
    {
        "Question": "How does MetaboAnalyst deal with zero and negative values in log or square root transformation?",
        "Answer": "The compound concentration or peak intensity values are assumed to be non-negative values. However, metabolomics data may contain some negative values due to various reasons (such as baseline subtraction). In order to deal with these values, MetaboAnalyst adopts a simple variation used in generalized logarithm (glog). It has many desirable features (for details, see [Durbin BP. et al](http://www.ncbi.nlm.nih.gov/pubmed/12169537)). Its formula is shown below:  \n\n![](upload://aloYTaceNETpIa7SVOeOM0IEZTA.png)  \n\nIn MetaboAnalyst, the log base is 10, and **a** is one tenth of the minimal positive values in the data."
    },
    {
        "Question": "How to use enrichment factor or ratio to assess the importance of a pathway in functional analysis?",
        "Answer": "The enrichment factor of a pathway is the ratio between the number of significant pathway hits from the user uploaded data and the expected number of hits within that pathway. It is computed based on the table below using the formula: Enrichment Factor = Hits (Sig.) / Expected. Ideally, we would expect pathways involved should have both signficant p values and high enrichment factors (top right coner)."
    },
    {
        "Question": "Should data normalization be performed first and then batch correction?",
        "Answer": "In general, batch correction methods have their own normalization, scaling, etc to detect and correct batch effect. You can consider **batch correction is an enhanced version of normalization**. If you perform filtering & normalization first, you could **dilute** the batch signals, which could interfere with batch correction."
    },
    {
        "Question": "What is EBAM (statistical analysis)?",
        "Answer": "Empirical Bayesian Analysis of Microarray (EBAM) is an empirical Bayes method originally developed for analysis of microarray gene expression data. Both the prior and posterior distributions are estimated from the data. \n\nA gene is considered to be differentially expressed if its calculated posterior is larger than or equal to **delta** and no other genes with a more extreme test score that are not called differentially expressed. The suggested fudge factor **a0** is chosen that leads to the largest number of differentially expressed genes. More information about empirical Bayes can be found ([here](http://en.wikipedia.org/wiki/Empirical_Bayes_method)), and detailed description on the EBAM algorithm be found from the original paper by [Efron, B., Tibshirani, R. et al](http://genomics.princeton.edu/storeylab/papers/ETST_JASA_2001.pdf)."
    },
    {
        "Question": "How to decided between PCA, PLS-DA, sPLSDA, OrthoPLSDA?",
        "Answer": "PCA is an unsupervised analysis, while others are supervised based on the class information. There is no absolute definition which one is the best because they are constructed with different algorithm and shows different performance for different data. You can read these papers \n1. Westerhuis, J.A., van Velzen, E.J.J., Hoefsloot, H.C.J. *et al.* Multivariate paired data analysis: multilevel PLSDA versus OPLSDA. *Metabolomics* **6** , 119–128 (2010). https://doi.org/10.1007/s11306-009-0185-z; \n2. Lê Cao, KA., Boitard, S. & Besse, P. Sparse PLS discriminant analysis: biologically relevant feature selection and graphical displays for multiclass problems. *BMC Bioinformatics* **12** , 253 (2011). https://doi.org/10.1186/1471-2105-12-253) \n\nto learn more on the difference between them."
    },
    {
        "Question": "How to understand the ROC curve?",
        "Answer": "The **ROC curve** is a fundamental tool for performance evaluation of diagnostic tests. It provides a complete and easily visualized report on sensitivity-specificity trade-off across different cut-off values . As shown in the Fig. below, in a ROC curve the true positive rate (*Sensitivity*) is plotted against the false positive rate (1-Specificity) for different cut-off points of a given parameter. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold. \n\n![Screen Shot 2022-06-12 at 4.42.58 PM|690x422, 75%](upload://bce8lewWApoVqfTDeGJueyZrpsK.jpeg)\nA test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100% sensitivity, 100% specificity). Therefore the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test. The closer the ROC curve to the diagonal line, the poorer the diagnostic power of the test. \n\nThe area under the ROC curve **(AUC)** is a measure of how well a parameter can distinguish between two diagnostic groups (diseased/normal)."
    },
    {
        "Question": "How to interpret results from multivariate empirical Bayes (MEBA) time-series analysis?",
        "Answer": "The MEBA approach is designed to compare the short-course time-course profiles with regard to different experimental conditions. It is based on the **timecourse** method described by [YC Tai. et al](http://dx.doi.org/10.1214/009053606000000759). \n\nThe result is a list of variables that are ranked by their difference in temporal profiles across different biological conditions. The **Hotelling-T2** is used to rank the variables with different temporal profiles between two biological conditions under study; And the **MB-statistics** is used for more than two biological conditions. Higher statistical value indicates the time-course profiles are more different across the biological conditions under study. An example output from the top ranked feature is given below\n![3.06411042_7_dpi150|432x389, 75%](upload://jnamlNH5CthsdT8MpkKwOVUB0q0.png)\n\nPlease note, MEBA allows prioritize the features based on their temporal profiles. No associated p-values are computed in the implementation."
    },
    {
        "Question": "What are the differences among centWave, MatchedFilter and Massifquant (peak picking)?",
        "Answer": "MetaboAnalyst currently supports three algorithms for LC-MS peak picking. They are used for different scenarios, as illustrated in details below,\n\n* **centWave**, an algorithm which was created by [Ralf T. et al, 2008](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-504) has been extensively used for peak picking on high-resolution mass spectrometry data. It is using a continuous wavelet transformation model and optionally Gauss-fitting in the chromatographic domain. This algorithm is being used by default, and usually shows statisfying performance.\n\n* **Matched Filter** is mainly designed for low-resolution MS. This algorithm is being depreciated.\n\n* **Massifquant** is an Kalman filter-based algorithm, developed by [Christopher J. et al, in 2014](https://academic.oup.com/bioinformatics/article/30/18/2636/2475626). This algorithm is quite sensitive towards the ms signals, and should be used for MS data with low intensity or the MS data was acquired with too many MS2 scans simultaneously."
    },
    {
        "Question": "What are the main differences between cross validation and permutation tests",
        "Answer": "Both cross validation and permutations are used for performance evaluation of classification models. \n\n1) Permutation tests provide a binary (qualitative) answer to \"**is my model better than null (random) models?**\". Here the baseline reference are null models - often generated using the **same algorithm** trained on permuted group labels, or permuted data. \n\n2) Cross validations provide quantitative answer to \"**how good is my model compared to other models?**\". The baseline reference are other models - often generated using the **different algorithms** trained on the same data. \n\nAs you can see, permutation tests is the starting point to see if the model is of any use (i.e. capture any true signals). If so, you can further use CV to find out whether it is better than other models"
    },
    {
        "Question": "What's the difference between quantitative enrichment analysis and pathway analysis?",
        "Answer": "The enrichment analysis algorithm is the same (global test for table input and ORA for list input) in the \"Enrichment Analysis\" and \"Pathway Analysis\" modules. The difference between them is that for pathway analysis, we do a pathway topology analysis *in addition* to the global test. \n\nA metabolite set is just a group of metabolites, for example a list of metabolites associated with cancer. A pathway includes both a list of metabolites, and information about how the metabolites interact, for example metabolite A and metabolite B react to form metabolite C in the \"Glycolysis\" pathway. We can only do enrichment analysis for metabolite sets; we can do both enrichment (analyze metabolites) and topology analysis (analyze metabolites and their connections) for pathways"
    },
    {
        "Question": "What is MSEA?",
        "Answer": "MESA or Metabolite Set Enrichment Analysis refers to a concept to identify biologically meaningful patterns in metabolite concentration changes for quantitative metabolomic studies. This name is inspired by the well-established Gene Set Enrichment Analysis (GSEA). \n\nIn MetaboAnalyst, there are three statistical methods available for MSEA (as shown in the Fig below) \n![Screen Shot 2022-06-12 at 3.05.07 PM|690x406, 100%](upload://i6yIiXtQA7QGo4ZbLrNGUC9mBNl.png)\n\n\nThe above approaches are available in the <b>Enrichment Analysis<\/b> module for targeted metabolomics data. MetaboAnalyst also offers similar approaches for untargeted metabolomics data. Please refer to the  <b>Functional Analysis<\/b> module if you have LC-MS peak list data"
    },
    {
        "Question": "How to deal with missing values?",
        "Answer": "Depending on the type of experiments, there may be significant amount of missing values present in the data set. \n\nMissing values should be presented either as **empty values** or **NA without quotes** in order to be accepted by MetaboAnalyst. Any other symbol will be treated as string character and could cause errors during data processing. MetaboAnalyst offers a variety of methods to deal with missing values. \n\n* Remove features with a high-level (adjustable) missing values\n* Fill the remaining NAs using detection limits (LoD) – 1/5 of the lowest positive values reported for individual features\n* Users can also specify other methods, such as *replace by mean/median, Probabilistic PCA (PPCA), Bayesian PCA (BPCA) method, or Singular Value Decomposition (SVD) method* to impute the missing values ([Stacklies W. et al](http://www.ncbi.nlm.nih.gov/pubmed/17344241))."
    },
    {
        "Question": "MetaboAnalyst for proteomics data",
        "Answer": "Proteomics is interesting because the raw data and initial processing steps are more similar to metabolomics, but the downstream analysis relies on the same annotations and functional libraries as transcriptomics. \n\nWe developed [ExpressAnalyst](https://www.expressanalyst.ca/ExpressAnalyst/uploads/TableUploadView.xhtml) for transcriptomics analysis, but support common proteomics ID types as well:\n\n![image|690x379](upload://8OvZ4lExjiglAsoe86TlOcxjmp0.png)\n\nThe proteomics pipeline in ExpressAnalyst has only basic processing/normalization functionality. You can use these, or you can perform the initial processing/normalization in MetaboAnalyst, then upload the processed matrix to ExpressAnalyst for statistical and functional analysis."
    },
    {
        "Question": "How can I install MetaboAnalystR?",
        "Answer": "MetaboAnalystR is an open-source R package, which is designed for users to reproduce the analysis results from their local R environment, or to perform automated, large-scale data analysis which is not easy using the web interface. Please follow this [link](https://dev.metaboanalyst.ca/docs/RTutorial.xhtml#1.2%20Installation) to install it.\n\nThe recommended R version is 4.0 or later. At least 4GB RAM and 2GB hard drive space is required to ensure the functionality."
    },
    {
        "Question": "What is ASCA?",
        "Answer": "ASCA or ANOVA-simultaneous component analysis, is a multivariate extension of univariate ANOVA approach. This implementation in MetaboAnalyst currently supports ASCA model for two factors with one interaction effect. The algorithm first partitions the overall data variance (**X**) into individual variances induced by each factor (**A** and **B**), as well as by the interactions (**AB**). The formula is shown below with (**E**) indicates the residuals.\n\n**X = A + B + AB + E**\n\nThe SCA part applies PCA to **A**, **B**, **AB** to summarize major variations in each partition. Users need to specify the number of components used for each model. The maximum allowed number of components of each factor must be less than the corresponding levels of the factor. For example, if the phenotype factor contains two levels (control and disease). Only the top component will be extracted. In most cases, users should focus on top one or two components.\n\nPlease refer to the [original paper](https://doi.org/10.1093/bioinformatics/bti476) for more technical details on ASCA."
    },
    {
        "Question": "Which p-value combination method to use in functional meta-analysis?",
        "Answer": "The meta-analysis of MS peaks framework supports various methods for p-value combination, including **Fisher's**, **Edgington's**, **Stouffer's**, **Vote Count**, **Minimum P-value** or **Maximum P-value**. The choice of statistical method depends on the goal of the meta-analysis as well as the data structure itself. Briefly, Fisher's statistic, the Minimum P-value or Maximum P-value are traditionally used methods for combining p-values.\n\n* **Fisher's method** is known to be more sensitive than other methods to very small (or very large) p-values which can result in a high false positive rate. For instance, a single very small p-value can lead to a significant combined p-value. \"Fisher’s method employs the log product of individual P-values and thus, a single P-value of zero in one individual case will result in a combined P-value of zero regardless of the other P-values.\" - (PMID: 26471455). This method should be followed when the data follows a Chi-squared distribution (positive values). It is also not recommended for use for meta-analysis with([ >5 datasets](http://bioinfo.genyo.es/imageo/)).\n\n* **Minimum P-value** should be used to answer the question which metabolites are changed across at least one study? In this case, the minimum p-value among all studies is taken as the combined p-value.\n\n* **Maximum P-value** is the most restrictive method and should be used to answer the question of which genes are consistently changed across all studies? In this case, the maximum p-value among all studies is taken as the combined p-value.\n\n* **Stouffer's method** attributes different weights to the p-values when combining them in a meta-analysis. This method should be applied when the data follows a Gaussian curve. This method is not as sensitive as Fisher's to very small or very large p-values.\n\n* **Edgington's method** uses the sum of the p-values and unlike Fisher's method, is not sensitive to small p-values. It best fits circular data and it has been noted that using this method, a single large p-value can overwhelm small p-values (PMID: 11788962).\n\n* **Vote counting** method is limited to answering the question is there any evidence of an effect? One issue with this method is that it compares the number of \"yes\" studies to the number of \"no\" studies. The \"yes\" and \"no\" if often an arbitrary statistical cutoff that can bias the outcome. Secondly, it does not apply any weights to the studies, therefore the effect of a study with 1000 samples has the same weight as a study with 10 samples. While this method is simple to implement and interpret, this method should only be used when standard meta-analysis methods cannot be used. Meanwhile, at least 5 datasets are required for vote counting to reach the statistical confidence. To read more on vote counting [here](http://assets.press.princeton.edu/chapters/s10045.pdf)."
    },
    {
        "Question": "What is over-representation analysis (ORA)?",
        "Answer": "MetaboAnalyst offers three types of enrichment analysis for targeted metabolomics, including\n\n* Over Representation Analysis (ORA, input: significant compound names)\n* Single Sample Profiling (SSP, input: a complete sample profile)\n* Quantitative Enrichment Analysis (QEA, input: a complete concentration table)\n\nORA aims to test if a particular group of compounds is represented more than expected by chance within the user uploaded compound list. In the context of pathway analysis, we are testing if compounds involved in a particular pathway is enriched compared by random hits. The most common methods for such analysis is <b>Fishers' exact test<\/b> and <b> hypergeometric test<\/b> . Please note, the over-representation analysis only consider the <b> count<\/b>  (i.e. the total number of compounds that match a particular pathway) and does not consider the magnitude of their concentration changes (not quantitative). So compound that are changed more significant will be treated the same as compounds that are less significant."
    },
    {
        "Question": "How is the optimal threshold determined in ROC analysis of individual biomarkers?",
        "Answer": "MtaboAnalyst currently offers two different approaches to determine the optimal threshold based on ROC curves.\n\n* In Youden approach, the optimal cut-off is the threshold that <b>maximizes the distance to the diagonal line<\/b>. The optimality criterion is *max(sensitivity + specificity)* .\n\n* The other approach is to find the point <b>closest to the top-left corner<\/b> of the ROC plot with perfect sensitivity or specificity. The optimality criterion is *min((1-sensitivity)^2 + (1-specificity)^2)*\n\nPlease note,\n1. There might be more than one threshold identified using the above criteria;\n2. The optimal cutoff is only calculated for the ROC curve using the actual data points, not the smoothed one."
    },
    {
        "Question": "What are the main differences between mummichog and GSEA in MetaboAnalyst?",
        "Answer": "The *mummichog* algorithm implements an over-representation analysis (ORA) method to evaluate pathway-level enrichment based on significant peaks. Users need to specify a pre-defined cutoff based on either t-statistics or fold changes. We note that using top 10% peaks (default in MetaboAnalyst) generally works very well.\n\nAn alternative approach is the Gene Set Enrichment Analysis ([*GSEA*](https://www.ncbi.nlm.nih.gov/pubmed/16199517)) method, which is widely used to test for enriched functions from ranked gene lists. Unlike ORA, GSEA considers the overall ranks of features without using a significance cutoff, and is claimed to be able to detect subtle and consistent changes which could be missed from using ORA-based methods."
    },
    {
        "Question": "How to understand the different p-values computed from mummichog",
        "Answer": "There are actually **4 types** of p values computed for mummichog (available in the download table), including\n   * One-tailed Fisher Exact Test (very sensitive but based on Gaussian hypergeometric probability distribution)\n   * EASE score (a conservative adjustment to the Fisher exact probability that weights significance in favor of themes supported by more hits)\n   * Empirical p values based on non-parametric permutations - p value is the percentage of hits received better than original;\n   * Gamma p values - using Gamma distribution to model permutation results \n\nIn general, Fisher p is very sensitive but could give a lot false positives, while empirical p is robust but does not have a lot power (non-parametric), while gamma p tries to combine both worlds .... \n\n2) The web interface shows the **original p values** as described above (not adjusted). The multi-testing adjusted p values are available in the download table. There are two considerations:\n   * One main interest is to identify the most \"perturbed\" pathways for hypothesis generation. We notice that in many times the adjust p values are all 1, making them uninformative for this purpose.\n   * Many peaks or compounds are shared among different pathways (i.e. pathways are correlated), violating the assumption of independent tests. \n\nWe suggest not to rely solely on statistical procedures, but combine this evidence with more biological context."
    },
    {
        "Question": "How to perform meta-analysis of untargeted metabolomics data (LC-MS peak tables)?",
        "Answer": "With the increased use of metabolomics and global efforts towards science transparency, the amount of publicly available metabolomics data deposited in public repositories such as [**Metabolomics Workbench**, ](https://www.metabolomicsworkbench.org/)[**MetaboLights** ](https://www.ebi.ac.uk/metabolights/)and [**OmicsDI**](https://www.omicsdi.org/) has grown tremendously. \n\nIntegrating datasets collected on the same or similar conditions from independent studies, a process called meta-analysis, can help address the reproducibility issues due to low sample size, sample heterogeneity, and identify robust patterns and biomarkers. MetaboAnalyst implements two relatively straightforward approaches to support meta-analysis in the <b>Functional Meta-analysis<\/b> module.\n\n<b>Feature level meta-analysis<\/b>\nThis is a low-level integration where features are merged directly for enrichment analysis. Such practice is usually restricted to the data from the same studies. For instance, in LC-HRMS metabolomics, a common practice is to collect spectra from the same samples using both positive and negative ion modes. The resulting peaks can be directly merged for downstream pathway activity analysis. \n\n<b>Pathway level meta-analysis<\/b>\nIn this case, LC-MS peak tables should be collected under similar experimental and analytical conditions (i.e. similar metabolome coverage). Each datasets are subject to pathway enrichment analysis, and the resulting pathway-level p values are then integrated based on fixed or random effects models. [More details are here](https://omicsforum.ca/t/what-is-pathway-level-meta-analysis-of-ms-peaks/359)."
    },
    {
        "Question": "\"Total\" and \"Hits\" Interpretation For Enrichment Analysis",
        "Answer": "Given that the Enrichment Ratio for Quantitative Enrichment Analysis is determined based on the ratio of the observed Q statistic to the expected Q statistic, how should I interpret the values under \"Total\" and \"Hits\" for each Metabolite Set and how do those numbers work into the Dot Plot/ Bar Graph?"
    },
    {
        "Question": "How to use Logistic Regression for biomarker analysis?",
        "Answer": "A nice introduction to logistic regression (LR) can be [found here](https://christophm.github.io/interpretable-ml-book/logistic.html). To prepare the input data, it is recommended to use the number (0 or 1) instead of string labels. Usually, 1 is used for the case and 0 is for the control.\n\nLR usually works best for a dozen or so variables and cannot be directly used for omics scale data with 100s ~1000s of variables. It is often necessary to perform feature selection first. MetaboAnalyst offers this support in its Biomarker Module under the \"**ROC curve based model evaluation (Tester)**\" track, since this track allows users to manually select a subset of features/samples for ROC analysis using the statistics table (feature ranking) in the Model Builder step \n\nYou can then perform logistic regression analysis with the selected variables and explore the modelling results. The results  include plots and tables are generated using MCCV (100-fold cross-validation). In addition, it produces the result with 10-fold cross-validation in the \"LR model (10-fold CV)\" tab. An example output is shown below:\n\n![Screen Shot 2022-07-27 at 5.42.33 PM|507x500](upload://rzKYPI7HnVcCkZNJZlJhY2QAaxp.png)\n**Cautions!**  if you have selected features based on their overall ranks (AUC, T-statistic or fold changes), there will be an increase risk of overfitting - they may be the best biomarkers for this particular data, but not the case for new samples!"
    },
    {
        "Question": "How to interpret the important features identified in multivariate ROC exploratory analysis?",
        "Answer": "In MetaboAnalyst Biomarker Analysis module, important features are selected from the training data at each cross-validation (CV) run. \n\nThe orders and identities of the list could be (hopefully slight) different each time. This is because in each CV, important features will be selected based on the different samples!\n\nThere are two forms in reporting the most important features. The Frequency of being selected shows the **stability of the rank** of the importance for a given biomarker, and the Average importance measure provides a **quantitative measure** of the importance for a given biomarker. The first measure is more robust and not sensitive to outliers. In most cases, these two approaches should produce similar results. \n\nAn example output (based on frequency) is shown below\n\n![cls_imp_0_dpi150|500x500](upload://hVBy3nyaT8lcM9Qgzn7kJYmMsGg.png)"
    },
    {
        "Question": "How does the weighted z-test work in joint-pathway analysis?",
        "Answer": "When we perform the joint-analysis, if a pathway contains many more genes than metabolites, the significance of the genes will overwhelm the significance of the metabolites. In addition, the transcriptomics usually report far more differential expression genes than metabolomics, in this case, the integration result is always dominated by transcriptomics datasets.\n\nThe weight strategy for different ‘universes’ (“transcriptomics data universe” and “metabolomics data universe”) are performed with a weighted z-test. The weighted z-test proposed by [Dmitri V. Zaykin. et. al](https://doi.org/10.1111/j.1420-9101.2011.02297.x) is designed for the weighted integration of different datasets of very different sizes. A figure below is provided to illustrate the mechanism of this weighted integration of different Omics-data in MetaboAnalyst.\n\n![joint_image_faq|531x282](upload://5eAnD4SENGK8KrbODVKV0GAHzEA.png)\n\nSpecifically, we assign different weights based on the proportion of genes and metabolites in the specific ‘omics universes’ to balance the influence from the different sizes of the ‘omics inputs upon the integrated pathway results. The adjusted P value is estimated with a weighted Z-test below.\n\n![z_test_formula|187x101](upload://HYRAjuWaXN5rDlbMp6FRQ1bahu.png)\n\nIn the equation, w<sub>i<\/sub> is the weights of the P values of genes or compounds within individual omics \"universe\" or \"pathway space\", respectively; Z<sub>i<\/sub> is the Z score of the corresponding P values of single omics data, usually, Z<sub>i<\/sub> = Φ−1(1 −P<sub>i<\/sub>); P<sub>i<\/sub> is the P values from the enrichment analysis above; Φ denote the standard normal cumulative distribution function."
    },
    {
        "Question": "Why aren't all uploaded compound names/IDs matched even they are in HMDB or KEGG?",
        "Answer": "For compound annotation, the pathway or enrichment analysis modules are designed for compounds with annotations in our libraries (metabolite sets or metabolic pathways). If you are looking for general purpose compound annotation, please use “Metabolite ID Conversion” under “Utilities”. \nFor enrichment analysis, please note that all compounds covered by our pathways or metabolite sets will be annotated. In general, pathway/enrichment analysis is less dependent on whether the compounds exist in current HMDB. It depends more on whether the compounds are included in our pathway libraries. There are a lot of compounds in KEGG / HMDB, but only a small portion of them have functional annotations. If they are not recognized (even they have valid HMDB IDs), there will be little or no effect on the results. This is because by default, the background “universe” is defined by those compounds in pathways or metabolite sets during analysis. It is possible to define and upload your own reference metabolome when selecting pathway libraries."
    },
    {
        "Question": "PLS-DA Q2 and R2 change with changing labels",
        "Answer": "This is expected. PLS-DA R2/Q2 are quantitative measures and are more sensitive to model variations (such as random partitions during CV) compared to Accuracy. If you have a small sample size, such variations can be quite noticeable.  You can repeat analysis (keep clicking Update button) to see if the result is stable or not. In general, if your group orders are meaningful, you can use regression based measures (R2/Q2), but you should keep group orders intact \n \n2) If your group orders are not meaningful, you can ignore order but should use classification based measure (Accuracy) - maybe we should hide or disable R2/Q2 measures once users uncheck the option\n\nOverall, multi-group classification with small sample sizes is \"more of an art\", and is not very useful especially for PLS-DA (it could overfit even for ~100 samples in two group classification!). Discussing performance in this scenario does not carry too much meaning. Random forests is more robust in this case"
    },
    {
        "Question": "How does SAM work?",
        "Answer": "SAM or Significance Analysis of Microarray is a robust method initially designed for identification of statistically significant genes in data from gene expression microarray. In particular, it provides researchers with a non-parametric score for each gene based on repeated measurements.\n\nSAM use moderated t-tests to computes a statistic dj for each gene j, which measures the strength of the relationship between gene expression (X) and a response variable (Y). This analysis uses non-parametric statistics by repeated permutations of the data to determine if the expression of any gene is significant related to the response. The procedure accounts for correlations in genes and avoids normal assumptions about the distribution of individual genes. A typical SAM output is shown below. More detailed description about about SAM history, features, and instructions can be found [here](http://www-stat.stanford.edu/~tibs/SAM/).\n\n![sam_imp_0_dpi150|500x500](upload://q1SeOuxdHud1P2fYVNlYbcGeNUS.png)\n\n[A recent study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7909396) has shown that SAM may lose certain power in general statistical tests to correctly detect significant features which violate homogeneity."
    },
    {
        "Question": "How to interpret the diagnostic plots in power analysis module?",
        "Answer": "The power analysis  in MetaboAnalyst is based on R package SSPA [described here](https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-10-439)\n\nThe calculation is based on two assumptions:\n1. The test statistics follow a normal or near normal (Students' t) distribution.\n2. The effect is indeed present in the data;\n\nThe diagnostic plot is to help assess whether these two assumptions are reasonably met. In particular, the panels on the left (**normality assessment**) shows the distribution of the test statistics (t-stat) as a histogram (*top panel*) and as QQ plot (*bottom panel*); the panels on the right shows the distribution of the raw p values as histogram (*top panel*) and the bottom panel shows the sorted p values against their ranks (**effect assessment**). We expect a large proportion of p values will be close to zero (indicating strong effect) - **i.e.** the histogram should be left-shifted and the bottom graph should shift to top left corner.\n\n![power_diag|500x500](upload://gKiLjRN9rzVlIZTs1UgSVObOkK2.png)"
    },
    {
        "Question": "Can I use the selected features for classification?",
        "Answer": "Cautions must be taken for the practice. \n* It is OK to use the features selected based on the background biological knowledge (domain knowledge);\n* It is OK to use features selected based on overall data characteristics (such as abundance level, variance, etc)\n\nIn MetaboAnalyst, one can use non-specific filtering (i.e. not using the class labels) to select features. We recently introduced the **Data filter** function under the **Data Process** category. Users can use this function to remove low quality features using a variety of criteria. Additionally, users can also try to remove sample outliers if exists using the **Data editor**. These are safe procedures that can potentially improve the classification performance.\n\n* It is **not proper** to use the features selected based on the whole dataset using some supervised methods (methods that utilize the class label information such as **t-tests**, **PLS-DA** or other supervised classification methods). Feature selection using supervised methods will introduce selection bias and result in a very optimistic performance based on cross-validation due to \"information leak\".  Please refer to paper by [Ambroise C and McLachlan GJ](http://www.ncbi.nlm.nih.gov/pubmed/11983868) for a more detailed discussion. In order to obtain an objective performance evaluation, one should **include the feature selection procedure in the cross validation**. Alternatively, one can evaluate the classifier using independent dataset not used in the feature selections.\n\nIn MetaboAnalyst <b>Biomarker Analysis<\/b> module - Multivariate Exploratory ROC curve analysis path, we have implemented the  feature selection procedure embedded within the cross validation, which is further enhanced with repeated, balanced subsampling to deal with relatively small sample size as well as unbalanced class issues, common in clinical biomarker analysis"
    },
    {
        "Question": "What is quantitative enrichment analysis (QEA)?",
        "Answer": "MetaboAnalyst offers three types of enrichment analysis for targeted metabolomics, including\n<ul>\n<li>\nOver Representation Analysis (ORA,  input: significant compound names)\n<\/li>\n<li>\nSingle Sample Profiling (SSP, input: a complete sample profile)\n<\/li>\n<li>\nQuantitative Enrichment Analysis (QEA, input: a complete concentration table)\n<\/li>\n<\/ul>\n\nQEA is based on compound concentration table. It is often claimed to be more sensitive than ORA and has the potential to discover \"subtle but consistent\" changes among compounds within the same biological pathway.\n\nMany algorithms have been developed in the last decade for this type of enrichment analysis, the most famous being the [Gene Set Enrichment Analysis](http://www.broadinstitute.org/gsea/). Many new and improved methods have since been implemented. When users upload concentration tables,  [GlobalTest](http://bioinformatics.oxfordjournals.org/cgi/content/abstract/23/8/980)  is used for functional enrichment analysis;  for pathway enrichment analysis, users can choose between [GlobalTest](http://bioinformatics.oxfordjournals.org/cgi/content/abstract/23/8/980) or [GlobalAncova](http://bioinformatics.oxfordjournals.org/cgi/content/short/24/1/78). \n\nSome important features about these two methods include that they support binary, multi-group, as well as continuous phenotypes, and p values can be approximated efficiently based on the asymptotic distribution without using permutations, which is critical for developing web applications."
    },
    {
        "Question": "Why are the gamma adjusted p-values NaN? (mummichog)",
        "Answer": "Users may sometimes find that their gamma adjusted p-values are **NaN**. This is because the permutation p-values could not be modelled properly by Gamma distribution. The issue arises usually because the number of permutations with significance is too close to zero."
    },
    {
        "Question": "Weird looking volcano plots when using the limma covariate function",
        "Answer": "In case this works for anyone else, I think that the weird shape in the volcano plots was being caused by the autoscaling function. I'm guessing it has something to do with the fact that it divides each variable by its standard deviation. I removed the autoscaling step, keeping only the log10 transformation and the plots are looking nice now, and the highlighted metabolites remain essentially the same, although the FC are more discrete now."
    },
    {
        "Question": "How to interpret the metabolome view (pathway analysis)?",
        "Answer": "It contains all the matched pathways (the metabolome) arranged by p values (from pathway enrichment analysis) on Y-axis, and pathway impact values (from pathway topology analysis) on X-axis. \n\nThe node color is based on its p value and the node radius is determined based on their [pathway impact](https://omicsforum.ca/t/what-is-pathway-topological-analysis-pathway-impact/162) values. The pathway name is shown as mouse-over tooltip. Click the corresponding node when the tool-tip shows will launch the corresponding [pathway view](https://omicsforum.ca/t/how-to-interpret-the-pathway-view/166)\n\n![](upload://wSFx9wLpov1qNpcxZ3qy0C3bWWv.png)"
    },
    {
        "Question": "What is the main biomarker analysis approach in MetaboAnalyst?",
        "Answer": "A unique requirement in biomarker is the balance of sensitivity (true positive rate) and specificity (true negative rate). Ideally, we would like a test to be of high sensitivity (i.e. able to detect all positive cases) and high specificity (i.e. able to correctly tell negative cases). However, this is often hard to attain and we need to decide a cutoff point with some trade-off.\n\nReceiver Operating Characteristic (ROC) curve analysis is the method of choice for performance evaluation in biomarker analysis. It can be easily used for visualizing results obtained from different cutoff values for either univariate or multivariate approaches. Note in multivariate context, the cutoff points do not have very intuitive interpretations as in the classical univariate ROC analysis (see the Fig. below produced from MetaboAnalyst) \n\n![Screen Shot 2022-06-12 at 4.42.58 PM|690x422, 75%](upload://bce8lewWApoVqfTDeGJueyZrpsK.jpeg)\n\nMetaboAnalyst offers, through a user-friendly web interface, classical univariate ROC curve analysis, and integration with several well-established algorithms (currently support: PLS-DA, Random Forests and SVM) to assist researchers in performing common ROC curve analysis for biomarker discovery and performance evaluation in metabolomics studies."
    },
    {
        "Question": "How to detect potential interactions in multi-factor analysis?",
        "Answer": "Detecting the presence of potential interactions between experimental factors are generally not straightforward in omics data analysis, especially for higher-order interactions (i.e. more than two factors). Several practical methods are available in MetaboAnalyst: \n\n* For individual variable, the interaction can be assessed by univariate two-way ANOVA or linear modeling (limma). Users can view a two-way box plot summary of each variable by clicking the corresponding name in the detailed table view of the two-way ANOVA results.\n\n* The overall interaction effect can be assessed by ASCA permutation tests (under the \"Model Validation\" tab on the ASCA page). It performs unrestricted permutation of observations (Manly's approach) and recalculates the total sum of squares (TSS) for each experimental factor and their interactions. If the TSS calculated based on the original data is significantly different from those calculated from the permuted data, then the effect is significant. For more detailed discussions on this subject, please refer to the paper by [Vis D. J. at. al](http://dx.doi.org/10.1186/1471-2105-8-322)\n\n* Through visualization approaches such as PCA, heatmap, etc to examine patterns of variations across different experimental factors"
    },
    {
        "Question": "How to choose covariates to include in the linear model?",
        "Answer": "The number of covariates that you include is partially dependent on your sample size. We recommend adjusting for only one covariate if your sample size is less than 30, although it depends on the statistical power that you are comfortable with. See [this link](https://www.real-statistics.com/multiple-regression/multiple-regression-analysis/sample-size-multiple-regression/) for a rough picture of the relationship between the number of predictors, statistical power, and the sample size.\n\nOnce you have determined an appropriate number of covariates to include, it is prudent to prioritize those that appear to **explain some variation in the metabolomics data but does not correlated with the primary metadata of interest**. This can be assessed using the \"Correlation\" and \"iPCA\" tools within the multi-factor meta-data module. It is also important to leave out any variables that are highly correlated with the primary variable of interest, as this can lead to highly unstable coefficient estimates (also known as **collider bias**)."
    },
    {
        "Question": "How does the peak intensity table work in the Functional Analysis module?",
        "Answer": "The peak intensity table allows users to perform more flexible data analysis of their untargeted metabolomics data, including \n1) Flexible data processing and normalization using various options within MetaboAnalyst  (like in the Statistical Analysis module) to create the peak list, and then the mummichog or GSEA based functional enrichment analysis\n2) Visually perform <b>enrichment analysis on any patterns of interest<\/b> (for instance, co-regulated peak groups, not just significant peaks) through an interactive heatmap. \n\n![Picture1|690x420](upload://soNZ273VeAjAUsKOPIfcuRZvrB3.png)\n\nSteps: \n1. Drag-select a pattern from the left panel (Overview) to the center panel (Focus View);\n2. Perform enrichment analysis on the patterns displayed within the Focus View;\n3. Click an enriched pathway to examine their matched annotations beside their patterns\n\nLive Demo:\nYou can watch this [video](\"https://youtu.be/8_CbKcE7iwA\") to get how does the interactive heatmap work."
    },
    {
        "Question": "Batch effect correction in MetaboAnalyst",
        "Answer": "MetaboAnalyst offers a web interface for batch effect correction (\"**Other Utilities => Batch Effect Correction**\"). It currently supports nine well-established methods (ComBat, EigenMS, QC-RLSC, ANCOVA, RUV-random, RUV2, RUVseq, NOMIS and CCMN) for batch effect correction. The default option \"automated (default)\" will try all suiable methods and return the results with least distance among batches."
    },
    {
        "Question": "What are the important features for pathway analysis?",
        "Answer": "MetaboAnalystis offers a free, web-based tool for pathway analysis based on targeted metabolomics data. \n<ul>\n<li>\n<b>Algorithm<\/b>: it integrates many well-established (i.e. univariate analysis, over-representation analysis ) methods, as well as novel algorithms / concepts (GlobalTest, GlobalAncova, pathway topology analysis) into pathway analysis.\n<\/li>\n<li>\n<b>Pathway database<\/b>: pathways are defined based on KEGG metabolic pathways (~25 organisms) and [SMPDB](https://www.smpdb.ca/) (human/mouse) \n<\/li>\n<li>\n<b>Visualization<\/b>: implements a Google-Map style interactive visualization system to help users understand their analysis results. These simplified pathways are hyperlinked to their original pathways in KEGG and SMPDB\n<\/li>\n<\/ul>\n  \nMetaboAnalyst also supports pathway analysis for LC-MS based untargeted metabolomics data based on [mummichog](https://doi.org/10.1371/journal.pcbi.1003123) in its <b>Functional Analysis<\/b> module. \n\nFor targeted metabolomics data, there are many commercial pathway analysis software tools, such as [Pathway Studio](http://www.ariadnegenomics.com/products/pathway-studio/), [MetaCore](http://www.genego.com/metacore.php), [Ingenuity Pathway Analysis](http://www.ingenuity.com/), *etc* ."
    },
    {
        "Question": "What is pathway-level meta-analysis of MS peaks?",
        "Answer": "For the **pathway-level meta-analysis**, each study undergoes the typical steps of calculating m/z level statistics (if not already done), putative metabolite annotation, followed by pathway activity prediction. \n\nOnce this is complete for all studies, all pathway results are combined to create a unified matrix of pathway-level results (keeping only pathways found across all-studies). Pathway activity scores are then combined using one of several p-value integration methods.\n\n![pathway_integration|690x216](upload://xIsb5NtrllC4GWAkaTcI5vHwhft.png)"
    },
    {
        "Question": "Does MetaboAnalyst offer class-specific quantile normalization?",
        "Answer": "Due to its potential interest to larger audience, this post was adapted from [our MetaboAnalystR GitHub post](https://github.com/xia-lab/MetaboAnalystR/issues/227)\n\nSome approaches in transcriptomics may not be appropriate for metabolomics, and require benchmarking studies before we can recommend them confidently.  Untargeted metabolomics (~1000s features) are more similar to transcriptomics in terms of feature numbers, as compared to targeted metabolomics data (10s ~ 100s features). More specific considerations are given below:\n\nQuantile normalization (QN) has a very strong assumption and influence on data distribution. In our experience, if it is applied to each class separately, it will generate distinct class separations (very clear on PCA). It is of particular concern when dataset is small. We see PCA changes from no separation to clear separation, with many more significant features identified after this procedure. However, this could be artifacts (i.e. caused by the algorithm).\n\nA general assumption in differential analysis is that most omics features will remain stable (\"homeostasis\"), and only a small percentage (say, < 20%) will change. In this case, it is reasonable to apply QN globally, which is the typical use case for QN approach.\n\nIn summary, without dedicated benchmarking, we only recommend QN (applied to whole dataset instead of class-level) for untargeted metabolomics"
    },
    {
        "Question": "Different feature output in heat map when ANOVA was applied to get top 25, 50 and 100 features",
        "Answer": "Keep in mind there are three actions performed:\n1) Perform ANOVA\n2) Select top # of features\n3) Perform hierarchical clustering on the selected features\n   * This will give different patterns for different number features"
    },
    {
        "Question": "Why in sometimes the 1st component explains less variance than the 2nd component in PLS-DA?",
        "Answer": "Yes, it is possible. PLS-DA maximizes the **covariance** between X (data) and Y (group). The variance displayed in the plot above is the **explained variance for X** . Covariance and x-variance may not agree with each other in some cases. For instance, the 1st component may not explain more X-variance than the 2nd component. In summary:\n1) The first component still explain the most co-variance between X and Y (most predictive)\n2) There are other factors (in addition to Y) contributing to the variance in the data X"
    },
    {
        "Question": "How does \"normalization by a reference sample\" work?",
        "Answer": "Normalization by a reference sample, also known as **probabilistic quotient normalization** ([Dieterle F et al ](http://www.ncbi.nlm.nih.gov/pubmed/16808434)), is a robust method to account for different dilution effects of biofluids. This method is based on the calculation of a most probable dilution factor (median) by looking at the distribution of the quotients of the amplitudes of a test spectrum by those of a reference spectrum.\n\nA closely related method is normalization by a pooled reference sample, in which the reference sample is created computationally by using the mean values of the variables for a user specified reference group."
    },
    {
        "Question": "How to avoid filtering during data normalization",
        "Answer": "MetaboAnalyst website aims to provide the best practice for metabolomics data analysis. \nI assume your data is LC-MS untargeted metabolomics which contains a high proportion of noise,\n\n*  If you choose no-filtering, you will have top 5000 features, not 2500. After minimal data cleaning (blank subtraction and removing low repeatability peaks based on QC), the peaks are already below this number in most time based on our own experience. \n*  Please read [this post](https://omicsforum.ca/t/can-i-perform-pca-using-all-features-i-e-not-filtered-to-a-max-of-5000/576) on data filtering for PCA\n*  [Our recent benchmark study](https://pubmed.ncbi.nlm.nih.gov/36572652) shows that GSEA does not perform well, and ~30% annotation rate can achieve high recall (~90%) on pathway activity prediction using mummichog\n\nFor R package installation, have you tried to follow our instructions, and what are the issues?"
    },
    {
        "Question": "How does MetaboAnalyst optimize the parameters for raw spectra processing automatically?",
        "Answer": "\nThe parameter optimization in MetaboAnalyst is based on our OptiLCMS R package to achieve efficient parameter optimization using two main strategies - selecting high quality peaks for training and focusing on the most influential parameters. OptiLCMS includes three main steps: \n\n1) Contaminant removal (optional)\nIt is not rare that spectra data include some contaminants or noise from MS instruments or chromatography reagents. These mass signals usually appear persistently and may generate giant chromatographic peaks. These noise peaks should be excluded during the parameter optimization step. In OptiLCMS, all mass centroids are extracted and re-sorted from lowest to highest. All centroids that correspond to peaks that spread out over half of the whole chromatogram are excluded. Note, these centroids are only excluded during parameter optimization; they are not deleted from the raw spectra data.\n\n2) Regions of interest (ROI) extraction\nMass signals in LC-HRMS raw spectra are usually enriched in certain regions, rather than distributed evenly across the spectra. Parameter optimization based on the entire spectra is unnecessary. In OptiLCMS, a sliding window method is implemented in both m/z and retention time dimensions to extract multiple areas that are abundant with mass signals. These areas are the base for the subsequent parameter optimization stage.\n\n3) Parameter optimization\nOptiLCMS focus on optimizing eight critical parameters used in the centWave algorithm. Parameters related to noise level (noise, prefilter value and prefilter abundance) and mass error (ppm) are estimated first using a kernel density estimator model. Then, a “Design of Experiment” model (central-composite model) is utilized to recursively estimate four other parameters (peak width, mzdiff, snthresh and bandwidth). Briefly, three levels (-1, 0 and 1) of all parameters are used to construct 44 combinations. The peak profiling results are evaluated based on the principal of selecting more stable and well-behaved peak groups. After the first round of optimization, a new round will be started by setting the best parameters from the last round as the initial values to optimize; this process is repeated until no better results can be obtained. The final optimized parameters will be used for peak profiling.\n\n![Figure-6s_画板 1|625x500, 100%](upload://jbYDknEg31ow3W81GtY5vfyruzY.jpeg)\n\n See more details from our previous [publication](https://www.mdpi.com/2218-1989/10/5/186)."
    },
    {
        "Question": "What are the libraries to select from for functional analysis?",
        "Answer": "The Functional Analysis module provides genome-scale metabolic models from the original mummichog python package, pathway libraries for ~130 (version 6.0) different organisms based on KEGG and BioCyc, as well as other general metabolite set libraries\n\n* The genome-scale metabolic model of *Danio rerio* was manually curated using the KEGG zebrafish model, as well as the human BiGG and Edinburgh Models, and is designated with a [MFN] at the end of its name ([Li et al. 2010](https://www.ncbi.nlm.nih.gov/pubmed/21114829)). \n\n* The human genome-scale metabolic model was also manually curated and originates from a number of sources (KEGG, BiGG, and Edinburgh Model) and has [MTF] at the end of its name. \n\n* The remaining four genome-scale metabolic models were directly derived from BioCyc, denoted with [BioCyc]. The KEGG pathway libraries are designated with [KEGG]\n\n* We also offer 10 metabolite set libraries based on chemical structures, association with diseases, SNPs, locations, etc\n\nFor other organisms not in current options, please select the library closest to your organism."
    },
    {
        "Question": "How to interpret mummichog result table?",
        "Answer": "The results of mummichog method from Functional Analysis module consists of the total number of hits, the raw p-value (Fisher’s), the Gamma-adjusted p-value (for permutations), and the Empirical p-value per pathway. \n\nThe Gamma-adjusted p-values are the Fisher's p-values calculated using Lsig that are adjusted for the null distribution of permutation p-values. \n\nMeanwhile, the Empirical p-values consist of the number of times the p-values using the permuted data were better than the p-values using the significant data, divided by the number of permutations."
    },
    {
        "Question": "How are important features selected in multivariate ROC exploratory analysis?",
        "Answer": "The algorithm tries to identify important features through repeated random sub-sampling cross validation (CV). In each CV, two thirds (2/3) of the samples are used to evaluate the importance of each feature based on \n* VIP scores (feature selection using PLSDA), \n* Decreases in accuracy (feature selection using Random Forest), or\n* Weighted coefficients (feature selection using Linear SVM)\n\nThe top 2, 3, 5, 10 ...100 (max) important features are used to build classification/regression models which are validated on the 1/3 the samples that were left out.\n\nThe significant features are ranked by their frequencies of being selected in the models (see the Fig. below)\n\n![cls_imp_0_dpi150|500x500](upload://hVBy3nyaT8lcM9Qgzn7kJYmMsGg.png)"
    },
    {
        "Question": "Can I perform PCA using all features (i.e. not filtered to a max. of 5000)?",
        "Answer": "For statistical analysis of untargeted metabolomics data, MetaboAnalyst provides a data filtering step to help reduce noise and improve signals. Even you choose the “None\" option, only the top 5000 features (based on a chosen raking method) will be used. This number is generally sufficient for current metabolomics. \n\nPCA is an excellent visualization technique for data overview. It is driven by abundant features / peaks. We find that using top 25% abundant features will get almost the same patterns as using 100% features. If your data contains 8000 features (typical in LC-HRMS untargeted metabolomics), using the top 5000 features (ranked by **mean/median intensity** - the last two options in the Data Filtering page), the PCA results will be **literally identical** to the results based on all 8000 features. This is because that in such high-dimensional data, the remaining 3000 low-abundant features will have coefficients that are too small (essentially zero) to have any effects on the PCA results."
    },
    {
        "Question": "What types of ANOVA are performed for multi-factor ANOVA?",
        "Answer": "For multi-factor/covariates data upload, two-way ANOVA is performed. For time-series only data upload, one-way repeated ANOVA is performed.  For time-series + one experimental factor data upload, it depends on whether the experimental factor is defined within (each subject has multiple experimental factor labels) or between subjects (each subject has only one experimental factor label). For within subjects, two-way repeated ANOVA is performed. For between subjects, mixed ANOVA is performed. \n\nAll ANOVA tests conducted with the [RStatix R package](https://rpkgs.datanovia.com/rstatix/), which automatically determines whether Type I, II, or III errors are appropriate. Due to computational limitations, only **top 200 features** (based on variance) will be tested. For analysis of all features or for unbalanced designs, we suggest to use our **Linear Models** with Covariate Adjustment approach."
    },
    {
        "Question": "How does IQR filtering work?",
        "Answer": "IQR is a measure of variance of a variable (based on its 25th - 75th percentile from concentrations across all samples) - all variables are ranked based on their IQRs and those at the lower tail (i.e. 5% at the bottom) will be removed (near constant). Please note there will be some randomness if two features have the same values (ranks). If you know R, you can search the R function from the R history to see exact command used. \n\nIn this case, it is this R function: \n\"**PerformFeatureFilter**\", \nand this line of R command: \n**rk <- rank(-filter.val, ties.method='random');**"
    },
    {
        "Question": "How to deal with multiple factors and interactions in metabolomics data analysis?",
        "Answer": "In general, multi-factor analysis in conventional statistical analysis cannot be accommodated in omics data simply because 1) such analysis require large sample size usually not available in omics studies; 2) if we perform such tests across all omics features, there is no well-accepted method in multiple testing adjustment, and we are risking high false positives. \n\nHere are some general suggestions in omics analysis with multiple factors \n\n1) Try to <b>reduce<\/b> the number of factors in analysis. For instance, using PCA or heatmap to visually explore the data with regard to meta-data or factors. When there is no clear patterns of separation, it is generally advisable to analyze the data with regard to each experimental factor separately for simpler and easier interpretation.\n \n2) Try to <b>stratify<\/b> data with regard to important factors. In case, strong patterns were detected for some factors, an intuitive approach is split data based on this factor and do analysis separately. For instance, if gender is important, then perform analysis on M and F separately\n\n3) In MetaboAnalyst, the <b>Statistical Analysis [metadata table]<\/b> module does offer several carefully selected approaches that can be used to do analysis at omics scale with considerations of multiple factors and interactions, including \n\n<ul>\n<li>\nTwo-way ANOVA \n<\/li>\n<li>\n ANOVA-simultaneous component analysis (ASCA)\n<\/li>\n<li>\nLinear modelling (limma, supporting fixed and random effects model)\n<\/li>\n<li>\nRandom forest (naturally deals with multi-factors including interactions) \n<\/li>\n<\/ul>"
    },
    {
        "Question": "Can I perform raw spectra centroiding on the fly by MetaboAnalyst?",
        "Answer": "Yes for only a small number of samples.  The online centroiding online is designed to **correct a few raw spectra data failed sanity check due to centroid issue**.  It is not intended for general purpose spectra centroiding.  \n\nIn addition,  given that the Profile data is usually quite huge (> 500MB), it is higly recommended to centroid your data with **ProteoWizard** before uploading (see \" [How to convert raw spectra data into centroid mode?](https://omicsforum.ca/t/how-to-convert-raw-spectra-data-into-centroid-mode/366)\")."
    },
    {
        "Question": "What is the limit of raw spectra data file size?",
        "Answer": "For public server, the size limit of **200MB** per file (after centroiding and zipping) is mandatory. This design is used to ensure the efficiency of data uploading.\n\nIf the file size after centroiding and zipping stills exceeds 200MB, please download and install our R package [OptiLCMS](https://github.com/xia-lab/OptiLCMS) from your local computer."
    },
    {
        "Question": "Why the permutation results generated from SIMCA-P and MetaboAnalyst are different",
        "Answer": "You are comparing an open-source model (k-opls) with a commercial proprietary model (SIMPCA-P).  It is unclear whether they are identical or directly comparable, and  also the permutation procedure could be different. As for k-opls in MetaboAnalyst, the result is more reliable for two-group evaluation than for multi-group scenario."
    },
    {
        "Question": "How to interpret the pathway view?",
        "Answer": "An example of \"pathway view\" is shown below. It shows the current metabolic pathway after user clicks the corresponding node on the \"metabolome view\".  The pathway is essentially a simplified KEGG pathway map shown only chemical compounds. \n\n<ul>\n<li>\nThe default node color is light blue. The matched nodes will show varied heat map colors based on their p values. \n<\/li>\n<li>\nWhen a reference metabolome is provided, some compounds will be colored in light grey if they are not within the reference metabolome. \n<\/li>\n<li>\nThe common compound names can be obtained via mouse over tool-tip. Click on any node will reveal more detailed information as well as database links. For matched compounds, it will also include images summarizing the concentration distribution of the corresponding compound (see [compound view](https://www.omicsforum.ca/t/how-to-interpret-the-compound-view-in-pathway-analysis/167)).\n<\/li>\n<\/ul>\n\n![](upload://u16AAZkBfzyQ5g9mO0CupLZWSpl.png)"
    },
    {
        "Question": "Which databases are used for lipids annotation in MetaboAnalyst v5.0?",
        "Answer": "The lipids have been obtained from [RefMet](https://www.nature.com/articles/s41592-020-01009-y) and [LIPID MAPS](https://stke.sciencemag.org/content/12/563/eaaw2964).\n\nCompared to metabolites, pathways or functional annotation of lipids are much less. In MetaboAnalyst (<b>Enrichment Analysis<\/b> module), lipids are mainly annotated based on their structures. Please choose these libraries for lipidomics data (see the fig below)\n![Screen Shot 2022-06-12 at 3.29.27 PM|690x102](upload://rlB0H7wcu6Q6aS67sUE9Jv0T4CX.png)\n\nWe also recommend the [LION](http://lipidontology.com/) web application for lipidomics data analysis"
    },
    {
        "Question": "What is p-value combination in statistical meta-analysis?",
        "Answer": "Calculating and combining P-values from multiple studies has long been used in the meta-analysis of microarray data, and we are now using these approaches for metabolomics data. These are simple to calculate and flexible to use. \n\n**Fisher’s method** and **Stouffer’s method** are two popular approaches. They have similar levels of performance and can be easily interpreted whereby larger scores reflect greater differential abundance. \n\nThe main difference is that weights (i.e. based on sample sizes) are incorporated into the calculation in Stouffer’s method, whereas Fisher’s method is known as a weight-free method. \n\nNote that larger sample size does not warrant larger weights, as the quality of each study can be variable. Users should choose to apply Stouffer’s method only when all studies are **of similar quality.**"
    },
    {
        "Question": "How are mummichog and GSEA p-values combined?",
        "Answer": "The **Functional Analysis** module uses the ([Fisher's method](https://en.wikipedia.org/wiki/Fisher%27s_method)) for combining the p-values calculated by mummichog and GSEA. It takes the raw p-values per pathway to perform p-value combination."
    },
    {
        "Question": "Where are the results when I run mummichog (PerformPSEA) using MetaboAnalystR",
        "Answer": "When running MetaboAnalystR (such as PerformPSEA), it usually saves these data files in the working directory."
    },
    {
        "Question": "Why should I filter baseline noises (untargeted metabolomics)?",
        "Answer": "* For NMR or MS spectra, there are many regions where no known compounds in biofluids have signals. The corresponding regions contain mainly baseline noises. \n* When signal approaches background, the relative errors increases and conclusions based on these data will be questionable. \n* The penalty for multiple testing adjustment will also become more stringent to control false positives. \n\nTherefore, it is best to first try to filter baseline noises before further analysis."
    },
    {
        "Question": "What are the accepted data formats for raw spectra data processing?",
        "Answer": "Currently, MetaboAnalyst only accepts open-source formats of raw spectra data, including \"**mzML**\", \"**mzXML**\", \"**cdf**\" and \"**mzData**\". Other vendor data formats are not supported for now. \n\nPlease perform data conversion before uploading with [Proteowizard](https://proteowizard.sourceforge.io/download.html) if your data are not provided in any format above.\n\nIt is highly recommended to convert the raw MS data into **centroid** mode to reduce the uploading time. (See \"*[How to convert raw spectra data into centroid mode?](https://www.omicsforum.ca/t/how-to-convert-raw-spectra-data-into-centroid-mode/366)*\")"
    },
    {
        "Question": "What are the differences among the pathway databases in joint-pathway analysis?",
        "Answer": "There are four different types of pathways prepared for users to integrate and interpret their data.\n\n![Screen Shot 2022-06-12 at 4.04.47 PM|618x298, 50%](upload://rIBUPfVzpZTxXVLL5KaRzqJELwr.png)\n\nAll these pathways are based on KEGG database obtained using KEGG REST API. The first two options are for integrative analysis, with the latter option also includes pathways containing only genes (i.e. gene regulatory pathways). The last  two options are mainly for users to compare the results based on metabolites only or genes only,"
    },
    {
        "Question": "Why does MetaboAnalyst offer several pathway libraries for the same organism?",
        "Answer": "There are several widely used pathway databases including KEGG, BioCyc, SMPDB, as well as GEM models. All of them have different strengths and limitations in terms of pathway definition and species coverage. MetaboAnalyst aims to accommodate the diverse needs of the user community by providing multiple options.   \n\nFor instance, for humans, users can either use the manually curated genome-scale metabolic model **[MTF]**, the BioCyc metabolic model **[BioCyc]**, or the KEGG pathway library **[KEGG]**."
    },
    {
        "Question": "What is the difference between mummichog v1 and v2 in Functional Analysis module?",
        "Answer": "The *mummichog* version 2 takes into consideration of retention time information to perform pathway analysis. It is **only be available** if user's data contains a retention time (\"rt\" or \"r.t\") column. The inclusion of retention time will increase the confidence and robustness of the potential compound matches. \n\nAnother difference is that currency compounds are removed directly from the user's selected pathway library, versus removed from potential compound hits during the permutations."
    },
    {
        "Question": "Low sample size",
        "Answer": "For most datasets analyzed in MetaboAnalyst, the PLS-DA results should be taken as exploratory, to identify potential patterns in the dataset. For a deeper understanding of the permutation p-value in the PLS-DA module, see [this post](https://omicsforum.ca/t/how-to-interpret-the-permutation-result-pls-da/96). \n\nOmics datasets often have very low sample size (n = 3 is especially low), where the statistical power is quite low for moderate effect sizes, even if though many of these moderate effect sizes could still be biologically relevant. You can combat this by looking from the data from multiple perspectives (ie. differential abundance analysis, pathway analysis, PCA, PLS-DA, etc) and looking for consistent trends."
    },
    {
        "Question": "Low sample size",
        "Answer": "The bottom line: prediction / classification (i.e. PLS-DA) generally requires more samples than statistical comparison (i.e. t-tests). Cross validation or permutations are not meaningful with n=3"
    },
    {
        "Question": "When should I use direct merge for meta-analysis?",
        "Answer": "In this approach, different data sets are merged into a mega-data set and then analyzed as if all data sets were derived from a single experiment. This approach ignores the inherent bias and heterogeneity of data sets from different sources. \n\nMany other factors (experiment protocols, technical platforms, raw data processing procedures and so forth) can potentially contribute to the observed differences. This approach should **only be used when data sets are very similar** (i.e. from the same lab and same platform without batch effects)."
    },
    {
        "Question": "Data upload failed",
        "Answer": "GC-MS data, and then Pathway Analysis on MetaboAnalyst platform. Data upload always fails. I doubt that the compound name is inconsistent with the database name. Is there any solution?"
    },
    {
        "Question": "One Factor Statistical Analysis PLS-DA Permutation Test Do Not Display Or Download",
        "Answer": "I have been using one factor statistical analysis of two experimental condition lc-ms processing, everything have been running fun until the new update. I was able to run everything smoothly on transformation, normalization, and other analysis, however, the permutation test for my PLS-DA does not display after it finished running, displaying only a blank page. I have tried to use different computer and browsers, enabling java and cookies but nothing seem to be working. Might anyone have any idea for resolution?\n\n![Screenshot 2023-04-21 at 1.01.40 PM|624x500](upload://xv1FGnBrWSsQ4NANXqBwshPsQvT.png)\non test is also not available in the download section like it have been in the past."
    },
    {
        "Question": "What types of input does MetaboAnalyst accept?",
        "Answer": "MetaboAnalyst accepts all data formats commonly generated in metabolomics, including \n\n* Targeted profiling (compound list, or concentration tables)\n* Fingerprinting approaches (spectral bins, peak lists) produced from either NMR, LC-MS, or GC-MS. \n* Raw LC-MS spectra saved in open data format (mzML, mzXML, NetCDF) \n\nFor format specification and example datasets, please check the <a href = \"https://www.metaboanalyst.ca/docs/Format.xhtml\">\"Data Formats\"<\/a> from MetaboAnalyst for more details."
    },
    {
        "Question": "How does \"Normalization by a pooled sample from group\" work?",
        "Answer": "The method works as below:\n\n1. Compute a reference sample based on your selected group by averaging across each feature / variable ; \n2.  For each sample, \n  a.   Compare with this reference sample to obtain a most probable dilution factor (median of the ratio);\n  b.   Divide each feature by this dilution factor;\n\nNote the reference sample is the same for all, but the dilution factors are sample specific. \n\nIn Step #2, unless your QC samples contain identical values (which are unlikely),  their values will still remain different.  Hopefully the QC profiles will become more similar to each other (i.e. tighter cluster in PCA) compared to the profiles before normalization."
    },
    {
        "Question": "How should I optimize parameters for spectra processing?",
        "Answer": "MetaboAnalyst provide flexible and transparent approach for user to optimize the parameters manually or automatically.\n\nFor **beginners**, it is recommended to use the \"**Auto-optimized**\" mode to optimize paramters automatically. Once the option is checked, the parameters that would be optimized automatically are disabled for manually editing (see screen below).\n\nFor **Advanced Users**, you can try to use the \"Auto-optimized\" mode or use \"**Default/Manual**\" mode based on your platform. The suggested parameters would be filled automatically in the parameters panel. You can manually change or edit based on your knowledge or experience.\n\nIt is noted that, for the parameter \"**Polarity**\", you have to manually choose \"positive\" or \"negative\" based on your instrumental condition, no matter what \"Parameter Setting\" mode you are using.\n\n![image|419x500](upload://ru8aOaBylXdL9GuQgOkEWezuq8G.png)"
    },
    {
        "Question": "Error when running function mSet<-Read.TextData(mSet, \"metaboanalyst_input.csv\", \"colu\", \"disc\") and InitDataObjects() will return NULL",
        "Answer": "When you finish a complete analysis of a specific module, you need to clean the environment and do the analysis for another one. This is highly recommended and required when your code running into an error and cause the mSet into NULL."
    },
    {
        "Question": "How to report the results from the new linear mixed modelling analysis",
        "Answer": "The linear modelling is using the limma R package and link their excellent [user manual](https://www.bioconductor.org/packages/devel/bioc/vignettes/limma/inst/doc/usersguide.pdf). \n\nFor models that include a blocking factor, we are following the methods specified in section 9.7 almost exactly. The only difference is that in the final line of section 9.7, they specify a single coefficient from the model (referencing a single contrast) in their topTable command, whereas we do not specify any which causes topTable to report all coefficient values for the primary metadata \n\nWhen the  primary metadata is continuous (ie. AGE) or categorical with only two groups (ie. CTRL, TRT), there is only one coefficient (AGE or TRT-CTRL respectively) and limma returns the moderated t-statisic and associated p-value; when it is categorical with >2 groups there are more coefficients (ie. CTRL, TRT.A, TRT.B = TRT.A-CTRL, TRT.B-CTRL). When topTable is not given a specific model coefficient, it reports an ANOVA-like F-statistic and associated p-value. The MetaboAnalyst results table column will be named either \"F\" or \"t\" depending on the situation.\n\nIf you'd like to dig further, query the \"topTable\" documentation page in R (?topTable; limma R package). They have an excellent description of each column. To see the exactly how the code is implemented, you can click \"Show R Commands\" in the top right corner and then inspect the relevant functions in the [MetaboAnalystR github page](https://github.com/xia-lab/MetaboAnalystR)."
    },
    {
        "Question": "How to interpret \"enrichment ratio\" in enrichment analysis result table?",
        "Answer": "**In ORA and SSP:** Fold-enrichment is calculated by dividing the observed number of hits by the expected number of hits (\"Hits\" / \"Expect\" columns of the ORA and SSP results table).\n\n**In QEA:** Fold-enrichment is calculated by dividing the observed Q statistic by the expected Q statistic (\"Statistic\" / \"Expected\" columns of the QEA results table)."
    },
    {
        "Question": "How to judge the quality of data normalization",
        "Answer": "One way would be to compare the distribution of the pre- and post-normalized data. This can be done directly in MetaboAnalyst: after you submit your normalization parameters, you will be given the option to view your results before proceeding. If done well, your normalized data should have a Gaussian/normal distribution (note there is no guarantee of global multivariate normal distribution). You should also use PCA (and/or Heatmap) visualization to see if there are some patterns/outliers that make better sense based on your study design."
    },
    {
        "Question": "How many raw spectra files each group are required for processing?",
        "Answer": "At least **3** samples (files) are required for each group. In addition, we highly recommend including QCs and BLANKs, expecting **a minimum of ~ 10 spectra**"
    },
    {
        "Question": "How does recursive SVM (RSVM) work?",
        "Answer": "Recursive SVM (R-SVM) uses SVM for both classification and for selecting a subset of relevant genes according to their relative contribution in the classification. This process is done recursively so that a series of data subsets and classification models can be obtained in a recursive manner, at different levels of feature selection. \n\nThe performance of the classification can be evaluated either on an independent test data set or by cross validation on the same data set. R-SVM also includes an option for permutation experiments to assess the significance of the performance. Please note, only linear kernel was used for classification, since the information is usually far from sufficient for reliably estimating nonlinear relations for high-dimensional data with a small sample size. First-order approximation will reduce the risk of overfitting in case of limited data. CV2 refers to the cross validation embedded with the feature selection procedure as discussed above. The chart below summarize the R-SVM workflow. For more details, please read the paper by [Zhang X, et al](http://www.ncbi.nlm.nih.gov/pubmed/16606446).  \n\n![](upload://bgmRxcXY7Rx2S3wtx9hbaBKwtIS.png)"
    },
    {
        "Question": "Interpreting Statistic Q and Expected Q in Metabolite Set Enrichment Analysis (MSEA)",
        "Answer": "MSEA is based on the well-established [**globaltest**](https://doi.org/10.1093/bioinformatics/btg382) to test associations between metabolite sets and the outcome. The algorithm uses a generalized linear model to compute a ‘Q-stat’ for each metabolite set. The Q-stat is calculated as the average of the Q values calculated for the each single metabolites; while the Q value is the squared covariance between the metabolite and the outcome. The globaltest has been shown to exhibit similar or superior performance when tested against several other popular methods.\n\nIf you know R, you can search the function (from R command history) to see its source code in our MetaboAnalystR GitHub"
    },
    {
        "Question": "Why does the PLS-DA separation pattern change after I updated the class labels?",
        "Answer": "The separation in PLS DA is calculated by maximizing the covariance between the data matrix (X) and the class labels (Y). By default , the program will first convert the class labels into rankings based on their numerical or alphabetic orders. For instance, group labels “A, B, C, D” will be 1, 2, 3, 4; while group labels “low, medium, high” will become 2, 3, 1! The PLS regression will be performed between the data matrix X and the numerical Y.  When you update the labels, it could leads to the change of order, and thus the separation patterns (note the classification will not be affected by this) \n\nFor two group data, this procedure will not affect the visualization pattern, as it will always be between 1 vs. 2. For multi groups, this default approach is meaningful when the group labels correspond to time series, disease severity, or treatment dose. However, when group labels do not reflect quantitative differences, users should **uncheck the option \"Class order matters\"** (located on the top of the page, see below). In this case, PLS-DA will be performed using a general linear model in which group labels will be coded using **model matrix** rather than numerical values.\n![Screen Shot 2022-07-25 at 10.52.10 AM|690x112, 75%](upload://bmKtaUa2TsMiVohIAf2zhu92sKL.png)"
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "For untargeted metabolomics anayliss, I have 8 biological replicates for each sample.  When we are performing differential metabolite analysis (such as fold change >2, VIP >1, P value <0.5), for one compound, some replicates have a value (relative peak intensity),  while other replicates have no value (empty).  How could we calculate the overall fold change (or VIP score, P value)  for this sample and define if it is differential or not compared to other samples?"
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "I am not sure about the experimental design based on your description\n\n1) If you mean 8 **technical replicates** for each sample (i.e. one sample measured 8 times)? If so, you should first [merge technical replicates](https://www.omicsforum.ca/t/how-to-deal-with-technical-replications/80), as most analysis methods in MetaboAnalyst assume independent samples (i.e. biological replicates)\n\n2) If you mean 8 biological replicates for each **group**, and you have two or more groups, it is the typical design, and you can directly upload it to MetaboAnalyst for statistical analysis."
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "Thanks for your reply. I did not know that we could generate the report.\nI still have one question about the data processing.  I'll use my own data as an example. I have 10042 features for input,  around 5000~7000 features (for all samples) are left  (see picture below) after the steps of data filtering and normalization, but only 2500 features are used for the following statistical analysis, as shown in the files \"data_processed.csv\" and \"data_normalized.csv\" . Furthermore, there is also one sentence in the report : \"Further feature filtering based on Interquantile Range Reduced to 2500 features based on Interquantile Range.\"  \n\nMy question is:  why did you only choose 2500 features for the following statistical analysis?\n\n![image|690x100](upload://3Fqr5JxWbGUGoxBzKLyI0x6RH5a.png)"
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "If your samples are very heterogeneous even within the same group,  then it could be difficult to draw conclusions in statistical analysis. For untargeted metabolomics, you can: \n\n1) **Increase sample size**\n2) Remove potential sample outliers \n3) Missing value estimation \n4) Data filtering \n5) **Data normalization**\n\nMetaboAnalyst offers comprehensive support for options 3,4,5.  You should follow our detailed tutorials (such as this [protocol](https://doi.org/10.1002/cpbi.86)) on these topics.  Note the data for downstream statistical analysis is save as **data_normalized.csv** in your \"Download\" folder. You can open this file using any Spreadsheet program to see the actual values for your feature of interest"
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "Yes, it is the second option, 8 biological replicates for each group.  My meaning is that how does MetaboAnalyst treat 8 biological replicates for statistical analysis if  there is a big difference among  these biological replicates?"
    },
    {
        "Question": "How to deal with biological replicates?",
        "Answer": "The short answer is that we need to have a default value, but there are many other options. I would strongly encourage you to read the details on the **Data Filtering** page.    \n\nAnother [related post is here](https://omicsforum.ca/t/can-i-perform-pca-using-all-features-i-e-not-filtered-to-a-max-of-5000/576)"
    },
    {
        "Question": "How many nodes can be visualized (network size limit)?",
        "Answer": "The visualization is actually limited by the performance of users' browsers and screen resolutions. Too many nodes will make the network too dense to visualize and the computer slow to respond. \n\nFor practical visual exploration and understanding, we recommend limiting the total number of nodes to between **200 ~ 2000** for the best experience. For very large networks, please make sure you have a decent computer equipped with a modern browser (we recommend the latest Google Chrome)."
    },
    {
        "Question": "Order of operation for fold change and p value computing in MetaboAnalyst",
        "Answer": "Normalization and scaling are conducted before the fold-change and p-values are calculated, so they will impact these values. This is standard practice. You can see based on the order of the pages, and also you can click to see the R commands in the top right corner. This shows the order that different functions are called in. The sentences below are copy-and-pasted directly from the fold analysis page: \n\n## Fold Change (FC) Analysis\n\nThe goal of fold change analysis is to compare the absolute values of change between two group means. Since column-wise normalization (i.e. log transformation and various scaling) will significantly change absolute values, FC calculation are using data **before** the column-wise normalization was applied (i.e. at the original scale). The significant features are those features whose FCs are beyond the given FC threshold (either up or down)."
    },
    {
        "Question": "How to set a specific order for your samples in an heatmap?",
        "Answer": "You can now use **Data Editor => Edit Groups** to re-order groups or exclude a group of interest."
    },
    {
        "Question": "How to prepare data sets for statistical meta-analysis?",
        "Answer": "Here are some **basic rules** for data collection for using <b>Statistical Meta-analysis<\/b> module in MetaboAnalyst:\n\n1. These data sets were collected under **comparable experimental conditions**, and/or the underlying experiments share the same hypothesis or are held to have the same mechanistic underpinnings;\n2. **Only two-group comparisons** are supported at the moment (i.e., control vs disease);\n3. These datasets must share the **same type of IDs** so that the majority of these feature will match. This is usually not possible for untargeted metabolomics. Please use <b>Functional Meta-analysis<\/b> module in this case;\n4. It is best to keep all data on the **same scale or range** (i.e. both raw or normalized in the same way). It is generally preferred to compare at log scale. MetaboAnalyst offers boxplots and log normalization to help facilitate this process."
    },
    {
        "Question": "Similar Programs to Metaboanalyst for Proteomics",
        "Answer": "Have you tried our ExpressAnalyst ([expressanalyst.ca](https://www.expressanalyst.ca))? It is designed for both transcriptomics and proteomics. You can read our recent protocols (Current Protocol and Nature Protocol - with proteomics as examples) from the web site"
    },
    {
        "Question": "Why does the univariate ROC analysis sometimes yield AUROC better than those obtained using multiple features?",
        "Answer": "\"Classical\" means traditional approaches before ML & cross validation become popular \n \nKeep in mind that MetaboAnalyst allows you to manually create biomarker model (the **Tester** path).  To generate a cross-validated univariate ROC model,  select a single feature of interest, use any of the models (SVM, PLS-DA, RF) to get the ROC curve."
    },
    {
        "Question": "Why does the univariate ROC analysis sometimes yield AUROC better than those obtained using multiple features?",
        "Answer": "The ROC curves created (using ROC Explorer or Tester) are based on **cross-validation** performance of multivariate algorithms (SVM, PLS-DA or Random Forests). In contrast, the classical univariate ROC curves are created based on the performance measured by testing all possible cutoffs within **ALL** data points. \n\nTherefore, the AUROC from cross validated ROC curve is more realistic for prediction purpose, while the AUROC calculated from ROC curve created by univariate approach is often too optimistic (i.e. overfit). In other words, univariate ROC can be considered as an indicator of the discriminating \"potential\" of the feature, not its actual performance."
    },
    {
        "Question": "Option for time series analysis",
        "Answer": "We have increased support for continuous/complex metadata, and renamed the module \"Statistical Analysis [metadata table]\". There are several types of analysis available after filtering/normalization. The ones relevant for time series analysis are \"Two-way ANOVA\" and \"Multivariate Empirical Bayes Analysis of Variance for Time Series\" (these are in the video tutorial I believe). A new feature we've implemented is \"Linear Models with Covariate Adjustment\" - you can identify metabolites associated with the \"time\" metadata, and adjust for other covariates like sex, age, or batch if applicable."
    },
    {
        "Question": "How does MetaboAnalyst calculate 95% confidence intervals (CIs) of AUC/pAUC (biomarker analysis)?",
        "Answer": "The program uses a non-parametric re-sampling based approach for calculating the confidence intervals. In either bootstrap (classical) or MCCV (multivariate) approach, the data are re-sampled many times, with the AUC/pAUC calculated each time. \n\nConfidence intervals are then estimated by simply sorting the data and taking the percentiles to our desired confidence interval bounds. For instance, in 1000 resampling, 95% CIs will be the 25th and 975th values of the sorted AUC values. For details, please refer to the paper by [T.A. Lasko et al.](http://www.ncbi.nlm.nih.gov/pubmed/16198999)."
    },
    {
        "Question": "What is Q-statistic in quantitative enrichment analysis (QEA)?",
        "Answer": "The formula to calculate Q-statistic can be obtained from the original publication by ([Goeman JJ, et al](http://www.ncbi.nlm.nih.gov/sites/entrez/14693814)). Q-statistic can be intuitively interpreted as an aggregate of squared covariance between concentration changes and the phenotypes - compounds with large variance have much more influence on the Q than compound with small variance."
    },
    {
        "Question": "How many raw spectra files at most allowed for processing simultaneously?",
        "Answer": "For public server, the maximum number of sample files allowed for processing simultaneously is **200**. \n\nIf the file number exceeds 200, you can either subscribe to the Pro version or install our R package [OptiLCMS](https://github.com/xia-lab/OptiLCMS) in your local computer and do spectra processing based on our documentation."
    },
    {
        "Question": "What is statistical meta-analysis?",
        "Answer": "Meta-analysis is a type of statistical technique used to integrate multiple independent datasets that have been collected to study same or similar experimental conditions, in order to obtain more robust biomarkers. By combining multiple data sets, the approach can increase statistical power (more samples) and reduce potential bias.\n\nA key concept in meta-analysis is that it is generally unadvisable to **directly combine different independent datasets** (i.e. merge them into a single large table) and analyze them as a single unit. This is due to potential batch effects associated with each datasets, which can completely overwhelm the biological effects. This issue has been well-studied in microarray experiments generated from different platforms. It is expected the issue could be more severe due to the lack of standardization in metabolomics.\n\nInstead, meta-analysis is usually computed based on summary statistics (p values, effect sizes, etc.) to identify robust biomarkers. The <b>Statistical Meta-analysis<\/b> module in MetaboAnalyst was developed to support these approaches. The results can be visualized using heatmap to explore the patters across different studies."
    },
    {
        "Question": "Compound name mapping API does not work for anything other than name",
        "Answer": "HI, I was trying to perform Compound name mapping by API in section 3.2 here:\nhttps://www.metaboanalyst.ca/MetaboAnalyst/docs/RTutorial.xhtml\n\nAs other posts have mentioned, it seems to only work when querying by name but not other types of ID (such as KEGG ID). I was wondering if this issue has been solved? thank you very much for your help.\n\n\nRelated posts are here:\nhttps://omicsforum.ca/t/api-mapcompounds-too-does-not-work-for-anything-other-than-name/614\nhttps://omicsforum.ca/t/metaboanalystr-querying-pubchem-cids-hmdb-ids-with-api-in-rstudio-compound-name-mapping/606\n\n\nhere is my code record:\n======\n> library(httr)\n> \n> # using compound name to query:\n> name.vec<-c(\"1,3-Diaminopropane\")\n> toSend = list(queryList = name.vec, inputType = \"name\")\n> \n> \n> # The MetaboAnalyst API url\n> call <- \"https://www.xialab.ca/api/mapcompounds\"\n> \n> # Use httr::POST to send the request to the MetaboAnalyst API\n> # The response will be saved in query_results\n> query_results <- httr::POST(call, body = toSend, encode = \"json\")\n> \n> # Check if response is ok (TRUE)\n> # 200 is ok! 401 means an error has occured on the user's end.\n> query_results$status_code==200\n[1] TRUE\n> \n> # Parse the response into a table\n> # Will show mapping to \"hmdb_id\", \"kegg_id\", \"pubchem_id\", \"chebi_id\", \"metlin_id\", \"smiles\" \n> query_results_text <- content(query_results, \"text\", encoding = \"UTF-8\")\n> ### fromJSON takes JSON strings\n> query_results_text2 <- gsub(\"'\", '\"', query_results_text)\n> query_results_text2 <- purrr::map(query_results_text2, jsonlite::fromJSON)\n> query_results_table <- do.call(cbind, lapply(query_results_text2, data.frame, stringsAsFactors = FALSE))\n> rownames(query_results_table) <- query_results_table[,1]\n> print(query_results_table)\n                                Query              Match        HMDB PubChem ChEBI   KEGG METLIN SMILES Comment\n1,3-Diaminopropane 1,3-Diaminopropane 1,3-Diaminopropane HMDB0000002     428 15725 C00986   5081  NCCCN       1\n> \n> \n> \n> # using kegg ID to query:\n> name.vec<-c(\"C00986\")\n> toSend = list(queryList = name.vec, inputType = \"kegg\")\n> \n> # The MetaboAnalyst API url\n> call <- \"https://www.xialab.ca/api/mapcompounds\"\n> \n> # Use httr::POST to send the request to the MetaboAnalyst API\n> # The response will be saved in query_results\n> query_results <- httr::POST(call, body = toSend, encode = \"json\")\n> \n> # Check if response is ok (TRUE)\n> # 200 is ok! 401 means an error has occured on the user's end.\n> query_results$status_code==200\n[1] TRUE\n> \n> # Parse the response into a table\n> # Will show mapping to \"hmdb_id\", \"kegg_id\", \"pubchem_id\", \"chebi_id\", \"metlin_id\", \"smiles\" \n> query_results_text <- content(query_results, \"text\", encoding = \"UTF-8\")\n> ### fromJSON takes JSON strings\n> query_results_text2 <- gsub(\"'\", '\"', query_results_text)\n> query_results_text2 <- purrr::map(query_results_text2, jsonlite::fromJSON)\n> query_results_table <- do.call(cbind, lapply(query_results_text2, data.frame, stringsAsFactors = FALSE))\n> rownames(query_results_table) <- query_results_table[,1]\n> print(query_results_table)\n        Query Match HMDB PubChem ChEBI KEGG METLIN SMILES Comment\nC00986 C00986    NA   NA      NA    NA   NA     NA     NA       0\n\n======\n> sessionInfo()\nR version 4.1.1 (2021-08-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] httr_1.4.7\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11         urlchecker_1.0.1    pillar_1.9.0        compiler_4.1.1      BiocManager_1.30.22 later_1.3.1        \n [7] remotes_2.4.2.1     profvis_0.3.8       tools_4.1.1         digest_0.6.33       pkgbuild_1.4.3      pkgload_1.3.3      \n[13] jsonlite_1.8.8      memoise_2.0.1       lifecycle_1.0.4     tibble_3.2.1        pkgconfig_2.0.3     rlang_1.1.2        \n[19] shiny_1.8.0         cli_3.6.1           rstudioapi_0.15.0   curl_5.1.0          fastmap_1.1.1       dplyr_1.1.4        \n[25] stringr_1.5.1       generics_0.1.3      fs_1.6.3            vctrs_0.6.5         htmlwidgets_1.6.4   devtools_2.4.5     \n[31] tidyselect_1.2.0    glue_1.6.2          R6_2.5.1            fansi_1.0.5         sessioninfo_1.2.2   purrr_1.0.2        \n[37] magrittr_2.0.3      usethis_2.2.2       promises_1.2.1      ellipsis_0.3.2      htmltools_0.5.7     mime_0.12          \n[43] xtable_1.8-4        httpuv_1.6.12       utf8_1.2.4          stringi_1.8.2       miniUI_0.1.1.1      cachem_1.0.8"
    },
    {
        "Question": "Error in Data Editor - Edit groups error",
        "Answer": "In Data Editor> Edit Groups: after excluding some groups to make available only 2 groups > submitting and reapplying normalization > then when I try to visualize the Volcano Plot this error message appears:\n\n* ErrorThe method is only applicable for two-group data analysis! You can use **Data Editor** => **Edit Groups** to specify two groups of interest for analysis."
    },
    {
        "Question": "LC-MS Spectra Processing ERROR:trying to get slot \"params\" from an object (class \"bplist_error\") that is not an S4 object",
        "Answer": "I am trying to process my raw LC-MS/MS data using the LC-MS Spectra Processing module and keep on getting the same error at Step 4/6 (ERROR:trying to get slot \"params\" from an object (class \"bplist_error\") that is not an S4 object).\n\nData:\nUPLC-Q/TOF negative ion mode raw data\n66 mzML files (including BLANK and QC files) uploaded as individual zip files\n\nParameters:\n“Default/manual” parameter settings for “UPLC-Q/TOF” LC-MS Platform\nPeak Alignment Method: obiwarp\nPeak Annotation Polarity: negative\n\nPlease advise on what parameters need to be adjusted to resolve this issue. Thank you very much!\n\n![metaboanalyst parameters|453x500](upload://cbaf7t25H36RFaiWzVukwPEEYTN.jpeg)\n![metaboanalyst error|617x500](upload://i5hrgNxu6thJO6ffu9UfUDKhjwQ.jpeg)"
    },
    {
        "Question": "LC-MS Spectra Processing ERROR:trying to get slot \"params\" from an object (class \"bplist_error\") that is not an S4 object",
        "Answer": "Your job was failed because of \"Out of MEMEORY\" issue. This is due to your job was requesting more RAM than the up-limit we can allocate. Please try to run local OptiLCMS or MetaboAnalystR to process your data."
    },
    {
        "Question": "Is it possible to get the p-value for the R2Y and Q2 in PLS-DA?",
        "Answer": "In theory, it is possible (i.e. based on permutations). However, the actual value is unclear. For validity of PLS-DA model, the B/W and prediction performance are two options provided in MetaboAnalyst"
    },
    {
        "Question": "Job status shows as \"CANCELED\", but a few seconds later it changes to \"KILLED\" for LC-MS spectra processing",
        "Answer": "The Job status shows \"CANCELED\" or \"KILLED\" means the job processing time exceeds the maximum time limits allocated for a job (usually 6 hours, at current stage). To  allow more users submiting and finishing their jobs, MetaboAnalyst has to terminate the job due to the limited computing resource. In this case, you are encouraged to use OptiLCMS (https://github.com/xia-lab/OptiLCMS) to run your job locally or subscribe to our pro version."
    },
    {
        "Question": "When should I use Data editor or Data filter?",
        "Answer": "These two functions are designed to allow users to manipulate their data to obtain more consistent and reliable results. In particular, \n*  Use **Data Editor - Edit Samples** to exclude outlier samples (must have strong reasons); \n*  Use **Data Editor - Edit Groups** to exclude certain groups during comparative analysis. For instance, to perform two-group comparisons for  multi-group dataset; \n*  Use **Data Editor - Edit Features** to **manually exclude** certain features based on some visual inspection; \n* Use **Data Filter** to **automatically exclude** noisy or uninformative **features** based on some statistical measures (i.e. baseline noises, near-constant-features). These features tend to dilute the signal and decrease the performance of most the statistical procedures.\n\nWe strongly recommend [this post on data editing](https://www.omicsforum.ca/t/can-i-use-the-selected-features-for-classification/102)"
    },
    {
        "Question": "Some images did not show up after I click the corresponding tab?",
        "Answer": "This implies MetaboAnalyst failed to execute the command. \n\n* <b>Parameter issue<\/b>: adjust parameters and try again;\n\n* <b>Data issue<\/b>: in many cases, the problem is associated with sample size. In particular, if the sample size is very small (below 10), some unpredictable error may happen. For instance, by default PCA and PLSDA will try to generate summary/classification/permutation plot for the top 5 components, if the sample size is too small, it will fail to do so;\n\n* <b>Program issue<\/b>: if you believe the issue is unlikely caused by issues described above, please provide details (data + steps) that can reproduce the issue"
    },
    {
        "Question": "Error while processing raw LC-MS/MS data at step 4/6: \"ERROR:trying to get slot \"params\" from an object (class \"bplist_error\") that is not an S4 object\"",
        "Answer": "I am trying to process a set of raw LC-MS/MS data from my experiment and it keeps erroring out at step 4/6 with the same error. I have tried uploading the same data set and rerunning three time and get to same error at the same point each time.\n\nJob ID: 17382(got cancelled) and [17378](https://www.metaboanalyst.ca/MetaboAnalyst/faces/Share?ID=0ne68n4q1_17378)\n\n![image|690x473](upload://27SvkL4McSs6j38COT59QyNt1tr.png)\n\nPlease advise on what I need to fix or if any additional information is \n required from me to resolve this issue! Thank you for your time."
    },
    {
        "Question": "Files too large",
        "Answer": "One possible way is to install MetaboAnalystR to do it locally,  as the public server has limited resources"
    },
    {
        "Question": "Files too large",
        "Answer": "I am using a dataset where each file is around 400MB. After conversion to .mzML or .zip, the size doesn't shrink under 250MB - which is still too big to be uploaded.\n\nHow should I upload my data?"
    },
    {
        "Question": "Pairwise comparisons using linear models",
        "Answer": "Hi -\nI am running an analysis on a complete randomized block design. We have 3 treatment groups (between subjects; Treatment A, Treatment B, and Treatment C) and 5 time points per animal (repeated measure). Because our design is not perfectly balanced, I can't use the ANOVA option and I have to use the Linear Model option. My primary metadata is treatment. I am modeling time as a continuous covariate, subject as the blocking factor to account for repeated measures, and then I have block and 2 other covariates to account for variation as covariates.  Please let me know if you have any thoughts on how I set this up. \n\nHow do I conduct pairwise comparisons between my 3 treatment groups using a linear model? OR do I need to run the analysis 3 separate times, one time for each comparison (Treatment A v. B, A v. C, and B v. C)?  I see a P-value and an adjusted P-value (presumably for the main effect of treatment), but I don't see pairwise comparisons. \n\nThanks!\nTurner"
    },
    {
        "Question": "Pairwise comparisons using linear models",
        "Answer": "Currently the linear model tool is not set-up to return p-values from individual contrasts when the categorical primary metadata has more than two groups. For a categorical primary metadata, you must set a reference treatment (ie. Treatment A). Then, if there are more than two groups, MetaboAnalyst will return the fold-change for each other treatment vs. reference (ie. Treatment B/Treatment A; Treatment C/Treatment A) - see the first columns in the results table. For categorical variables with two groups, the results table p-value is for the one contrast and derived from an t-stat. For those with more than two, it's an ANOVA-style p-value for the set of contrasts, derived from an F-stat. \n\nI am currently implementing an interface that will allow you to get statistics for a specific contrast when the categorical primary metadata has more than two groups. It should be done in a few days, and I'll update this with how to use it to address your situation."
    },
    {
        "Question": "Pairwise comparisons using linear models",
        "Answer": "The interface for specific contrasts is now available online. It looks like this:\n\n![image|690x438](upload://daw0i6zhtO904fa8KhNDZCeQd2b.png)\n\nIn this example, I am looking for metabolites that are significantly different between subjects exposed to \"High\" and \"Low\" concentrations of TCE (the primary metadata variable), while accounting for age and sex as covariates (fixed effects) and batch as a blocking factor (random effect). \n\nTo get pairwise results, I would save this, then perform two more analyses as you outlined, in my case: \"Medium\" vs. \"Low\" and \"High\" vs. \"Medium\"."
    },
    {
        "Question": "How do I select metabolites clustered together in a heatmap and do enrichment analysis on only those selected metabolites?",
        "Answer": "Please see the attached picture. I found three metabolite clusters (I, II, and III of my interest) after creating a heatmap for four treatment groups (n=5). I want to know how to select only the clustered metabolites for further enrichment analysis. \n\n![Heatmap|442x500, 100%](upload://2CqnI6TU6gb45GDlrNuqeGgUKGL.png)"
    },
    {
        "Question": "How do I select metabolites clustered together in a heatmap and do enrichment analysis on only those selected metabolites?",
        "Answer": "Hi,\n\nThank you for asking this question. In general, enrichment analysis is not available in the \"Statistical Analysis\" module as feature IDs need to be standardized first. \n\n* If your input data type is LC-MS peak intensity table (i.e. untargeted metabolomics), you can indeed perform direct selection on heatmap clusters as you described.  Choose the \"**Functional Analysis**\" module. In the Visual Analytics method (Library View page), select \"Heatmaps\" (see below). You should be able to select clusters on the resulting heatmaps. \n![Screen Shot 2022-07-09 at 3.58.53 PM|690x171](upload://i0S9mRyv2Sv8pkeu8QrtOS5UoEa.png)\n\n* If your input data type is compound concentration table (i.e. targeted metabolomics),  a similar function is available in the \"**Pathway Analysis**\" module. \n![Screen Shot 2022-07-09 at 10.30.13 PM|690x190, 75%](upload://6O3EUCERlKUUaliluEY6AOyNScn.png)\n\n\n* For \"Enrichment Analysis\" module, the support is not available yet (the feature is in our to-do list). At the moment, you can achieve this using two modules:\n  1) In the \"Statistical Analysis\" module, use the \"Heatmaps\" function to identify clusters (you already did this step). Here use the \"**Detail view**\" option and record those compound names in the clusters of interest;\n  2) Upload those compound names to the \"Enrichment Analysis\" module  for enrichment analysis"
    },
    {
        "Question": "Is the data I uploaded to MetaboAnalyst kept confidential?",
        "Answer": "The data files you upload for analysis as well as any analysis results, are not downloaded or examined in any way by the administrators, unless required for system maintenance and troubleshooting. All files are deleted from the server after no more than 72 hours, and no archives or backups are kept. You are advised to download your results as a zip immediately after performing an analysis."
    },
    {
        "Question": "Different Q2 in statistical analysis after update",
        "Answer": "Cross validation involves randomly splitting the data into different groups, for example, 10-fold cross validation splits the data into 10 groups. Then, all groups except for one are used to fit the chosen model, and the final group is used to test the model. This is repeated until every group has been used to test the model (so, 10-fold CV means we repeat this procedure 10 times).  This is useful, because then we can use the results from each prediction to estimate things like model accuracy, etc. \n\nThe results change slightly when you click 'Update' because the very first step (splitting the data into groups) is done randomly, so each time different groupings of the samples are used to train and test the model. If the optimal number of components is changing, for example between 1 and 2, it likely means that the model performance is very similar under these two scenarios, so the one that 'wins' can change depending on the random grouping pattern."
    },
    {
        "Question": "What is single sample profiling (SSP)?",
        "Answer": "Metabolite concentrations in biofluids are tightly regulated through homeostasis under normal physiological condition. For common human biofluids such as blood, urine, or cerebral spinal fluids (CSF), normal concentration ranges are known for many metabolites in clinical settings. Many diagnosis are based on the concentrations of small compounds (i.e. glucose concentration for diabetes)\n\nFor targeted metabolomics (i.e. absolute concentrations), it is often desirable to know whether these compound concentrations from a particular sample are significantly higher or lower compared to their reported normal ranges. For this purpose, we implemented SSP to compare the measured concentrations of compounds to their recorded normal reference ranges. \n\nCompounds that are above or below the normal range beyond a user-specified threshold will then be further investigated using ORA. Please note, SSP is only applicable to human blood, urine and CSF samples, with normal metabolite concentration ranges based on [HMDB biofluids](https://hmdb.ca/biofluids)."
    },
    {
        "Question": "What is vote counting?",
        "Answer": "Vote counting is the most primitive but simplest and most intuitive method of meta-analysis. In this approach, significant features are first selected based on some criteria (e.g. adjusted P < 0.05 and same direction of fold changes) for each data set. \n\nThe vote for each features can then be calculated by counting the total number of times it occurs as significant across all data sets. This method is **statistically inefficient and should be considered as a last resort** in situations when other meta-analysis methods cannot be applied."
    },
    {
        "Question": "Can I use a subset of uploaded data to do raw spectra processing?",
        "Answer": "Yes. You can check or uncheck the corresponding files from **Data Integrity Check** page (See screenshot below).\n\n![image|690x398](upload://wBEdl4th8gtO3YCHDMf0DtSvSRx.png)\n\nBut you have to make sure there are at least **three samples per group** included, otherwise an error message would stop you from proceeding to the next step."
    },
    {
        "Question": "What does the \"Peaks appearing in less than half the samples in each group were ignored\" mean?",
        "Answer": "During peak picking and alignment, a valid peak group should appear in 50% of the data in **at least one group** in order to remain. \n\nThe underlying R code snippet: \n<pre>\n#'@param minfrac, define the minimum fraction of samples necessary in at least one of the sample groups for\n#'it to be a valid group\n#'@param minsamp, define the minimum number of samples necessary in at least one of the sample groups for \n#'it to be a valid group \n\n# minfrac = 0.5, minsamp = 1,\n….\n  # test for each grouped features (i.e. a single peak before alignment) \n  # default require at least half of samples per group\n     if (! any(gcount >= classnum*minfrac & gcount >= minsamp))\n        next # ignore\n...\n<\/pre>"
    },
    {
        "Question": "How are the subnetworks generated from my data from Network Analysis module?",
        "Answer": "Subnetworks are generated by first mapping the genes/metabolites (also known as \"seeds\" or \"baits\" ) to the underlying gene-metabolite-disease interaction database. A search algorithm is then performed to identify and extract first-order neighbours (nodes that **directly** interact with those seeds) to build the subnetworks. \n\nThe above approach will typically return one giant subnetwork (\"continent\") with multiple smaller ones (\"islands\"). Most subsequent analyses are performed on the continent. Note, **networks with less than 3 nodes will be excluded** ."
    },
    {
        "Question": "OUT OF MEMORY error while processing spectra",
        "Answer": "Depending on the data, the optimization process could be memory intensive. The public server is at its capacity these days.  You can try to run locally using the MetaboAnalystR package."
    },
    {
        "Question": "Size of points in scatter plot mummichog and GSEA pathway enrichment analysis/ms peaks to pathways",
        "Answer": "Dear Team,\n\nI was wondering how the size of the points and their colors are calculated when plotting the scatter plot mummichog vs. GSEA?\n\nThis is what I found in an article: The color and size of each circle correspond to its p-value and enrichment factor, respectively. Darker tones indicate more statistically relevant predicted pathways. The size of each dot represents the ratio between significant pathway hits and the expected number of compound hits within the pathways.\n\nSo does the size now correspond to the combined p-value of GSEA and mummichog? and the color of the points as well?or does the size correspond to the ratio of significant hits and total pathway total? \nIt is a bit confusing. \n\nWould be very happy if you could help here."
    },
    {
        "Question": "Size of points in scatter plot mummichog and GSEA pathway enrichment analysis/ms peaks to pathways",
        "Answer": "Indeed, the sizes and colors are both based on the combined p value.  The ratio is not used here as GSEA is a cutoff-free method - there is no definition of significant hits. \n\nOur documentation is a bit outdated - you can see those details from MetaboAnalystR (if you know R)"
    },
    {
        "Question": "How install Meta_Analysis functions in R? (FeatureCorrelationMeta and or PlotMetaCorrHeatmap)",
        "Answer": "Hi,\n\nI' m Trying to use meta-data functions of Metaboanalyst like FeatureCorrelationMeta or PlotCorrHeatmap in MetaboanalystR, but those functions are visible in the [github page](https://rdrr.io/github/xia-lab/MetaboAnalystR/api/), but not in the MetaboAnalystR package installed on R studio( version 3.2.0).\n\nCan someone help me with this issue? there is a particular way to install the github code in R studio? I've yet tried with the commands:\n\n```\ninstall.packages(\"remotes\")\nremotes::install_github(\"xia-lab/MetaboAnalystR\")\n```\n\nwith no results,\n\nThank you fr your time"
    },
    {
        "Question": "How install Meta_Analysis functions in R? (FeatureCorrelationMeta and or PlotMetaCorrHeatmap)",
        "Answer": "I guess the answer to the above question is irrelevant.\n\nHow can we extend the R package functions to meta-analysis?"
    },
    {
        "Question": "How install Meta_Analysis functions in R? (FeatureCorrelationMeta and or PlotMetaCorrHeatmap)",
        "Answer": "There are several options for installing directly from GitHub, detailed on the main MetaboAnalystR GitHub page: [https://github.com/xia-lab/MetaboAnalystR](https://github.com/xia-lab/MetaboAnalystR)\n\nYou must first install main R package dependencies, then install the MetaboAnalyst package from GitHub."
    },
    {
        "Question": "Request to add the three-way ANOVA analysis in the module of \"Statistical Analysis [metadata table]",
        "Answer": "Adapted from a [MetaboAnalystR GitHub post](https://github.com/xia-lab/MetaboAnalystR/issues/242)\n\nIn general, we discourage the usage of traditional statistical methods - they are not suitable for omics data analysis. Some considerations from our perspective: \n\n1) Computationally expensive - when applied to 1000s of features ...\n2) Statistically no well defined for multiple testing adjustment for interactions, post-hoc analysis\n3) Interface design are very complex to support 3-way ANOVA (better do it offline by experienced statisticians)\n\nWe recommend using the **linear modelling (limma)** for flexible multi-factor analysis - available in the Statistical Analysis [metadata] module."
    },
    {
        "Question": "What is the recommended sample size for biomarker analysis?",
        "Answer": "A minimum of 30-40 samples for balanced groups (i.e. at least 15~20 each group) are recommended in order to calculate decent ROC curves and AUC evaluations. \n\n**Note**: for unbalanced data, the algorithm uses Monte Carlo random sampling to produce balanced sub-samples for training data. In this case, the smaller group should have 30~40 samples"
    },
    {
        "Question": "What are the recommended format/analysis for repeated measures?",
        "Answer": "Hi,\n\nI'd also like to know if I the time series + 1 factor is appropriate to use? But  I get an error about missing sample names when I upload. For each genotype I have 2 reps, 2 years of data and then a phenotype whether it was raw or roasted. So I followed the format below. When I did the statistical analysis 1 factor I had to combine factors in the name to have only 1 name- no duplicate names, so I didn't think that analysis was appropriate.\nSample, Phenotype, Time, Subject\n10_7.2019, Raw, 2019, 10_7\n10_7.2019, Raw, 2019, 10_7\n10_7.2019, Roasted, 2019, 10_7\n10_7.2019, Roasted, 2019,10_7\n10_7.2020, Raw, 2020, 10_7\n10_7.2020, Raw, 2020, 10_7\n10_7.2020, Roasted, 2020, 10_7\n10_7.2020, Roasted, 2020, 10_7\n\nThank you!\n\nGina"
    },
    {
        "Question": "Best format/analysis for repeated measures?",
        "Answer": "In the \"Statistical analysis [metadata table]\" module, there is an experimental design called \"Time series + 1 factor\" that sounds appropriate for your data. If you scroll down to the example data on the upload page and click the link for metadata on the third example, you can see the required format (must use these column names).\n\nIf you format in this way, subject will automatically be considered as a repeated measure. Note that the underlaying R package requires a balanced design (same # replicates per experimental group). \n\nAnother option is the \"Multiple factors/covariates\" option. Here, make sure time is a continuous variable on the metadata check page. Then, select \"Linear models with covariate adjustment\". Specify 'Subject' as a blocking factor (this models as a random effect - appropriate for repeated measures on the same person). Now you can view metabolites associated with 'Time' by putting time as primary and 'Treatment' as secondary, or metabolites associated with 'Treatment' by switching them. This is fitting a regression model to the data, then pulling out the coefficients associated with either 'Time' or 'Treatment' (depending on what is designated primary), while controlling for the effects of the other variables. \n\nHopefully this helps, statistical designs start getting complicated with more metadata!"
    },
    {
        "Question": "Heatmap show truncated metabolite names",
        "Answer": "This is unavoidable sometimes when the names are too long - the best way is to use short names or abbreviations like those in publications."
    },
    {
        "Question": "Which adducts are used by the Functional Analysis module by default?",
        "Answer": "For the negative ion mode (**ESI<sup>-<\/sup>**), the adducts used are: M-H[-], M-2H[2-], M(C13)-H[-], M(S34)-H[-], M(Cl37)-H[-], M+Na-2H[-], M+K-2H[-], M-H2O-H[-], M+Cl[-], M+Cl37[-], M+Br[-], M+Br81[-], M+ACN-H[-], M+HCOO[-], M+CH3COO[-], and M-H+O[-].\n\nFor the positive ion mode (**ESI<sup>+<\/sup>**), the adducts used are: M[1+], M+H[1+], M+2H[2+], M+3H[3+], M(C13)+H[1+], M(C13)+2H[2+], M(C13)+3H[3+], M(S34)+H[1+], M(Cl37)+H[1+], M+Na[1+], M+H+Na[2+], M+K[1+], M+H2O+H[1+], M-H2O+H[1+], M-H4O2+H[1+], M-NH3+H[1+], M-CO+H[1+], M-CO2+H[1+], M-HCOOH+H[1+], M+HCOONa[1+], M-HCOONa+H[1+], M+NaCl[1+], M-C3H4O2+H[1+], M+HCOOK[1+], and M-HCOOK+H[1+].\n\nNote, you can use Advanced Options  (see the Fig. below) to refine this list \n\n![Screen Shot 2022-06-13 at 11.58.14 AM|690x122, 50%](upload://54PLp22SOX5eQqTd0AIsRrPqD6C.png)"
    },
    {
        "Question": "What is a power analysis?",
        "Answer": "**Power** is the probability of detecting an effect, given that the effect is really there. For instance, if a study comparing the two groups (control vs. disease) has power of 0.8 and assuming we can conduct the study many times, then 80% of the time, we would get a statistically significant difference between the two groups, while 20% of time we run this experiment, we will not obtain a statistically significant effect, even though there really is an effect in reality. \n\nThere are three major factors:\n\n1. Effect size which is usually defined as the difference of two group means divided by the pooled standard deviation. When all others are equal, a larger the effect size will lead to more power;\n2. Degree of confidence which is usually the p value cutoff (alpha) for statistical significance. When all others are equal, there will be reduced power if we require a very high degree of confidence;\n3. The sample size - more samples will in general increase power. In many cases, the sample size is our interest for a given power (i.e. 0.8).\n\nIn practice, researchers are most interested in knowing the sample size (number of subjects) required in order to obtain sufficient power."
    },
    {
        "Question": "Can I delete certain nodes from the network?",
        "Answer": "Yes, you can delete nodes (and their associated edges) from the current network. \n\n* First you need to select the nodes using checkbox from the **Node Table** in the left pane. \n\n* Then click the **Delete** button at the top of the node table. A confirmation dialog will appear asking if you really want to delete these nodes. \n\nNote, this action will trigger network re-arrangement, especially if hub nodes are removed. In addition, \"orphan\" nodes may be produced due to removal. These nodes will also be excluded during re-arrangement."
    },
    {
        "Question": "Can I perform enrichment analysis on my selected genes/metabolites in the network?",
        "Answer": "Yes. For query metabolites, you can test enriched KEGG pathways. For query genes only, you can test enriched Gene Ontologies or pathways (KEGG/Reactome). \n\nThere are three steps (please refer to the Fig. below)\n\n1) Click the \"Reset\" icon ![reset|25x24, 75%](upload://evVcbxbnXpVkliFDFEXY9eANOqX.png) in the network tool bar to make sure no nodes are highlighted in the current network\n\n2) Highlight nodes based on your interest using one of the three methods:\na) Use the checkboxes in the Node Table on the left; Or\nb) Use the free select icon ![lasso|200x200, 10%](upload://4qhv2im3CRzxAUlM1C4xFxXucOj.png) to drag-select nodes directly on the network; Or\nc) Entering a list of node IDs to the text box in the \"Batch Selection\" panel on the right side\n\n3) After that, select a functional catergory from the Function Explorer section, make sure the <b>Query<\/b> option is set to <b>Highlighted Nodes<\/b> and click the **Submit** button.\n\n![Screen Shot 2022-06-12 at 10.09.06 PM|690x329](upload://wFpJ7j4QekHaiUTIwZK8LZkYayt.png)"
    },
    {
        "Question": "How do I interpret the differences in node colors and sizes in the default network?",
        "Answer": "In the default network generated by *MetaboAnalyst*, the **size** of the nodes are based on their **degree values**, with a big size for large degree values. \n\nThe **color** of nodes are based on\n* Node type (distinct colors are applied for genes, metabolites or disease nodes)\n* Node betweenness centrality values (different gradients within each node type).\n* When user switches to Expression View, the color will be based on their expression values (if available)."
    },
    {
        "Question": "How to extract the top n features from heatmap",
        "Answer": "Next to the 'Use top' text input is a dropdown where you can select the method. These are all other tools within the 'Single Factor analysis' module - you can simply perform this other analysis and download the results table."
    },
    {
        "Question": "How to extract the top n features from heatmap",
        "Answer": "Dear support team,\nI have used the one factor statistics analysis function to do the heatmap analysis. And I used top 500 features, to obtain a good clustering. How can I get the list of the features I used? Record one by one in detail view is so difficult for me because the large number of features.\nThank you so much for your support! I am looking forward to hearing from you,\n\nBest, Anne"
    },
    {
        "Question": "How ANOVA post-hoc analysis is computed in MetaboAnalyst?",
        "Answer": "Post-hoc is calculated literally as described - for each of the significant features, do LSD. If their **raw p values** are lower than 0.05, report them. No p-values are reported for post-hoc, as they are not well defined and misleading."
    },
    {
        "Question": "How does MetaboAnalyst compute power for metabolomics data?",
        "Answer": "In general, it is inappropriate to directly apply the traditional univariate approach on power analysis to omics datasets which are characterized by high dimensions with 100s to 1000s of features and a relative small number of samples. \n\nThe power analysis in MetaboAnalyst is based on the R package [SSPA](http://www.bioconductor.org/packages/release/bioc/html/SSPA.html) that was originally developed for power calculation for gene expression datasets. For a given pilot data, the method estimates **the average power for a given false discovery rate**. For more details, please refer to the original publication by [M van Iterson et al](http://www.biomedcentral.com/1471-2164/10/439)"
    },
    {
        "Question": "How does MetaboAnalyst deal with over-fitting in biomarker analysis?",
        "Answer": "In multivariate exploratory ROC analysis, MetaboAnalyst uses **repeated, balanced sub-sampling cross validation (CV)** to test the performance of models created with different number of features. At each CV, 2/3 samples are used for feature selection and model training and the remaining 1/3 of samples are used for testing. The procedures are repeated 50 times in order to produce a more stable estimation. \n\nIn ROC Tester, MetaboAnalyst also provides **permutation tests** to calculate the significance of the biomarker model by comparing with those obtained based on data with shuffled group labels.\n\nPlease note, there are no CV nor permutation tests used in classical univariate ROC curve analysis - the AUROC is mainly for biomarker potential (i.e. ranking), and should not be used as prediction performance."
    },
    {
        "Question": "What is BMD and mPoD?",
        "Answer": "Dose response analysis is conducted at multiple concentrations of a chemical. Metabolomics data are measured in each sample, and a suite of non-linear curves are fit to the levels of each metablomics feature. The best fitted curve is analyzed to compute a feature-level benchmark dose (BMD), which is the minimum concentration of a substance that produces a clear, low level health risk relative to the control group.\n\nThe mPoD or metabolomic-level point-of-departures is estimated based on the distribution of BMD values of the metabolic features. Three values are offered -  the BMD value of 20th feature, the 10th percentile, or the most frequent BMD of the 1st curve. This follows  the common practice in transcriptomics (tPOD). The result is presented graphically (see an example below)\n\n![Screenshot 2024-03-11 at 8.29.18 PM|676x500, 75%](upload://uDXSCWSUu8oGf2MVtrvmw993Wsd.jpeg)"
    },
    {
        "Question": "What does MFN stand for?",
        "Answer": "Hello, \n\nWe used Metaboanalyst Peaks to Paths module with the Human [MFN] database for a recently accepted publication. The journal wants us to include the expansion for \"MFN\". Does this stand for \"MetaFishNet\" (from this reference: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3156954/)? \n\nThank you!"
    },
    {
        "Question": "Support Vector Machine (SVM) error - important features sort just by order, without any sorting?",
        "Answer": "This just means that all these features have equal chances to be selected by the model. No features are more important than others. This happens when many features are redundant (i.e. providing equivalent information for classification), such as in untargeted metabolomics data"
    },
    {
        "Question": "Which currency metabolites are removed by the Functional Analysis module by default?",
        "Answer": "By default, the **Functional Analysis** module considers these metabolites as **currency**: 'C00001', 'C00080', 'C00007', 'C00006', 'C00005', 'C00003', 'C00004', 'C00002', 'C00013', 'C00008', 'C00009', 'C00011', 'G11113', 'H2O', 'H+', 'Oxygen', 'NADP+', 'NADPH', 'NAD+', 'NADH', 'ATP', 'Pyrophosphate', 'ADP', 'Orthophosphate', and 'CO2'.\n\nNote, you can use Advanced Options  (see the Fig. below) to refine this list \n\n![Screen Shot 2022-06-13 at 11.58.14 AM|690x122, 50%](upload://54PLp22SOX5eQqTd0AIsRrPqD6C.png)"
    },
    {
        "Question": "How do I identify important nodes in network analysis?",
        "Answer": "Important nodes can be identified based on their position within the network. The assumption is that changes in the key positions of a network will have more impact on the network than changes on marginal or relatively isolated positions. \n\n*MetaboAnalyst* provides two well-established node centrality measures to estimate node importance - **degree centrality** and **betweenness centrality**. \n\nIn a graph network, the degree of a node is the number of connections it has to other nodes. Nodes with higher node degree act as hubs in a network. The betweenness centrality measures the number of shortest paths going through the node. It takes into consideration the global network structure. \n\nFor example, nodes that occur between two dense clusters will have a high betweenness centrality even if their degree centrality values are not high. Note, you can **sort the node table** based on either degree or betweenness values by double clicking the corresponding column header."
    },
    {
        "Question": "Time-series + one experimental factor",
        "Answer": "Hello，I have two groups and two time-points. The blood was collected at two time-points from each individual.  I want to use time-series + one experimental factor to do the analysis. But there is unknown error when I use this. I want to ask if time-series + one experimental factor is fit to our data which have only two time-points? If it is not fit, which analysis could I use to analyze out data? Thank you very much!"
    },
    {
        "Question": "Can I view all the metabolite/gene members of a pathway within the current graph?",
        "Answer": "Yes, after you have performed functional enrichment analysis, the over-represented themes will be displayed in the table below. By **double clicking** on a pathway name, all metabolite/gene members of the pathway will be displayed as highlighted nodes within the current network."
    },
    {
        "Question": "Missing samples in repeated measures",
        "Answer": "I have a project where I am analyzing fecal metabolomics from animals. I have repeated samples (7 time points) from two treatment groups. Some of the animals did not produce feces at all time points. Is it possible to analyze this data set including all individuals, including those that have individuals with missing at random (MAR) samples?\n\nI am getting error messages when I try to input this data in metabolanlyst with a metadata table."
    },
    {
        "Question": "How to import mouse gene data to Network analysis?",
        "Answer": "Even after converting DEGs obtained from RNA-seq data of mouse tissues into KEGG identifiers using the KEGG Mapper, MetaboAnalyst fails to recognize the KEGG identifiers. When searching on Google, it seems that there are no issues with KEGG identifiers. Have any users of MetaboAnalyst encountered similar problems when analyzing non-human data, apart from human data?\n![image|690x165](upload://ugilUGgExJLqOc3mOVwced9Gu4E.png)"
    },
    {
        "Question": "After normalization, the document shows that the variety of compounds decreases",
        "Answer": "After normalization, check the normalization document. The type of compound input has changed from 1000 to 600. Why? Thank you"
    },
    {
        "Question": "Missing value estimation - exlude variables with missing values",
        "Answer": "Hello, \nI would like to ask you if in the 'statistical analysis (one factor)' --> Missing value estimation --> Step 2. Estimate the remaining missing values --> Exclude variables with missing values\nIs the term **variable**  used for a metabolite? Because on step 1 metabolites are stated as features and after doing exactly the same analysis once choosing 'exlude variables with missing values' and once 'Replace by LoDs (1/5 of the minimum positive value of each variable)' I found that on the first case I miss many metabolites, as wou can see in the pictures\nThanks a lot!\n![image|689x454](upload://cG3iWPRkKyHVR1sDam5oYPbaKiR.png)\n![image|628x500](upload://yafhYnjHwv0UkB96Ef8DNV0y0bu.png)"
    },
    {
        "Question": "Missing value estimation - exlude variables with missing values",
        "Answer": "In your data table, there are three key information\n1) Class labels or metadata\n2) Sample IDs\n3) Sample descriptors:  metabolites/genes/proteins (used biological context), or features/variables (used in statistical context) or for untargeted metabolomics"
    },
    {
        "Question": "How should I interpret a volcano-like plot from GSEA analysis (Functional Analysis module)",
        "Answer": "Indeed, we use volcano plot as a visual summary of the GSEA result (based on its p values and NES). I guess your question is on how to interpret NES?  I would refer you to [the GSEA website](https://www.genepattern.org/modules/docs/GSEA/14#gsc.tab=0).  Here genes are replaced by putative metabolites"
    },
    {
        "Question": "How should I interpret a volcano-like plot from GSEA analysis (Functional Analysis module)",
        "Answer": "Enrichment score can be positive or negative. Positive scores mean the pathway hits tend to be on the top half of the ranked list, while negative means the hits end to be at the bottom half. Note negative is not meaningful (interpretable) if you use p-values for ranking\n\nNote we don't recommend GSEA - it is well-established but lacks power - see our publication \"[Comprehensive investigation of pathway enrichment methods for functional interpretation of LC–MS global metabolomics data](https://doi.org/10.1093/bib/bbac553)\""
    },
    {
        "Question": "How should I interpret a volcano-like plot from GSEA analysis (Functional Analysis module)",
        "Answer": "Hello all, I am using a GSEA approach to run pathway analysis on my metabolomics data. this analysis produces the plot that reminds me a volcano plot with pathways arranged according to their p-value on the y-axis and NES on the x-axis. On this plot NES (i.e. enrichment scores) can be negative or positive. How is this determined? How should I interpret this plot?\n\nBest,\nLisa\n[ZA17_DH_GESA.pdf|attachment](upload://roOZ13d09gtdw88aPB2j7w7tbuz.pdf) (111.2 KB)"
    },
    {
        "Question": "How should I interpret a volcano-like plot from GSEA analysis (Functional Analysis module)",
        "Answer": "Dear Jeff\n\nThe [GSEA website](https://www.gsea-msigdb.org/gsea/doc/GSEAUserGuideTEXT.htm) explains that the NES is computed as a ratio of experimental Enrichment Score and  mean of ESs against all permutations\n\nI am unclear on how a NES could be a negative value, as both numerator and denominator of that ratio are both positive values?\n\nI found no example on the GSEA website of negative ES or NES. I probably missed something?\n\nRegards"
    },
    {
        "Question": "Is it possible to save my current biomarker models for predicting future samples?",
        "Answer": "This is clearly doable and we intend to add the feature in the near future. You will need to register in order to save and reuse the biomarker models next time, as uploading a model (executable code) to our server is too risky. \n\nPlease note if your data is not too big, when your future samples are ready, you can [combine all samples for prediction](https://www.omicsforum.ca/t/can-i-predict-class-labels-for-new-samples/680).  This could reduce potential batch effects which negatively impact most biomarker models performance. \n\nWhen you have sufficient data, the best practice to have clean separation of training and testing datasets (including the pre-processing stage). Please refer to this excellent paper on [common pitfalls using machine learning methods for prediction]( https://doi.org/10.48550/arXiv.2207.07048)."
    },
    {
        "Question": "Can I predict class labels for new samples?",
        "Answer": "Yes, the Biomarker Model allows users to predict new samples (unlabeled samples). \n\nTo do this, you need to combine both labeled and unlabeled samples into **a single data table**. Upload the table to the Biomarker Module so that these samples will be processed together.  At the 'ROC Analysis Option' page, make sure you select the **Tester** track (see below)\n\n![Screen Shot 2022-07-27 at 3.48.41 PM|690x123](upload://ifvI59cdHclK3SA1ssRsODZAKrU.png)\n\nMetaboAnalyst will create model (using the labeled data) to predict unlabeled data."
    },
    {
        "Question": "Nature of the Metabolomic Input Clean file",
        "Answer": "Hello,\nWhen using the raw MS data processing, there are two peaks table (excel files) generated at the end of the process : metaboanalyst_input and metaboanalyst_input_clean.\nCould you please explain what is the difference between both files and what filter is used ?\nKind regards\nOlivier"
    },
    {
        "Question": "Which database is used for creating the gene-metabolite-disease network?",
        "Answer": "*MetaboAnalyst* uses a comprehensive gene-metabolite-disease interaction data based on [MetPriCNet](https://www.nature.com/articles/srep17201). The data contains interaction data mainly extracted from published literature. \n\nThe database currently contains 11,502 genes, 1,900 metabolites, 132 diseases making a total of 139570, 519, and 78200 interactions for gene-metabolite, metabolite-disease and metabolite-metabolite networks respectively in human. \n\nThe gene-chemical and chemical-chemical associations for the gene-metabolite and metabolite-metabolite networks, respectively, were extracted from STITCH, such that only highly confident interactions are used. \n\nMost of associations in **STITCH** are based on co-mentions highlighted in PubMed abstracts including reactions from similar chemical structures and similar molecular activities. The associations for the metabolite-disease network were obtained from HMDB. \n\nDisease association have been added to HMDB via the Human Metabolome Project’s literature curation team. The Metabolite-Gene-Disease network is an integration of gene-metabolite, metabolite-disease and gene-disease interaction networks."
    },
    {
        "Question": "How are the top 5000 features chosen during Data Filtering?",
        "Answer": "I have a dataset with more than 5000 features and was wondering: how is the data limited to 5000 features during data filtering? \n\nI've seen in the \"Can I perform PCA using all features (i.e. not filtered to a max. of 5000)?\" post that a chosen ranking method is used. What is this method? If I input my data with over 5000 features and click the \"None\" option for data filtering, how are those 5000 features chosen?\n\nThanks"
    },
    {
        "Question": "How are the top 5000 features chosen during Data Filtering?",
        "Answer": "We have provided the details and reasoning in the \"Data Filtering\" page.  Your question is covered in the last sentence (see below)\n\n![Screen Shot 2022-08-02 at 5.39.11 PM|690x104](upload://vNlSosJrpWzA0iCwGrSoDbTa5Lh.png)"
    },
    {
        "Question": "PLS-DA components",
        "Answer": "In some cases the %variance values for the 3D PLS-DA plot is not in descending order of the orthogonal components. For example component 3's % is larger than component 2 (see example). Shouldn't the %var explained decrease for each additional component?\n![PLSDA|382x297](upload://yK2ESvBXSdIoz3bXAvFadLhjImK.jpeg)"
    },
    {
        "Question": "PLS-DA components",
        "Answer": "Yes, it is possible. The issue is discussed in [this post](https://omicsforum.ca/t/why-in-sometimes-the-1st-component-explains-less-variance-than-the-2nd-component-in-pls-da/663)"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "**Pathway/Enrichment analysis is NOT dependent on whether the compounds exist in current HMDB. It depends on whether the compounds are included in our pathway libraries.** The compound annotation in MetaboAnalyst is for pathway analysis, not for general purpose HMDB compound annotation. All compounds defined in our pathway libraries will be annotated. If they are not recognized (even they have valid HMDB IDs), there will be no effect on the results.    \n\nThe information is stated in the compound mapping result table (see below)\n![Screen Shot 2022-12-29 at 3.05.44 PM|690x64](upload://f3AiWZiPjyt9HOLYNmP7E6jIawG.png)"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "Hi Zhiqiang and Guoliang,\nwe struggle with the same issue (we loose a lot of metabolites for pathway analyses because they are not recognized by neither their name or HMDB ID). On the Metaboanalyst website we found that the last update based on HMDB releases took place almost five years ago (v4.0). Is there any way of mapping the metabolites to the most recent HMDB release to achieve higher coverage of metabolites for pathway analyses?\nTHANKS so much,\nSteffen"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "Please be aware that compound annotation results have very **little**  effect on the downstream pathway analysis in MetaboAnalyst.  All compounds covered by our pathways or metabolite sets will be annotated. During analysis, the background \"universe\" is defined by those compounds in pathways or metabolite sets. Adding new compounds (recognized or not) will not affect the result.  **The main factor here is not compound annotation, it is pathway annotation**. Our pathway libraries were updated in late 2021."
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "Hi Guoliang,\n\nThanks for your description on your question. Let's be brief. You are using Enrichment Analysis module, right? Can you convert your compound name into KEGG ID or HMDB ID for better recognication? This is the best approach recommended to incease the coverage.\n\nBased on your description, you have tried to use self-defined database? Have you defined the database correctly according to the template format? Can you share the database and your data for further checking?\n\nCheers,\nZhiqiang Pang"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "Dear Jeff and Connor,\n\nthanks so much for your responses and helping to try to solve our problem. Please excuse my delayed response. Our original assumption was that the pathway annotations are linked to the HMDB annotation, which is, following your response Jeff, not the case. Our \"problem\" of loosing one third of measured metabolites for the pathway analyses persists but my understanding is that these might then hopefully be not the most functionally important metabolites.\n\nThanks again and best wishes for the new year,\nSteffen"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "\nHello,\n\nI used MetaboAnalyst 5.0 to analyze data generated using the Biocrate MxP kit. We have 8 wildtype samples and 8 knockout samples.\nI uploaded the .csv file containing ~630 metabolites quantified using the Biocrate MxP kit (for ease of reference in this post, this .csv file is called \"file_1\". There were more than 100 metabolites not recognized by the MetaboAnalyst 5.0 database. As a result, these 100 metabolites were excluded by MetaboAnalyst 5.0 in the subsequent KEGG pathway analysis. \nTo reintroduce these 100 metabolites to MetaboAnalyst 5.0, I manually added these unrecognized metabolites to KEGG .csv file following the instruction of MetaboAnalyst 5.0 (i.e., add metabolite1; metabolite2; ... to the 2nd column of this KEGG .csv file).  \n\nLater, I found that if a metabolite in file_1 was unrecognized by the MetaboAnalyst 5.0 database, even if I manually added this metabolite to the KEGG dataset, this manual editing did not change the result of pathway enrichment.\n\nFor example, the metabolite \"Hydroxyglutaric acid\" in my file_1 was not recognized by the MetaboAnalyst 5.0 database. I added \"Hydroxyglutaric acid\" to the KEGG dataset (either to an already existing pathway, or a newly created pathway in the KEGG dataset.csv file). Adding it to an already existing pathway did not change the enrichment ratio or p value of this existing pathway. We also created a new pathway containing  \"Hydroxyglutaric acid\" and several other metabolites unmapped to MetaboAnalyst 5.0. All the metabolites defined in this new pathway exist in our file_1, so we expected the enrichment ratio of this newly created pathway to be 100%, but it was 0%. \n\nBesides \"Hydroxyglutaric acid\", I have tried multiple metabolites that were neglected by the MetaboAnalyst 5.0 database and results were the same.\n\nHaving said so much, my question is that, is there a way not to exclude the unmapped metabolites from the final KEGG pathway enrichment analysis?\n\nThanks!\nGuoliang Cui"
    },
    {
        "Question": "Metabolites unrecognized by MetaboAnalyst 5.0 were excluded from the subsequent customized KEGG pathway analysis",
        "Answer": "Hi Jeff, \n\nI'm not quite sure I understand your answer in the context of the question, but perhaps I am misunderstanding the issue. It sounds like they have compounds which exist in the current HMDB that are not being recognized and are thus being excluded from the pathway analysis, e.g. it's not recognizing hydroxyglutarate as an input and thus it's not being considered during pathway analysis."
    },
    {
        "Question": "How does enrichment analysis work in network analysis?",
        "Answer": "The enrichment analysis is to test whether any pathways or metabolite/gene sets (defined within the user selected library) are significantly enriched among the currently highlighted nodes within the network. *MetaboAnalyst* uses **hypergeometric tests** to compute the enrichment p values."
    },
    {
        "Question": "Why does the result change slightly each time I re-do the biomarker analysis?",
        "Answer": "The algorithm uses repeated random sub-sampling cross validation (CV) to evaluate the feature importance as well as to test the performance of different models. Every time when user click the \"Submit\" button to re-do the analysis, a new random sampling will be generated. Therefore, the results would be only slightly different. This is the intended behavior, users should looking for the \"stable core\" for more robust results. The procedure is computationally intensive and the following rules are used to control the time and resources based on the sample size:\n  * < 100 samples: **50 repeats**\n  * 100 - 200 samples: **30 repeats**\n  * 200 - 500 samples: **20 repeats**\n  * \\> 500 samples: **10 repeats**\n\nTwo other factors can also affect the degree of variation - sample size and presence of outliers. If the sample size is small, the training and testing tend to have high variations. The outliers can also affect the results. Due to the nature of repeated sampling in each CV, some samples may be used multiple times and some samples may never be used. If the outlier samples are used imbalanced (i.e. never been used in the first analysis but used multiple times in the subsequent analysis), the result could change more than \"slightly\"."
    },
    {
        "Question": "Unable to complete spectral processing due to Out of Memory error",
        "Answer": "This means your job requires more computing resource than allocated for the public users. You can either subscribe to the pro version or do it locally using MetaboAnalystR."
    },
    {
        "Question": "Unable to complete spectral processing due to Out of Memory error",
        "Answer": "This literally means that the memory required to process your data exceeds the default allocation.  We do offer “Pro” version with double memory allocation for raw data processing. You can visit the link on top of the OmicsForum"
    },
    {
        "Question": "ANOVA posthoc Function not found",
        "Answer": "Dear MetaboAnalyst Team,\n\nI hope this message finds you well. I have previously used MetaboAnalystR (version 3.2).\n\nRecently, I installed the new MetaboAnalyst 4.00 and encountered the following error while using it:\n\nmSet <- Calculate.ANOVA.posthoc(mSet, \"tukey\", 0.05)\nError in Calculate.ANOVA.posthoc(mSet, \"tukey\", 0.05) : \ncould not find function \"Calculate.ANOVA.posthoc\"\n\n\nThe above script was copied from the browser version (MetaboAnalyst 6.0). Is the function Calculate.ANOVA.posthoc(mSet, \"tukey\", 0.05) only available in the browser version? I believe that the previous browser version of MetaboAnalyst did not have the functionality to separate ANOVA P values and Posthoc P values. Is this a new feature from version 6.0? And is it not available in MetaboAnalystR?\n\nThank you for your assistance."
    },
    {
        "Question": "Image not displaying after personalization of colors in PCA and Heatmap",
        "Answer": "After I edit colors/marker style, both the PCA plot and heatmap do not display the correct image or do not display the image at all. I tried downloading the image with the paint icon and an error comes up:\n**type** Status report\n\n**message**Not Found\n\n**description**The requested resource is not available."
    },
    {
        "Question": "How to interpret the metabolic network visualization in functional analysis module?",
        "Answer": "The metabolic network visualization is based on the **KEGG** global metabolic network and has been manually curated. It aims to provide a global metabolic context for the significantly enriched mapped metabolites, as well as provide an in-house option for visual exploration of the results from the untargeted pathway analysis. \n\nUsers can click on a pathway name from the left panel to view all matched compounds within this network (see the Fig. below). <b>Empty circles<\/b> indicate the compounds are detected but insignificant; <b>Solid circles<\/b> indicate the compounds are detected and significant. <b>Double click<\/b> on those matched node will show all peaks assigned to this compounds (i.e. empirical evidence)\n\n![Screen Shot 2022-06-12 at 5.26.30 PM|690x325, 100%](upload://1TMqqwHURWmKCzlZP7EP49Sah6t.jpeg)\n\nUsers have the option to colour each specific pathway to their own preference, change the background colour, switch the view style, and download the image as a *PNG* or *SVG* file."
    },
    {
        "Question": "LC-MS raw data processing - MS-MS import error",
        "Answer": "Hi,\n\nI am trying to process LC-MS data but I am experiencing issues with MS2 spectra: \n![image|505x500](upload://5bYOEftP80ku2M5PQWIwCPbotdt.png)\nThis shows every time my data set includes MS2 spectra - regardless of the setting. \nThe spectra are DDA, positive mode, UHPLC Q-TOF.\nThank you very much in advance."
    },
    {
        "Question": "Does MetaboAnalysis 5.0 provide covariates (ANCOVA) analyses",
        "Answer": "Does MetaboAnalysis 5.0 provide covariates (ANCOVA) analyses with age, gender, BMI, etc.?\nIf it does, how can I input those covariates data online, or should I use other software in the OmiscForum with the R program?\n\nI look forward to hearing from you."
    },
    {
        "Question": "Does MetaboAnalysis 5.0 provide covariates (ANCOVA) analyses",
        "Answer": "You can try our latest Nature protocol \"[Using MetaboAnalyst 5.0 for LC–HRMS spectra processing, multi-omics integration and **covariate adjustment** of global metabolomics data](https://www.nature.com/articles/s41596-022-00710-w)\" to see if it addresses your needs"
    },
    {
        "Question": "What is a metabolite set?",
        "Answer": "A metabolite set can be any externally defined groups of metabolites that has something in common. For example,\n\n* Metabolites that are involved in the same pathways (SMPDB, KEGG, Biocarta);\n* Metabolites that are changed significantly under the same conditions;\n* Metabolites that are associated with the genomic variations (i.e. single nucleotide polymorphism or SNPs);\n* Metabolites that are located in the same cellular compartments;\n* Other published metabolite signatures, ontology terms, *etc.*\n\nPlease note that you can define your own metabolite set for functional enrichment analysis using MSEA."
    },
    {
        "Question": "Are there some tutorials to introduce the main features of each module in MetaboAnalyst?",
        "Answer": "Our [latest tutorials can be found here](https://www.metaboanalyst.ca/docs/Tutorials.xhtml). A screenshot of the topics are shown below: \n\n![Screen Shot 2022-10-04 at 7.23.10 AM|690x286](upload://9HqE6jc0kefrB6uoniNP4gu1nLC.png)\n\nPlease note, due to frequent updates of MetaboAnalyst, many screenshot illustrations are outdated. Therefore, we ask that users do not take those steps verbatim. Instead, users should focus on the the analysis concepts and the workflow for metabolomics data analysis using this tool."
    },
    {
        "Question": "Unable to use Generate Report in Download section of Functional Analysis",
        "Answer": "Hi ,\nI am performing Functional analysis in mixed mode, with RT in seconds, and pvalues. I get the results as well. when I go to Download section to download report and zip folder, it only allows me to download zip folder of the results but doesn't generate report.\nCan someone help me with it."
    },
    {
        "Question": "Kruskal Wallis does not perform post hoc analysis",
        "Answer": "This is stated on the ANOVA page:\n\n\"You can choose to perform one-way ANOVA or its non-parametric version (Kruskal Wallis Test). The post-hoc tests have only been implemented for parametric ANOVA.\""
    },
    {
        "Question": "How I can see the boxplots of significant features in the t-test?",
        "Answer": "I see there are empty spaces after every  feature names - they cannot be recognized properly by computer.  It is  also not a good practice to use numbers as feature names"
    },
    {
        "Question": "How should I select metabolites for Metabolite set enrichment analysis (MSEA) input",
        "Answer": "There is no hard rules here. MSEA aims to find enriched functional themes from a list of metabolites, and it is up to you to define the list (as long as you can justify). In this case, ANOVA or VIP are both reasonable. \n\nFor exploratory analysis, you should try both -  they are different methods (univariate vs multivariate) and may yield complementary insights. Keep in mind that enrichment analysis is to detect function or group behavior - a good number of signficant features are essential (i.e. it is impossible to pinpoint a pathway with just one or two hits)."
    },
    {
        "Question": "How could I download the full MFN database?",
        "Answer": "I would assume you are using MetaboAnalystR: if you perform analysis using MFN, a copy of the library (hsa_mfn.qs) will be saved in your local directory. You can inspect it using RStudio.  Note this is not possible using web interface which is not designed for such purpose."
    },
    {
        "Question": "Corrections for MetaboAnalystR directions and a question about the functionality of Covariate Analysis",
        "Answer": "Please see the linked comment on this thread, from the creator of the limma package: https://support.bioconductor.org/p/128516/#128548 \n\nBasically, for a categorical metadata, ~x and ~ 0 + x are the exact same model. For continuous metadata, these are very different models. Explicitly setting the intercept to 0 forces the fitted linear model through the origin, which is usually not a reasonable assumption and causes weird results (ie. 100% of features are called differentially expressed, or all p-values are virtually identical). \n\nMetaboAnalyst was originally designed for only categorical metadata, and so the formula didn't matter. When we expanded it to accept continuous values, we added this exception after testing datasets with only continuous values and getting bad results. The if/else condition is really redundant: since ~x and ~ 0 + x are the same for categorical, we can use the second implementation for everything. It's been simplified in some of our other tools, we just haven't updated MetaboAnalystR yet."
    },
    {
        "Question": "Corrections for MetaboAnalystR directions and a question about the functionality of Covariate Analysis",
        "Answer": "I would also add - the intercept vs. no intercept gives the exact same model as long as you have at least one categorical metadata. This isn't true in some other linear model R packages, I think its specific to limma."
    },
    {
        "Question": "How to use and interpret the meta-data overview (Statistics [metadata table])?",
        "Answer": "The meta-data overview page gives a chance to understand relationships between different meta-data variables. This is an important part of downstream analyses - if some metadata are highly correlated, it can impact the stability of coefficient estimation during linear modeling, and can influence your choice of which variables to include in the final model.\n\nThe \"Meta-data Heatmap\" and the \"Correlation Heatmap\" both show relationships between metadata variables. The Meta-data Heatmap (see a Fig. below) shows actual meta-data values and allows more flexible clustering options while the Correlation Heatmap summarizes relationships with pairwise correlation coefficients.\n\n![Screen Shot 2022-06-14 at 9.53.16 AM|456x500](upload://5dVEoJyrDgTKEhWFcr0OCQot6rr.png)"
    },
    {
        "Question": "Data for lipids and metabolites",
        "Answer": "Good question! Directly merging the data is usually not a good idea as difference in the scale could make one dataset dominate the analysis. For instance, PCA is sensitive to large values in the data\n\nHere are some thoughts:\n\n1) If the main concern is difference in units/scale, you can perform normalization / scaling on each data and then combine them\n2) For biomarker analysis, it is possible that integrating features from both lipids and metabolites could improve the performance\n3) More features (same number of samples) could introduce more noises and lower statistical power (high false positives) \n\nMaybe explore both ways (individually and then combined) then let us know your findings!"
    },
    {
        "Question": "Data for lipids and metabolites",
        "Answer": "I have data for both lipids concetrations and metabolites concetrations, which are in different scale and units, for example metabolites' concetrations are in mmol/L and lipids are in mg/dL.\nIs it better to run two different analyses, one for the lipids alone and one for metabolites alone, or can I run one analysis for all of my data? And why? Is it because of the units or is better to run those compounds in seperate analysis?"
    },
    {
        "Question": "Does MetaboAnalyst use training and testing data in their PLS-DA analysis?",
        "Answer": "Thanks so much for getting back to me and for your advice!"
    },
    {
        "Question": "Does MetaboAnalyst use training and testing data in their PLS-DA analysis?",
        "Answer": "They are different concepts and for different application purposes.\n\nCross validation is a way to detect overfitting in classification tasks (together with Permutation). Its main application is when you would like to use the PLS-DA model for classification tasks. In MetaboAnalyst, its outputs include Q2 and Accuracy. For permutation, it is empirical p value\n\nScores and loading are visualization techniques to help understand the top components identified in PLS-DA model. Although it is possible to do scores and loading is each CV. It is rarely useful in this case. \n\nFinally, classification task requires a large number of samples. When you have very few samples, say, less than 12, I would suggest to focus on simpler methods, i.e. t-tests/ANOVA, PCA, heatmaps, etc"
    },
    {
        "Question": "Does MetaboAnalyst use training and testing data in their PLS-DA analysis?",
        "Answer": "Hi, \n\nFor many demonstrations of PLS-DA analyses I see online, they show models initially being created with training data which are then used to fit test data. I found some information about how MetaboAnalyst performs their PLS-DA [here](https://www.uab.edu/proteomics/pdf_files/2015/Analysis_Report.pdf), though I would like to clarify if the data is split this way at all? Especially for the scores , loadings, and important features sections? \n\nMany thanks!"
    },
    {
        "Question": "What types of MS instrumentation are supported in spectral processing and functional analysis?",
        "Answer": "Most functions we developed are benchmarked against MS instruments commonly employed in current untargeted metabolomics, namely **high-resolution MS** (such as Orbitrap, ToF or other Fourier transform mass spectrometry family). The high mass resolution can significantly improve peak annotation and pathway activity predictions."
    },
    {
        "Question": "Heatmap Clustering",
        "Answer": "Hello,\nMy statistical analysis is about time-series + one factor (5-time points, one control and one test group-4 subjects/group). When I generate the heatmap, I get mixed clustering where phenotype and time and subject gets mixed. How can I separate them? Meaning how can I have a representation of the metabolites for phenotype and time 1 (4 subjects/group), phenotype and time 2 (4 subjects/group), etc without showing each subject individually? That type of heat map would provide a better illustration of the correlations of each metabolite for each time point per phenotype.\nI hope someone can answer my question soon.\nThank you."
    },
    {
        "Question": "Time-series + one factor analysis unknown error",
        "Answer": "I believe I have placed my data in the correct format for Time-series + one factor analysis. The data  processes OK but when I click proceed I am given an unknown error message. Can anyone help? I have uploaded the metadata file and the dataset file. \n\n[Meta-data test.csv|attachment](upload://3C6lChuyu1C4TevvsuwEI8ueN9N.csv) (2.3 KB)\n[Dataset.csv|attachment](upload://shEcav3j4n1LKQM9S24ETTH7WCI.csv) (121.0 KB)"
    },
    {
        "Question": "How can metaboanalyst calculate PCA distance?",
        "Answer": "I got an normalized data from metaboanalyst web server and used it my code which generate PCA graph to obtain p-value.  my code calculate PCA distance using \"euclidean\". \nhow can I implement PCA graph like generated from metaboanalyst web server ?"
    },
    {
        "Question": "Similar Programs to Metaboanalyst for RT-PCR Data",
        "Answer": "Hi, does anyone know of any free software similar to Metaboanalyst for RT-PCR? I currently have a table containing the cycle thresholds for the RT-PCR from patient samples correlated to clinical data, and I wish to perform further analysis on it. Could a kind soul point me towards any software that can help accomplish the task? Thanks in advance!"
    },
    {
        "Question": "MSEA and QEA for peak intensity table",
        "Answer": "Hi, \n\nCan I do quantitative enrichment analysis for untargeted lipidomics data, I mean I won't have concentrations,  it is only normalized peak intensities/intensity ratios for identified/annotated peaks? if no, then what alternative do I have? is it only ORA?\n\nI have seen some papers use this function with peak areas but I am not sure if this is correct or not. \n\nCan you advise please?\n\nThanks"
    },
    {
        "Question": "MSEA and QEA for peak intensity table",
        "Answer": "I would suggest to read our recent publications on this topic:\n* Lu, Y., Pang, Z., and Xia, J. (2023) [Comprehensive investigation of pathway enrichment methods for functional interpretation of LC-MS global metabolomics data](https://doi.org/10.1093/bib/bbac553) Briefings In Bioinformatics (doi: 10.1093/bib/bbac553)\n* Pang, Z., Zhou, G., Ewald, J., Chang, L., Hacariz, O., Basu, N., and Xia, J. (2022) [Using MetaboAnalyst 5.0 for LC-HRMS spectra processing, multi-omics integration and covariate adjustment of global metabolomics data](https://doi.org/10.1038/s41596-022-00710-w) Nature Protocols (doi: 10.1038/s41596-022-00710-w)\n* Pang, Z., Chong, J., Zhou, G., Morais D., Chang, L., Barrette, M., Gauthier, C., Jacques, PE., Li, S., and Xia, J. (2021) [MetaboAnalyst 5.0: narrowing the gap between raw spectra and functional insights](https://doi.org/10.1093/nar/gkab382) Nucl. Acids Res. (doi: 10.1093/nar/gkab382)"
    },
    {
        "Question": "Interpreting Enrichment Analysis Results",
        "Answer": "That makes sense, thank you!\nIs there a way to tell the type of pathway perturbation (as in, is it enriched or depleted compared to the reference)?"
    },
    {
        "Question": "Interpreting Enrichment Analysis Results",
        "Answer": "I confused Q statistic with q-value; please disregard the first part of the question.\nPlot for the second part of the question:\n![ArachidonicAcidMetdpi150|690x345](upload://g2DfoESYIzDkov8NZo9NWxJwbUJ.png)"
    },
    {
        "Question": "Interpreting Enrichment Analysis Results",
        "Answer": "Hello,\n\nIn the QEA analysis result table: each time I ran the analysis, the raw p-values seem to be inversely related to the q-values.  How should I interpret this? \nAnd which results should I consider significant? E.g. if I go with the standard for raw p-value (<0.05), I'm getting very high (significantly above expected) q-value; if I go with a low q-value, corresponding raw p-value is beyond anything considered  to be significant.\nCould this indicate problem with the data?\n\nAlso, for the box plots showing relative abundance of the hit metabolites: all of mine have values above and below 0. Should I interpret that as  above normal (i.e. reference) abundance and below normal  abundance?  \n\nThank you"
    },
    {
        "Question": "Interpreting Enrichment Analysis Results",
        "Answer": "Values around 0 are likely due to normalization (scaling), not related to \"normal\" or \"reference\". You can say compound A is more abundant in group \"fast\" than in group \"glu\"."
    },
    {
        "Question": "Differences in differential metabolites screened under the opls-da model with metaboanalyst and with simca",
        "Answer": "MetaboAnalyst is not just a statistical program. It contains comprehensive data processing and normalization steps to make sure the input are appropriate for statistical analysis. All analysis procedures are based on well-established practices in metabolomics. You can trace all the underlying R commands together with MetaboAnalystR package. \n\nIt is hard to compare with a commercial tool as we have no knowledge about its underlying code. I suspect it could be related to data processing, normalization and VIP computing. Note the underlying R package is [ropls](https://bioconductor.org/packages/release/bioc/html/ropls.html)"
    },
    {
        "Question": "Questions about metabolic pathways",
        "Answer": "I would like to know why compounds with P value>0.05 can be matched into the pathway diagram. Is there any way to filter out these compounds?\nFor example: In this metabolic pathway with p value = 0.003, the orange compound actually has a p value of 0.07. Can the enrichment pathway analysis then be trusted?\n![1680162816194|668x460](upload://g0geGmkeT84ZDQshHds1HViaBew.png)\n\n![B|690x35](upload://RXXfTMJpMpuTEgApPLtp3THyw.png)"
    },
    {
        "Question": "Questions about metabolic pathways",
        "Answer": "Your question is relevant to over-representation analysis (ORA).  I guess you are using globaltest / GlobalANCOVA for analysis in this case, since no details were provided."
    },
    {
        "Question": "MetaboAnalyst 6.0 is unable to perform T-tests and other functions related to T-tests correctly！",
        "Answer": "I am unable to perform a T-test when using 6.0 to analyze data previously analyzed on 5.0. I think this is related to the name of a certain metabolite, because I created several sets of data using these metabolite names for testing, and the problem has persisted, but I cannot confirm which one is among the hundreds of metabolites. I don't think it's important to confirm which metabolite is causing the problem, what's important is that there may be some kind of bug when reading metabolite names in 6.0. I hope this issue can be resolved.\n![1|690x318](upload://sWo4Yxs7fOSHsTqvbcg76oCFBvP.png)"
    },
    {
        "Question": "Pathway visualisation",
        "Answer": "If you think it is not related to your data, please show the same issue using our example dataset. Note you still need to provide details - which example, and all the steps leading to the issue, as the issue could be related to the parameters you chose."
    },
    {
        "Question": "Pathway visualisation",
        "Answer": "Hi,\nI'm doing a joint pathway analysis. Everything works fine but when I try to visualize the pathways, I get this error message \"Failed to create a zoom-in image. If you are the Sys Admin, please make sure that the convert command is available in the PATH.\" \n![image|690x405](upload://6Q5ctC61o6sO3sMq2adILIf9s0w.png)\nI can give you my data set, but I don't think that they are part of the problem.\n\nThanks a lot,\nSarah"
    },
    {
        "Question": "In the enrichment analysis result, how do we know the pathways enriched in what group?",
        "Answer": "Thank you for your reply. How can I determine which of the two groups is considered reference? I tried changing the labels of my two groups, but the result always stays the same. If one of the groups is considered a reference, then we should be able to identify in which group the pathway is more or less perturbed compared to the reference?"
    },
    {
        "Question": "In the enrichment analysis result, how do we know the pathways enriched in what group?",
        "Answer": "The perturbed / enriched status of a pathway is calculated by comparing metabolite concentration profiles between two groups (one of them is considered reference), we then rank different pathways by their p values. \n\nTo answer your question, we need to have a **third** reference (normal) baseline concentrations of each metabolite in a pathway, then compare each group to that baseline profile."
    },
    {
        "Question": "In the enrichment analysis result, how do we know the pathways enriched in what group?",
        "Answer": "The tool gives you the information, and you make the decision regarding the question you asked.  \n* To the method, A vs B or B vs A are the same.\n* To the users, you decide which is the reference - for instance, if a particular pathway is significant, and group A is the control/reference in **your study design**, then the pathway in group B is considered perturbed.  If you would like to know the direction of change, you click to see the box plots for the underlying metabolites."
    },
    {
        "Question": "In the enrichment analysis result, how do we know the pathways enriched in what group?",
        "Answer": "Unlike feature / compound level analysis, we don't explicitly compute if a pathway is **enriched** in one group compared to other group. The name is misleading, a better term is if a pathway is **perturbed**. In real experiments,  metabolites in a pathway can be either up- or down-regulated due to dynamic regulation of metabolic flux. They are very meaningful.  \n\nYou can always see the actual compound-level concentration changes in MetaboAnalyst (click the **View** link) as shown by the Figure below\n![Screen Shot 2022-11-07 at 8.27.29 PM|690x444](upload://tUOTwVlLH2umkWBdHxJIH43cMJz.png)"
    },
    {
        "Question": "In the enrichment analysis result, how do we know the pathways enriched in what group?",
        "Answer": "Thank you for this explanation. However, In some cases (see example below), the enrichment analysis suggests one pathway being significantly perturbed, but the individual metabolites within that metabolite set are not enriched in the same direction. How can I know which whether the pathway is more perturbed/enriched in one group versus the other?\n![image|535x500](upload://e9Ft4rS96nYyFF2b6NrDbnqu8OU.png)"
    },
    {
        "Question": "Why in sometimes hit \"submit\" in permutation of PLSDA use same data has different Empirical p value?",
        "Answer": "Sometimes, I use same data for PLSDA, When hit the \"submit\" two or more times of permutation, it provided different Empirical p value"
    },
    {
        "Question": "Why in sometimes hit \"submit\" in permutation of PLSDA use same data has different Empirical p value?",
        "Answer": "Permutation tests contain random components in the procedure (more details: [biomarker analysis](https://omicsforum.ca/t/how-to-understand-the-result-from-permutation-tests-biomarker-analysis/302), [PLS-DA](https://omicsforum.ca/t/how-to-interpret-the-permutation-result-pls-da/96)). The results may be different in each run. In our experience, the  variations should be usually small when you have a large number of samples (at least 40 samples with balance design). \n\nIf the differences are large, consider the following: \n1) Sample size is too small\n2) Very unbalanced group\n3) Potential outliers which lead to unstable models"
    },
    {
        "Question": "how does auto-optimized parameters works",
        "Answer": "We have studied extensively the parameters and related files, however we do not find out why this difference on the features detected occurs, as the data were exactly the same both times. We are wondering if an update occurred between our two analysis in the software that could result in this difference.\nAdditionally, since yesterday (21/12/2023) we get the troubleshooting page , both with our data and the 2 examples provided in the LCMS data processing. Would this be related to the recent update we saw it was released? We are hoping that this problem will be resolved soon!"
    },
    {
        "Question": "how does auto-optimized parameters works",
        "Answer": "> In my recent analysis, I uploaded the same dataset twice into the program. The first run was conducted with auto-optimized parameters for LC-MS analysis, resulting in the detection of 5,128 features. However, when I repeated the process for the second time (two months later), the program only identified 1,851 features. I repeated the analyses multiple times in the second time receiving constantly the same result. I would appreciate it if you could explain to me about auto-optimized parameter and how that works."
    },
    {
        "Question": "how does auto-optimized parameters works",
        "Answer": "The details of the pipeline and algorithm are described in [this paper](https://www.mdpi.com/2218-1989/10/5/186) ."
    },
    {
        "Question": "Enrichment analysis metabolites - Problem",
        "Answer": "Hi,\nI was working on enrichment analysis of a list of metabolites, but was unable to get the results. \nProbably something was wrong in my dataset because a generic error landing page appeared: \n![image|690x289](upload://jqoSzUa4PqHF2tcVSUpmkBToSki.png)\n\nSince then, I am unable to open Metaboanalyst since it always appear the error message, blocking the program.\n\nThank you for help fixing this problem."
    },
    {
        "Question": "How to use and interpret PCA visualization?",
        "Answer": "The interactive PCA visualization summarizes all the data into the the first 2 or 3 principal components (PCs). Each data point in the **Scores Plot** represents a sample. Samples that are close together are more similar to each other. The colors of these data points are based on the factor labels. Users can change the colors according to any of the two factor labels.\n\nEach data point in the **Loadings Plot** represents a feature. When Scores plot and Loadings plot are viewed from the identical perspective, the direction of separation on the scores plot can be explained by the corresponding features on the same directions - i.e. features on the two ends of the direction contribute more to the pattern of separation."
    },
    {
        "Question": "Why should I use a reference metabolome?",
        "Answer": "How is the custom reference metabolome (if provided by the user) used by MetaboAnalyst? \n\n- Is it in order to perform accurate correction for multiple testing?\n- Quantitative Enrichment Analysis (QEA) typically uses as input *all detected* metabolites. Does this mean that for QEA we practically never need to provide a custom reference?"
    },
    {
        "Question": "Why should I use a reference metabolome?",
        "Answer": "Currently, no single analytical technique can simultaneously measure all the metabolites involved in the metabolic pathways. Different platforms - NMR, GC-MS, LC-MS, usually have different compound coverage. These difference will likely introduce bias during the enrichment analysis, which assumes all compounds in the pathways or metabolite sets have equal chance to be measured. To correct for this bias, a reference metabolome that is specific for the platform is recommended.  Please note the reference metabolome should be uploaded as [a list of common compound names](https://www.metaboanalyst.ca/MetaboAnalyst/resources/data/hmdb_list.txt). \n\nPlease note, this correction is only necessary when only a list of significant compounds are provided (over-representation analysis). When the whole concentration table is provided, the compounds within the data are used as the reference metabolome. It is not necessary to upload separately a compound list as reference metabolome."
    },
    {
        "Question": "How to interpret the compound view in Pathway Analysis?",
        "Answer": "The \"compound view\" is generated from univariate analysis for the matched compound. They show the concentration distributions of the corresponding compound with regard to the phenotype labels.\n\nTwo examples of \"compound view\" are shown below:\n<ul>\n<li>\nThe box plot image on the left shows the result with categorical (binary or multi-group) phenotype labels (t-tests, ANOVA); \n<\/li>\n<li>\nThe scatter plot image on the right shows the result with continuous phenotype labels ( linear regression). \n<\/li>\n<\/ul>\n\n![](upload://wLstuDikwv84fPVUA76FNVslKYd.png) ![](upload://fTLRnbscNh7KSGXaxxiKbJXnmou.png)"
    },
    {
        "Question": "What is the difference between the \"Include meta-data\" and \"Blocking\" inputs?",
        "Answer": "Covariates that are indicated in the \"Include meta-data\" and the \"Blocking\" inputs are both included in the linear model and are \"adjusted\" for when calculating p-values for the primary variable of interest. The difference is that the former are modeled as fixed effects while the latter are random effects. Fixed effects are typically variables with a known set of values that will have the same range for all future studies, such as sex or age, while random effects can be thought of as a small sub-set of all possible realizations of that variable, with future studies likely to have different sets of values, for example patient ID or sample processing batch. When variables are properly modeled as random effects, that model can be better for making future predictions, however it is more computationally intensive and reduces the statistical power. Since the majority of differential analyses in MetaboAnalyst will not be used for future predictions, we recommend modeling most variables as fixed effects."
    },
    {
        "Question": "Can I use MSEA on metabolomics data from other species?",
        "Answer": "Yes, but you may have to provide your self-defined metabolite set libraries.  In addition, some metabolite set libraries are species independent - such as those based on chemical structures. \n\nThe metabolite set libraries are species specific. For example, the pathway library is only valid for mammalian species. While the metabolite sets based on diseases are only applicable for human. \n\nHowever, MSEA allows users to upload their own metabolite set libraries for enrichment analysis. Therefore, if you want to perform enrichment analysis on data from species other than human being, you need to provide two files, one contains metabolite concentration data, the other contains the metabolite set library."
    },
    {
        "Question": "Create custom MS/MS database for OptiLCMS - MS/MS data processing",
        "Answer": "Hello, Is there a way to create custom MS/MS database for OptiLCMS? \nIf so, any clues you can share would be greatly appreciated. Tx"
    },
    {
        "Question": "Performing metabolomics pathway analysis using metabolites molecular weight or molecular formulas",
        "Answer": "I have a general question regarding metabolomics analysis and would appreciate any help/insights.\n\nI have a list of unknown/unannotated metabolites. The only 2 pieces of information I have are molecular weight and/or molecular formula (an example is in the attached csv file). I want to ask whether I may perform an enrichment (pathway) analysis using this information.\n\nMany thanks to you in advance for your help.\nEhab\n[Example.csv|attachment](upload://vlfEKnqhZklYFt6HkFaWzaMBypH.csv) (689 Bytes)"
    },
    {
        "Question": "Getting Logged Out During MS Spectral Processing",
        "Answer": "Hi, \n\nI am currently attempting to upload my data onto MetaboAnalyst for MS Spectra Processing. I am uploading around 75 samples, which admittedly takes a long time. I am having an issue where my account keeps getting logged out despite me checking the upload status every 30/45 minutes or so, and when that happens my files disappear. I have tried using the Save and Exit option, and my files disappear as well despite the project still being present. Is there anything I can do to stop my account from being logged out?\n\nBelow are the details of my files:\n1. Compressed into (.zip) files through WinZip, using the Compression Legacy option.\n2. Each zip file is less than 200 MB.\n3. There is a meta-data (.txt) file to show the samples and their groups. \n\nThank you in advance for your help!"
    },
    {
        "Question": "Different input sample order creates different results",
        "Answer": "Ok, in that case - the old version of the multi-factor ANOVA interface was not designed to handle this case, but I've added a dropdown to the updated version where you can specify whether the experimental factor is defined between or within (your case) subjects."
    },
    {
        "Question": "Different input sample order creates different results",
        "Answer": "I updated my post with the data attached. I also read the response to the recent question about group labels on PLS-DA. Does small sample size also influence how the Two-way anova is calculated, and thus different order of samples would influence the output?\nThanks!"
    },
    {
        "Question": "Different input sample order creates different results",
        "Answer": "Hi there,\nUsing Metaboanalyst, with the  Statistical Analysis (metadata table) module and data format as time series + one factor, when I input my data in my original sample order (RBC_data.csv), I get lots of significant proteins (>1000). But when I re-order the samples in my original datasheet to group by my one factor (RBC_datatest.csv), I get 0 proteins. I have treated the two files the exact same process (and confirmed they are the exact same file just sample order is different), so I am wondering is this due to the normalization step? Or am I missing something?\n\nMy process:\n-input data as time series + one factor, in columns\n-check that metadata is matching samples properly under data editor\n-default missing values replacement\n-no extra filtering\n-sample normalization by median\n-data transformation cube root\n-Pareto scaling\n-Two way anova with interaction, same FDR\n\nMore clearly: if the input data is the same, except for the order of the samples is different, and I do the exact same process, why do I receive different results?\n\n[RBC_datatest.csv|attachment](upload://qkYHI2aELiLQUEHntQ83uLe2vYE.csv) (1.3 MB)\n[RBC_data.csv|attachment](upload://4ITsbtMKOsn9Jovy68qtqkExh16.csv) (1.3 MB)\n[RBC_metadata_short.csv|attachment](upload://f8f7xNqcxKmMthdliN1tsuOPfxA.csv) (618 Bytes)"
    },
    {
        "Question": "Different input sample order creates different results",
        "Answer": "Hi @jess.ewald,\nThanks for the update! I will re-analyze my data afterwards.\n\nAnd indeed yes I do have repeated measures across my two factors - time and concentration because it was an in vitro study where I used red blood cells so they could be repeated over many treatments. \n\nThanks,\nSarah"
    },
    {
        "Question": "Different input sample order creates different results",
        "Answer": "Thanks for alerting us to this issue. There was indeed a problem with how we were handling the metadata, which is fixed now. In addition, while we were reviewing the code, we made some updates to the way the ANOVA tests are set-up and are using a new R package, so you can expect some interface changes. \n\nBtw, while using your data, I noticed that you have the same subject IDs for C, L, H. I assume this is control, low, and high, and it seems unlikely that you have done repeated 'exposures' to the same subjects for multiple time points? Pls ignore if this is not the case!\n\nWe have made the changes internally - the online version will be updated very soon."
    },
    {
        "Question": "Why the given KEGG IDs are not read by MetaboAnalyst",
        "Answer": "This is a common question. Please read [this post](https://omicsforum.ca/t/why-arent-all-uploaded-compound-names-ids-matched-even-they-are-in-hmdb-or-kegg/169)."
    },
    {
        "Question": "Metaboanalyst: How to get the full list of metabolites of the Volcano plot",
        "Answer": "You can set the cutoffs to be none i.e., p.val = 1 and FC = 0"
    },
    {
        "Question": "What is dose response analysis?",
        "Answer": "Dose-response analysis was developed by the field of toxicology to identify the concentration at which a biological assay responds to chemical exposure (the concentration is known as **benchmark dose or BMD**). Dose-response experimental designs typically include a control group (dose = 0) and at least three different dose groups, typically with the same number of replicates in each group. \n\nA key activity of dose response analysis is to identify dose-response models that can describe dose–response relationship by the observed (mean) responses at the tested doses  through a process called **curve fitting**. Dose-response models are regression models between the dose or concentration and omics abundance levels.  Dose-response models encompass a range of statistical models from nonlinear regression, generalized (non)linear regression, and parametric survival analysis. MetaboAnalyst currently offer 10 built-in models (see below). Using the dose response model, we can then perform BMD estimation. \n\n![Screenshot 2024-03-11 at 8.52.39 PM|690x141, 75%](upload://dTUcx0xk5bDZ7SRzxoesfeTee5A.png)"
    },
    {
        "Question": "How to interpret the Prob. Overview in biomarker analysis?",
        "Answer": "In multivariate ROC curve analysis, the prediction results from PLS-DA, SVM, RandomForests are presented in the form of probability [0, 1]. Since MetaboAnalyst uses balanced random subsampling, 0.5 will always be the cutoff point.\n\nThe prediction overview shows the predicted class probabilities (x-axis) of each sample (y-axis). The probability scores are the average from the 50 iterations, ranging from 0 ~ 1. For instance, less than 0.5 will belong to group A, more than 0.5 belong to group B. In theory, a sample could be located on the 0.5 line, which means the sample has never been selected for testing during the iterations.\n\nUsers can also use the Pred. Overview to identify potential outliers. For instance, if a sample is always predicted to have a high probability in the wrong group, this may indicate that the sample could be labeled incorrectly. Users can check \"Label samples classified to the wrong groups\" to identify these potential outliers. Note the Y values are just random values to help separate the samples so that users can better view individual probability scores. If you know R, the R code is below\n\n<pre>\ny <- rnorm(length(prob.vec)); # prob.vec is x-values containing all probabilities\nmax.y <- max(abs(y));\nylim <- max.y*c(-1.05, 1.05); # large sample size more spread out\n<\/pre>"
    },
    {
        "Question": "\"Use all compounds in the selected pathway library\" is a misleading option for reference metabolome",
        "Answer": "Thank you for the reply! I think the default option that generates biased results should be removed, since people (like me) may not be reading the tutorials and many will prefer methods that gives them statistically significant results rather than unbiased results. Attaching a test FYI.\n![Screen Shot 2022-09-08 at 10.17.12 AM|674x500](upload://lftWwePpsvp2Fc6rtzMI3Jn3DxN.jpeg)"
    },
    {
        "Question": "\"Use all compounds in the selected pathway library\" is a misleading option for reference metabolome",
        "Answer": "This is a valid concern and MetaboAnalyst has mentioned this potential bias from the day 1 (and in almost all of our tutorials on this topic).  \n\nFor targeted metabolomics, MetaboAnalyst offers the option for \"uploading a reference metabolome\" in both Metabolite Set **Enrichment Analysis** module (it is working), and Metabolic **Pathway Analysis** module (will be fixed this week).  For now, you can try the MSEA module which should give the same results (except the pathway visualization)"
    },
    {
        "Question": "\"Use all compounds in the selected pathway library\" is a misleading option for reference metabolome",
        "Answer": "MetaboAnalyst web platform is designed to allow users to explore their data interactively. For targeted metabolomics (i.e, ~40 compounds measured,  5 significant), there will be very few left after prefiltering. When cautions are taken, many researchers will ignore those \"bias\" or \"obvious\" pathway hits, or use them for quality assurance - they will continue down the list to find more meaningful hits.\n\nWhen more compounds are measured (~100s), we can do better in algorithm.  We are developing an unbiased approach, which does not require uploading a separate reference metabolome. Users will need to upload the full ranked list (or complete concentration table), and MetaboAnalyst will leverage this as background reference and further use permutation to compute empirical p values.  This is similar to the mummichog approach currently employed for untargeted metabolomics. We hope to release this feature by the end of the year, if not earlier"
    },
    {
        "Question": "\"Use all compounds in the selected pathway library\" is a misleading option for reference metabolome",
        "Answer": "Thank you. If the misleading option has to stay in the module, I think it should not be the default and should have warnings on the webpage (instead of the tutorial) to remind users to take cautions. \n\nLooking forward to the new approach!"
    },
    {
        "Question": "\"Use all compounds in the selected pathway library\" is a misleading option for reference metabolome",
        "Answer": "\"Use all compounds in the selected pathway library\" is provided as the default option for reference metabolome in the enrichment and pathway analysis module. However, unlike the other omics data, pathway coverage for metabolomics data are usually not even across different pathways. Metabolites that are lost during extraction procedures, too polar or non-polar for the LC, too labile for MS, etc won't get detected. Using all compounds in the selected pathway library as the reference metabolome will wrongly pick up the pathways with high coverage as significant hits. The only correct option should be \"Upload a reference metabolome based on your analytical platform\". However MetaboAnalyst has a bug that prevents this tool from running properly (see GitHub Issues 34,96 and 168). Please get these corrected soon. Thank you."
    },
    {
        "Question": "Inconsistency in Estimating Missing Values",
        "Answer": "In MetaboAnalyst 6.0, Statistical Analysis, One Factor, the Missing Value Estimation step has the following text \"Too many missing values will cause difficulties for downstream analysis. There are several different methods for this purpose. The default method replaces all the missing values with a small values (the half of the minimum positive values in the original data) assuming to be the detection limit. Click next if you want to use the default method. The assumption of this approach is that most missing values are caused by low abundance metabolites (i.e. below the detection limit).\"\nWhile the menu below that (Step 2) provides options for \"Estimate the remaining missing values\", the default is \"Replace by LoDs (1/5 of the minimum of the positive value for each variable). \" There is no option to use 1/2 of the minimum positive value as the text would suggest"
    },
    {
        "Question": "The “Raw p” of the pathwasy_results analyzed by R is quite different from that of MetaboAnalyst online. Which one is right?",
        "Answer": "We recently updated the R functions in web based on the comments from the MetaboAnalystR 3.0 GitHub. One of them is related to computing the ORA p values and background filtering. I suspect it could be the cause. We are preparing the new release (MetaboAnalystR 4.0) to solve the inconsistency."
    },
    {
        "Question": "When and how to use the Peak Annotation information?",
        "Answer": "Peak Annotation step generated peak groups which contain isotopes, adduct ions and other unknown peaks that could belong to the same peak group. However, in the downstream analysis it seems we did not use these information to reduce the peak list.  I think one of the main purposes for peak annotation is to shorten the peak list. I was wondering when and how to use these information properly.  Should we get rid of the isotope peaks, combine adduct peaks or combine all the peak intensity belong to the same peak group? Thank you."
    },
    {
        "Question": "When and how to use the Peak Annotation information?",
        "Answer": "One more thing, currently, MetaboAnalyst supports doing a basic feature filteration based on the annotation results. All primary (De)protonated ions will be kept based on the annotation results. The redundancy-free feature table is available from the Download Page (metaboanalyst_input_clean.csv).\n![Slide1|690x388](upload://ctEsx49QlrT6Zs3mqwo7HNWN3IC.jpeg)"
    },
    {
        "Question": "When and how to use the Peak Annotation information?",
        "Answer": "Yes. The variability of features truly deserves a specific concern. It is better to evaluate the variability based on some QC samples or other standard reference samples. But, as you said, the batch effect (and even signal drift) is the major source of variation, which needs first attention. Thanks for your advice, MetaboAnalyst will provide more mathmatically appropriate options for user to reduce the redundancy. This has been in my TODO list :smile:."
    },
    {
        "Question": "When and how to use the Peak Annotation information?",
        "Answer": "Hi Julia,\nThanks for this question. Yes, the annotation results of the entire feature table include both isotops and adducts information. This annotation is performed with CAMERA package. Based on their manual (https://bioconductor.org/packages/release/bioc/html/CAMERA.html), I didnot see a clear guidance on how to process these annotation results further. However, I do have some ideas on how to remove the redundancy:\n\n1. For isotopes, their intensity (or abundance) is expectedly much lower than their parent features (M+0). It is safe to remove the isotopes (M+1, M+2, etc), because the low intensity features are usually more variant (more deviation included) due to the base noise of the MS instrument. Unless users' researches are specifically focusing on the characteristics of isotopic features.\n\n2. For adducts, this depends on cases of specific features.\n\n    * If intensities these adducts features are much lower (e.g. 90%) than their parent feature, it is better to remove the adducts but keep their parent feature;\n    * Similar to the point above, if the intensity these adducts features are much higher than their parent feature, it is better to remove the parent feature but keep the adduct feature;\n    * If intensities these adducts features are same or similar as their parent features, it is better to keep both of them for further investigation;\n    * An important situation is that if there are more than one annotations results (e.g. annotated as one isotope + one adduct or as multiple different adducts) for one feature, it is challenging to make a decision in this case unless there is more experimental proof;\n    * In addition, mathematically merge the intensity (abundance) of the adduct and parent features seems obvious but also quite arbitary, because of the lack of evidence showing additivity of MS signals (from different m/z regions).\n\nIn summary, the annotation results can be used to show the relationshipe between MS features and reduce the redundancy to some extent."
    },
    {
        "Question": "How to add data labels to Pathway Analysis in Metaboanlayst",
        "Answer": "MetaboAnalyst is designed for **online** interactive exploration - every data point is labelled and you can see it with mouse over.  These features cannot be captured by PDF, labeling all of them simple won't be useful (i.e. not readable). \n\nNote with the empty / unlabeled graph, you can annotate any pathways of interest directly using PointPoint or other graph editing tools."
    },
    {
        "Question": "How to add data labels to Pathway Analysis in Metaboanlayst",
        "Answer": "Hello,\n\nI have used Metaboanalsyt to do a Pathway Analysis between my 2 groups of interest, to find pathways that are different using KEGG annotation.\n\nIt works well and generates a nice summary plot like this:\n![path_view_2_dpi150|500x500](upload://g6m5vNbIYrbQORLVvk4GYGy2f8u.png)\n\nI can hover my mouse over each dot on the graph to get the pathway information - but is there a way to add data labels to this graph? Seems very simple, but I can't find the option to do this.\n\nThanks in advance for your help!\n\nAll the best,\nJade\n\n[Pathway_Analysis_Report.pdf|attachment](upload://rC6icGQryMQgDBBLTSvwh5TjbBT.pdf) (175.1 KB)"
    },
    {
        "Question": "Issue with PerformParamsOptimization function in metaboanalystR",
        "Answer": "The issue could be related to the CPU type. The core code was written in C/C++11 and tested on Linux or Mac OS X equipped with **Intel** and **AMD** CPU types. It may not work well on **ARM** -based CPU (used in **Apple M1** chip and **Tau VM** )."
    },
    {
        "Question": "How does MetaboAnalyst deal with zero values if I don't perform missing value imputation?",
        "Answer": "Data processing is to prepare for normalization and statistical analysis. Since zero values will cause trouble in log transformation, they will be replaced by the 1/5 of the smallest positive values of that feature (i.e. replacing zero with detection limit). \n\nThe approach should not lead to distributional changes unless your data contain a large percentage of zeros. If this is the case, you should do **formal** data filtering and missing value imputation."
    },
    {
        "Question": "Unable to download ANOVA and to change colors of Heatmap class samples from MetaboAnalyst 6",
        "Answer": "Regarding the color of classes in heatmaps I was already able to change it! But the problem in ANOVA download remais the same. Even when I change the format and resolution the error remains. Can you help @jeff.xia ?"
    },
    {
        "Question": "False Discovery Rate Calculation in MetaboAnalystR",
        "Answer": "The FDR is based on R \n>p.adjust(raw.pvals, \"fdr\")\n\nThe associated R documentation:\nThe `\"BH\"` (aka `\"fdr\"` ) and `\"BY\"` method of Benjamini, Hochberg, and Yekutieli control the false discovery rate, the expected proportion of false discoveries amongst the rejected hypotheses. The false discovery rate is a less stringent condition than the family-wise error rate, so these methods are more powerful than the others."
    },
    {
        "Question": "How to get a list of significant metabolites for network analysis",
        "Answer": "The network analysis in a hypothesis generation method.  For your questions:\n\n1) It takes a list of **metabolite of interest** (for instance, based on similar patterns or fold changes). Raw p values or FDR are just used to select those that are interesting;\n2) This is independent of (unaware of) your upstream tests. The input list is assumed to be the truth. \n\nOverall, your question is more relevant when you combine all the steps under a single statistical modelling and interpret the p values in this context."
    },
    {
        "Question": "MSEA QEA data normalization and group comparisons - does the enrichment analysis use normalized data or original data when calculating enrichment scores and p values? In addition, how do you know which group is compared to the other (ex: A compared to B vs B compared to A) when looking at the Top 25 enriched metabolite sets",
        "Answer": "For Q1: this depends on your choice when you perform data normalization;\nFor Q2: please read [this post](https://omicsforum.ca/t/in-the-enrichment-analysis-result-how-do-we-know-the-pathways-enriched-in-what-group/1073)"
    },
    {
        "Question": "How to find the metabolite clusters from the Hierarchical Clustering in statistical analysis [one factor]",
        "Answer": "Unlike SOM or K-means clustering, there is no formal clusters defined in Hierarchical Clustering. You can do it manually - visually identify the cluster and record the names of the members. If the map is too crowded, you can choose \"Detail View\"."
    },
    {
        "Question": "I am unable to generate a pdf report after completing the statistical one data analysis and having generated all figures and tables. How to fix this error ? Thanks",
        "Answer": "Report generation in public version will be gradually deprecated - due to new technologies as well as the time-consuming support nature of this feature for an academic lab. You can check out our [Pro Tools options](https://www.xialab.ca/pro/protools.xhtml) which indeed focus on better generation of analysis reports, presentations as well as batch processing."
    },
    {
        "Question": "Group labeling and data structure in CSV file",
        "Answer": "There are two modules for performing statistical analysis of a metabolite table: \"Statistical Analysis [one factor]\" and \"Statistical Analysis [metadata table]\". \n\nIn either case, you can see the appropriate data format by clicking the module name, scrolling down to the example datasets, and then clicking the linked files. \n\nIn your case, if you have multiple metadata types, you likely want to use the \"Statistical Analysis [metadata table]\" module. There is an option specifically for datasets with one phenotype, a time series, and subject ID, however the underlaying R package requires a balanced design (same # replicates in each experimental group). \nThe \"Multiple factors/covariates\" experimental design is the most flexible, however there are still requirements surrounding the minimum number of replicates."
    },
    {
        "Question": "Heatmap does not show a chromatic scale correspondent to data",
        "Answer": "Heatmap allows you to view data at original or normalized scale. In addition, there is a \"Details View\" function, you can use this feature to generate a zoom-in view and to locate those rare, outlier values"
    },
    {
        "Question": "I received a format error when uploading compressed spectra (.zip)",
        "Answer": "There are **two** possible reasons when this error happens:\n\nThe zip files cannot be decompressed by our program. This happens if you used the most recent WinZip (v12.0) with default option for compression. Make sure to selecting the Legacy compression (Zip 2.0 compatible).\n\nIt can also be caused by the spectra itself. They must be in the formats accepted by MetaboAnalyst (mzML, mzXML, netCDF, etc) . In addition, make sure there are no other files (for example, log file or other parameters files) included in the spectra folder."
    },
    {
        "Question": "How are metabolite-gene interaction networks created from a list of genes / metabolites?",
        "Answer": "The networks are generated by first mapping the metabolites, genes or both to the underlying [gene-metabolite-disease interactions database](https://omicsforum.ca/t/which-database-is-used-for-creating-the-network/349).\n\nA search algorithm is then performed to identify first-order neighbours (e.g. metabolites that **directly** interact with a given metabolite) for each of these mapped metabolites (\"seeds\"). The resulting nodes and their interaction partners are returned to build the subnetworks.\n\n![network_eg_faqs|632x500](upload://70Cx8gePWJHGFrgu64KurTaqHkf.png)\n\nThe above figure shows an example of a generated metabolites-genes interaction network."
    },
    {
        "Question": "How to find the matched compounds in Pathway Analysis",
        "Answer": "In the pathway analysis table, click \"match status\" to see details in matching. However, statistical significance does not necessarily means biological significance - we need to consider more contextual evidence beyond math and stats!"
    },
    {
        "Question": "Why is it not encouraged to perform pathway analysis for multi-group data?",
        "Answer": "The main reason is that the result will be hard to explain when there are multiple groups. The increase / decrease is best defined in two-group design. However, you can always first perform analyses that accept multiple groups (such as ANOVA) and then use the ranked peaks for pathway analysis."
    },
    {
        "Question": "Heatmaps - are the t-test corrected for multiple comparisons",
        "Answer": "The t-tests (or ANOVA for multi-group) are used to generate a ranked feature list (based on **raw p values**) for selecting top # features in heatmap display. The multiple testing corrections are not quite relevant here as you can see different ranking methods are offered"
    },
    {
        "Question": "How to setup Reference Metabolome for MetaboAnalystR",
        "Answer": "By default, the reference metabolome will be all the metabolites in the metabolite set library. For instance, if you choose KEGG pathways, the reference metabolome will be all compounds involved in the pathways (usually larger than the metabolome that your platform can cover). When you provide a reference metabolome AND set this to be TRUE, the background will be filtered by your platform. If you are using MetaboAnalystR, the function name is \"Setup.HMDBReferenceMetabolome\" code. Note it is based on compound names and not HMDB IDs."
    },
    {
        "Question": "How can I find the exact value of R2 and Q2 for PLS-DA",
        "Answer": "The information is provided on the same place you see the plot (click the **table icon** beside the graphic icon)\n![Screenshot 2024-01-29 at 7.23.59 PM|690x426](upload://eJpnlhrdpFxNBUkdbz4dI4FbQSi.jpeg)"
    },
    {
        "Question": "Why the Debiased Sparse Partial Correlation (DSPC) is disabled in Network Analysis",
        "Answer": "There are two types of networks in MetaboAnalyst at the moment\n* Input: a compound list (i.e. significant metabolites) => knowledge-based network: all networks (except DSPC) you mentioned. They are already in our database and will be used to create the network by mapping your data to the underlying database;\n*  Input: a compound concentration table => data-driven network: i.e. DSPC, which is computed based on the data table you uploaded. After you create network, you can also perform enrichment analysis on this network in the network visualization page\n\nThe issue is that directly mapping all compounds from the data table to the knowledge network will create a huge network (not viewable nor interpretable).  You need to select a few compounds of interest first. At the moment, you can first upload the same table to Statistical Analysis module to get a list of significant compounds, then copy-and-paste the list to the Network Analysis module to access all the knowledge-based networks. \n\nThe Network Module was originally designed for **mapping** from a list of features of interest to different knowledge-based networks. The DSPC was added late - it requires table input to compute network based on the data. \n\nIf your input is a table, other networks will be disabled as they require list input. To use other networks, you need to first detect significant metabolites from the compound table (i.e. t-tests or fold changes using the Statistics module), and copy-paste the sig. features."
    },
    {
        "Question": "How to prepare inputs for Functional Analysis module (untargeted metabolomics)?",
        "Answer": "This module accepts either a <b>complete<\/b> (not just significant!) peak list or a <b>complete<\/b> peak intensity table.\n\n**Peak List (version 1):** The *Function Analysis* module accepts either one of the three formats below:\n\n* A three column table containing the **m/z** features, **p-values**, and **statistical scores**;\n* A two-column table containing **m/z** features and either **p-values** or **t-scores**;\n* A one-column table ranked by either **p-values** or **t-scores**. \n\nAll inputted files must be in .txt format. If the input is a three column table, both the mummichog and GSEA algorithms (and their combination) can be applied. If only p-values (or ranked by p-values) are provided, then only the mummichog algorithm will be applied. If only t-scores (or ranked by t-scores) are provided, then only the GSEA algorithm will be applied.\n\n**Peak List (version 2):** With Version 2 of mummichog in *Functional Analysis* module, retention time can be included as a new column with the \"rt\" or \"r.t\" heading. The maximum number of columns that can be uploaded is 5: \"**m.z**\", \"**r.t**\", \"**p.value**\", \"**t.score**\" and \"**mode**\".\n\n<b>Peak Intensity Table<\/b>: This table should contain sample class labels and feature IDs with mass and/or retention times. See examples below:\n\n* [Example data table with m.z only](https://www.metaboanalyst.ca/MetaboAnalyst/resources/data/mummichog_immu_table.csv)\n* [Example data table with m.z and r.t](https://www.metaboanalyst.ca/MetaboAnalyst/resources/data/malaria_feature_table.csv)"
    },
    {
        "Question": "What are the inputs for Functional Analysis module?",
        "Answer": "For these algorithms (mummichog and GSEA), p-values are only used to rank peaks and are not applied as a cut-off, so multiple hypothesis correction is not a concern. Sometimes multiple hypothesis correction results in many distinct p-values being replaced by the same value (ie. all 'rounded up' to 1), erasing the ranking. For this reason, using raw p-values is better."
    },
    {
        "Question": "What are the inputs for Functional Analysis module?",
        "Answer": "The  two links for the example peak intensity table given in the answer above are broken. Would you be able to re-upload the links or add screenshots of what the input data should look like/how it should be formatted?"
    },
    {
        "Question": "Issue uploading my data when doing enrichment analysis",
        "Answer": "Hi all,\nI'm having issue uploading my csv file to Enrichment Analysis [Quantitative Enrichment Analysis] module. The error info and my setting are in:\n![1|690x496](upload://vLsI1BBNDOj1dPV0ksYCT62lzqB.jpeg)\n\nAnd my csv file is here:\n[A.csv|attachment](upload://h9JyntpuHaEizkvS6jS0f9Z6uom.csv) (296.5 KB)\n\nThere's no problem when I try to upload the example 'human_cachexia.csv' file. I have no idea what's the problem affecting this. I would be greatly appreciated if you could provide any suggestions about how to fix it."
    },
    {
        "Question": "How should I code missing value in MetaboAnalyst 6.0 Data Integrity Check",
        "Answer": "Missing value should be empty or NA. Note value of 0 (zero) is not considered missing values."
    },
    {
        "Question": "In enrichment analysis, HMDB ID of metabolite and lipid can only be identified separately",
        "Answer": "In previous versions (5.0), metabolites and lipids were identified together when enrichment and pathway analysis were performed. Now metabolites and lipids can only be analyzed separately, what if I want to do the same? Thank you."
    },
    {
        "Question": "If my metabolite of interest can't be found, is there any way I still can perform causality analysis?",
        "Answer": "MetaboAnalyst supports MR analysis based on our curated public mGWAS resources. You can see how those metabolites were included: https://www.mgwas.ca/mGWAS/upload/MGBrowseView.xhtml."
    },
    {
        "Question": "How to interpret the results from concentration comparisons in single sample profiling (SSP)?",
        "Answer": "The reference concentrations SSP were mainly collected from literature based on HMDB. In most cases, the measured concentration should be comparable to the literature reported values as shown below. However, users should keep in mind that these concentrations were measured based on heterogeneous analytical platforms. Therefore, it is more suitable to compare with concentrations measured by the similar technologies. It is advisable to refer to the original literature (provided by SSP) if very extreme values are encountered.\n\nThe image below shows the comparisons of the measured **urinary Glycine** concentration (indicated by a dotted yellow line) to literature reported concentration values. The magenta squares indicate the mean concentration values, and the blue lines indicate the reported ranges. In some cases, 95% confidence intervals are used (two standard deviations from the mean) if no ranges were provided in the original report. Note the link to the original reference of each study will be provided in a table under each plot during analysis.\n![hmdb00123|500x480](upload://5WqMcqGReImzcWUemzE8qEY7bwJ.png)"
    },
    {
        "Question": "What is the reasoning behind 1/5 of the minimum values for missing value imputation",
        "Answer": "This is an empirical decision - computed for each variable as a proxy of their detection limit"
    },
    {
        "Question": "Can I get the p-values for all comparisons (i.e. a-b, a-c, and b-c) in ANOVA post-hoc analysis",
        "Answer": "This feature is only available in the Pro version. The public version will only report signficant or not for pair-wise comparison."
    },
    {
        "Question": "Still possible to export 3D PCA as SVG",
        "Answer": "Yes, these features will be supported in future in due time. This is not related to the R package. It is JavaScript function"
    },
    {
        "Question": "Is it necessary to separate positive and negative ion data when importing data into MetaboAnalyst?",
        "Answer": "This is a parameter you need to specify when you upload your peak intensity table. For peak list,  you do have the option \"mixed mode\". The parameter will inform potential adducts in peak annotation"
    },
    {
        "Question": "Using untargeted metabolomics in Quant Enrich Analysis (continuous phenotype)",
        "Answer": "I have a continuous phenotype and untargeted metabolomics data (primary metabolites, biogenic amines, lipids). Can I use the Quantitative Enrichment Analysis tool to conduct my analyses? Thanks.\n\nSanyog"
    },
    {
        "Question": "How to compare AUROC of the models fitted by SVM in Biomarker analysis?",
        "Answer": "In Biomarker analysis ->multivariate->explore, SVM provided me with 5 models with their AUC and 95%CI. I tried to compare them with z test, but it seemed the 95%CI were binomial exact confidence interval, which DeLong method cannot be applied to. Do we have any way to compare those AUC?"
    },
    {
        "Question": "How to compare AUROC of the models fitted by SVM in Biomarker analysis?",
        "Answer": "Currently MetaboAnalyst is not supporting statistical comparison of the models on this page. However, if you find a good method, you are welcome to suggest it (with related papers / links) - we will consider adding support in a new release, together with the associated documentations."
    },
    {
        "Question": "Pairwise comparisons in linear models and p-values of contrasts",
        "Answer": "* The result you obtained is the ANOVA style as you specified;\n* You can directly compare any two groups of interest by using Reference and Contrast;\n* Performing pair-wise (and post-hoc) analyses are possible, which is similar to batch analysis and is more suitable with the R package"
    },
    {
        "Question": "Pairwise comparisons in linear models and p-values of contrasts",
        "Answer": "Hi,\n\nI am running an analysis among 3 treatments (d5 vs. d10 vs. d15), however I am not being able to visualize the p-value of specific contrasts comparisons (for example, results from d5 vs. d10, or results from d5 vs. d10). \n\nI understand that 238 features are statistically different (as shown in picture 1), but when I try single analysis comparing two factors, I am not able to detect any differences.\n![1|690x391](upload://9KUe8m8lrEZ6e2UJERYvTNtcn8b.png)\n\nThen, when I look the data, I am not able to separate the results from the first contrast comparison (d5 vs. d10) and the second contrast (d5 vs. d10). I only have 1 general p-value (as shown in picture 2). \n![2|652x500](upload://aH6sDdnjotqCGCIOVxoHHT9jXyB.png)\n\nQuestion 1: Is it possible to obtain the p-values for each contrast? \nQuestion 2: Is it possible to obtain results from all comparisons? For example, d5 vs. d10, and d5 vs. d15, and D10 VS. D15 (this one is not included because of the reference group item).\n\nThank you."
    },
    {
        "Question": "What is the formula being used by the software for Sample normalization (Normalization by reference feature)?",
        "Answer": "Please explain the formula and the calculations being done by the software to normalize the samples based on a feature across the samples."
    },
    {
        "Question": "What is the formula being used for Sample normalization (Normalization by reference feature)?",
        "Answer": "This is a very simple method used in cases like urine samples (i.e. normalize by creatinine). You can search the MetaboAnalystR GitHub for the R code."
    },
    {
        "Question": "Functional Analysis does not return any results only a blank page",
        "Answer": "One potential issue is that your data does not contain enough signals for enrichment analysis. Have you tried statistical analysis to see if there are many significant features (enrichment analysis requires 100s of features to give meaningful results)? \n\nYou can upload  the complete ranked peak list based on t-statistics (not peak table) - the algorithm can use the top 10% for enrichment analysis - this is the classical mode"
    },
    {
        "Question": "Some functions working in Metaboanalyst 5.0 are not working in MetaboAnalyst 6.0",
        "Answer": "**Maintaining transparency and backward compatibility is among our top priority.** MetaboAnalyst 6.0 has **added** new modules and **enhanced** current modules.  The main change that I am aware of is the name mapping (from HMDB 4.0 to 5.0) which will affect pathway and enrichment analysis. There were some issues related to this change and most of them are due to cross mapping between KEGG and HMDB (as they are not synchronized 100%).  We have manually fixed them - thanks to those who posted the details for us to reproduce.\n\nI am curious about the differences or other inconvenience you have experienced. Note that we also published many tutorials and protocols based on the previous versions. If you have concerns with your data, you are welcome to use our own data and tutorials to show these cases. \n\nTwo comments:\n\n1. The issues are more related to your parameter settings (i.e. duplicated colors and shapes) - it should not work in 5.0, as we don't have that in mind until now. Such \"creative use cases\" are performed at your own risk since they are not documented on our tutorials. \n\nWe also notice many issues are related to using MetaboAnalyst as GraphPad or graphical tools with extensive support for manual customization (these are not in our design and official documentation). These features are not research related and are challenging to maintain in long term. If these features are important for your work, please consider [becoming subscribed / Pro users](https://www.xialab.ca/translation.xhtml)."
    },
    {
        "Question": "Functional meta-analysis for a multiple-doses study",
        "Answer": "Hello,\n\nWhich functional meta-analysis module would you recommend using for a dose-response study, where are several doses tested? Would you recommend the \"Pathway-Level Integration\" or \"Pooling Peaks Method\"?\n\nMany thanks to you for your help and insights."
    },
    {
        "Question": "Can I perform MSEA for untargeted metabolomics",
        "Answer": "You can perform enrichment analysis for LC-MS data. Please use the \"Functional Analysis\" module. Note the underlying enrichment algorithms are different."
    },
    {
        "Question": "Which MetaboAnalyst analysis can be used for frequency and histogram analysis?",
        "Answer": "Hi, I am looking to plot the frequency and histogram of a function (such as degree of the disease) that repeated between different samples. I wonder to know which type of analysis in Metaboanalyst I should use? Is it Power analysis? Thanks."
    },
    {
        "Question": "MetaboAnalyst View Hits for Enrichment",
        "Answer": "Hi all,\n\nI'm running an enrichment analysis on a set of Metabolites via MetaboAnalyst, and am wondering how I can extract the \"hits\" for each pathway after I run the analysis. Furthermore, I'm looking for the specific metabolites in my set that are also found in the matched pathway.\n\nI was able to find this information using the web browser, but when I downloaded the results I wasn't able to find this information in the zip file. Any help is appreciated.\n\nThanks!"
    },
    {
        "Question": "How can I extract the \"hits\" for each pathway after I run the analysis?",
        "Answer": "You need to click the name of the pathway to obtain the hits (lazy mode on pubic server to save computing). You may want to subscribe to the \"Pro\" version for automated, streamlined analysis."
    },
    {
        "Question": "Statistical Analysis [metadata table]--HTTP Status 500 - Internal Server Error after data integrity check",
        "Answer": "Please read our the detailed instructions on [Data Formats](https://www.metaboanalyst.ca/MetaboAnalyst/docs/Format.xhtml). It gives the clear rules on how to prepare your metadata. Please perform a quality check on your data - I see so many sample names are inconsistent or missing between the data and the metadata. The issue can only be addressed by the researchers who created such files. Please use short sample names and make sure no space in the names."
    },
    {
        "Question": "Joint-Pathway analysis graphical presentation",
        "Answer": "Hello.\nI'am using MetaboAnalyst 6.0 to make nice pathway presentation. My question is there any way to change names in compound nodes of pathway graph from KEGG Id to query names for making picture more readable?\nThank you!"
    },
    {
        "Question": "MetaboAnalyst 6.0 Volcano plot error in downloading",
        "Answer": "Hi there,\n\nI'm trying to download the volcano plot image and it gives me the following error.\n### Payara Server 5.2022.3 #badassfish\n\n![Error|455x244](upload://zN3ilRwFxAYSulTDQnJ9qwqjfZs.jpeg)\n\nI have used 0.05 for raw p-value as threshold and I cannot download the image alone.\nBut when I download the zip file (with all data) it gives me a volcano plot, but the p value threshold seems like default (raw p =0.1)\n\nCould you please help with this issue?\nThanks!"
    },
    {
        "Question": "MetaboAnalyst 6.0 Volcano plot error in downloading",
        "Answer": "Hi @hanszamora , Yes, the error occurred initially when there were no significant features. But, now I cannot download individual custom-changed figures even though there are significant features. When I used version 5.0 I was able to download them."
    },
    {
        "Question": "MetaboAnalyst 6.0 Volcano plot error in downloading",
        "Answer": "Hello, Satya.\n\nI observed that error when there was no significant features. I do not know if it is the same case."
    },
    {
        "Question": "I do not understand what means some details of the figures obtained from normalization",
        "Answer": "I applied \"auto scaling\" to my metabolite concentration data to reach normalization, but I do not understand well the results graphycally represented. What does it means the elements of boxplots: lines, boxes, whiskers, dots?"
    },
    {
        "Question": "I do not understand what means some details of the figures obtained from normalization",
        "Answer": "You can see [this post](https://omicsforum.ca/t/what-are-the-different-marks-in-the-boxplot-based-on/94), or  [wikipedia](https://en.wikipedia.org/wiki/Box_plot). It is not specific to MetaboAnalyst"
    },
    {
        "Question": "How to interpret the network output from network analysis module",
        "Answer": "We will be happy to help with any of scientific / technical questions, but not this type of \"how to analyze my data\" or \"how to interpret the result\".  In your case, I suppose the result was generated by DSPC method? Have you read [our tutorial](https://omicsforum.ca/t/what-is-dspc-network-and-how-does-it-work/348) or [the DSPC publication](https://pubmed.ncbi.nlm.nih.gov/28137712/)?"
    },
    {
        "Question": "Should Q2 for (O)PLS-DA models be interpreted as a probability?",
        "Answer": "Q2's definition is very clear as explained in [this post](https://omicsforum.ca/t/what-is-q2-value-pls-da-and-why-my-q2-value-is-negative/661). You can see its formula from the paper referenced, which is easily interpretable and is not the same as probability"
    },
    {
        "Question": "How to account for covariates in quantitative enrichment analysis (QEA)?",
        "Answer": "Not directly, but you can perform statistical analysis with covariate adjustment. The results can then be used for ORA (targeted metabolomics) or GESA/Mummichog (untargeted metabolomics)"
    },
    {
        "Question": "Spectral bins in MetaboAnalyst",
        "Answer": "Functional analysis for untargeted metabolomics requires first performing **putative** annotations that are reasonably accurate (say, 75% correct) to be practically useful.  In order to do so,  \n1. the input data should have good resolution;\n2. a good reference spectra library for annotation. \n\nHigh-resolution LC-MS data is most suitable at the moment. [Our recent benchmark study](https://pubmed.ncbi.nlm.nih.gov/36572652) shows that ~30% annotation rate can achieve high recall (~90%) on pathway activity prediction.  Other platforms are to be validated."
    },
    {
        "Question": "Why I get different results for PLS-DA with MetaboAnalyst 5.0 and 6.0",
        "Answer": "Upgrading to Version 6.0 should not affect this workflow. The most likely explanation is that you have changed the parameters in your re-analysis. That being said, please provide detailed evidence to support this claim (it is the tool not your operation) and we will look into it. Note we have published a lot of tutorials & protocols. Feel free to use them to show the case."
    },
    {
        "Question": "The picture or box plot of feature view can not be opened, other functions are normal.",
        "Answer": "Please make sure that your feature names are clean (containing no space or special characters such as \"/\", etc)"
    },
    {
        "Question": "Statistical Analysis [metadata table] - Time series + one condition - ANOVA Problem",
        "Answer": "The ANOVA for \"time-series + one factor\" is designed to evaluate the effect of the \"**one factor**\" across \"**time**\". The \"subject\" should not be selected as one of the two metadata of interest, as it is already been accounted for in the \"between subject\" parameter."
    },
    {
        "Question": "In Metaboanalyst statistical testing when generating a sPLSDA 3D PCA plots no longer can find vectors for individual points",
        "Answer": "I used to be able to get the vector coordinates for the sPLSDA 3-D plots and then regraph in a publication quality 3D software.  I could just click on the point for each subject and the coordinates would pop out.  Is there any other place to obtain the coordinates?  Thanks"
    },
    {
        "Question": "In Metaboanalyst statistical testing when generating a sPLSDA 3D PCA plots no longer can find vectors for individual points",
        "Answer": "All those underlying data files can be found from the \"Download\" page. For instance,  the \"**splsda_score.csv**\" will contain all the coordinates used to generate the score plot from sPLS-DA."
    },
    {
        "Question": "How to convert peak intensity to compound names in Statistical Analysis module?",
        "Answer": "The statistical analysis module does not perform any annotation - whatever ID types you upload are the ones displayed in the results. If you analyze labeled table in MetaboAnalyst, you will get the results with the compound names. For LC-MS peak intensity table, the feature IDs will be m.z and retention time."
    },
    {
        "Question": "How to use the sample view curve on the normalization step",
        "Answer": "This is a good question. In general, we don't care whether the sample-wise distribution is approximately normal, since all statistics are done feature-wise. \n\nHowever, sample-wise distribution can still be helpful for QA/QC purposes. If one or several sample-wise distributions are extremely different from the majority, it could indicate that there were technical problems with the data collection and those samples should be excluded from the analysis."
    },
    {
        "Question": "Sample view- statistical analysis (one factor)",
        "Answer": "We don't care whether the sample-wise distribution is approximately normal, since all statistics are done feature-wise. \n\nHowever, sample-wise distribution can still be helpful for QA/QC purposes. If one or several sample-wise distributions are extremely different from the majority, it could indicate that there were technical problems with the data collection and those samples should be excluded."
    },
    {
        "Question": "Data preparation for statistical analysis of datasets with QC samples",
        "Answer": "My dataset contains samples belonging to two or more biological groups and a few QC samples.  I assume the procedure to be: \n\ndataset upload -> data filtering (use QC for filtering) -> data normalization (use QC for as reference for sample normalization) -> data edit (remove QC group) -> statistical analysis\n\nHowever,  the page 'data edit' will be redirected to data normalization, which is unmeaningful in my case. I can choose to turn off the data normalization and jump to the statistical part, but still want to know what's the suggested way to do?"
    },
    {
        "Question": "My result of lipids enrichment analysis is weird",
        "Answer": "The non-significant FDR is likely due to the large total number of compounds in the Triradylcglycerols library, i.e. since the library contains >30,000 triradylcglycerol compounds, a few dozen hits in comparison may not be deemed statistically over-represented. The over representation analysis algorithm used in the enrichment module is best suited for metabolite sets with a biological context such as biological pathways, biological functions, disease states, etc. In the case of a large collection of compounds only based on chemical classification, statistical test for enrichment may not provide meaningful results. You might want to consider trying \"define your own customized metabolite sets\" and/or \"upload a reference metabolome based on your analytical platform\" options to better tailor the statistics to your research context."
    },
    {
        "Question": "Can I perform functional analysis for a compound list without m/z values",
        "Answer": "Please try the modules \"**Enrichment Analysis**\" or \"**Pathway Analysis**\" (both accept compound names). Note the \"Functional Analysis\" is pathway analysis but for LC-MS peaks (requiring m/z with or without retention time)"
    },
    {
        "Question": "What are the options if I would like to perform LC-MS analysis >200 spectra",
        "Answer": "You can learn to use the MetaboAnalystR to do it yourself, or you can subscribe to the [pro support service](https://www.xialab.ca/translation.xhtml)"
    },
    {
        "Question": "Why is the number of compounds for a KEGG pathway different between the KEGG website and MetaboAnalyst?",
        "Answer": "In MetaboAnalyst, the KEGG pathways were obtained based on the KEGG REST APIs followed by manual curations. The date or versions are described in the publications and should also be on the pathway library page. For some pathways, there may be a discrepancy in the number of compounds listed from KEGG directly compared to MetaboAnalyst (the compounds are primarily based on HMDB). This is because a KEGG pathway can contain compounds that have not been verified for that species or a generic compound, and there is no corresponding compound in HMDB. In most cases, these discrepancies should not affect data interpretation as we cannot measure those compounds anyway."
    },
    {
        "Question": "How does MetaboAnalyst calculate the p values associated with fold change analysis?",
        "Answer": "Please visit the FC analysis page for details on this approach. There is no p values associated with FC analysis. It just means these features pass the threshold you specified. Nothing more."
    },
    {
        "Question": "Some BMD curves are not showing in dose responses analyses",
        "Answer": "Please make sure there is no space or \"/\" in feature names, which will interfere with URL path. You can either remove those \"/\" or wait for the update which can deal with this issue"
    },
    {
        "Question": "Can I know more about Effect Size(s) for Power Calculations in MetaboAnalyst?",
        "Answer": "The module is designed to estimate the sample size based on a pilot data using the average effect sizes (according to your criteria) of individual features. The underlying R package is \"SSPA\"."
    },
    {
        "Question": "I want to know the calculation method of fold change",
        "Answer": "The details are provided on the **Fold Change Analysis** page in Statistical Analysis (single factor) itself. You can also inspect the R code in MetaboAnalystR if you are familiar with R"
    },
    {
        "Question": "What ID types are supported for pathway analysis?",
        "Answer": "Please use official names, common names, HMDB ID and KEGG ID in pathway analysis. At the moment, abbreviations are not well supported"
    },
    {
        "Question": "Inconsistency in graph vs table output using linear models with covariate adjustment",
        "Answer": "The y-axis shows the primary metadata p-value from the model that you specified:\n\n**metabolite ~ primary variable + covariates**\n\nThe x-axis shows the primary metadata p-value from the simplest possible model:\n\n**metabolite ~ primary variable**\n\nThe x-axis essentially gives you a 'baseline' to see the impact of adding covariates to the model. It is not the results from the model you specified, so we do not make them available for download to avoid confusion (ie. users reporting those statistics but saying they adjusted for covariates). If you really want the p-values and coefficients for the x-axis, you can simply specify the most simple model using the interface (ie. select a primary meta data but no covariates and no blocking factor). Then, the x and y-axis will be exactly the same and the results table will provide the details. \n\nThe file underlying this plot is now available in the Download page, under the name **covariate_adj_vs_none.csv**"
    },
    {
        "Question": "Sample normalization based on co-variate (such as fish weight)?",
        "Answer": "If you expect fish weight could affect metabolomics profile, you can include it as a covariate during analysis or normalize using the information. For normalization, if you include this information as a feature in the metabolomics data, you can directly use \"Normalize by a reference feature\"; Otherwise, you need to manually enter the values using \"Sample-specific normalization (i.e. weight, volume)\" "
    },
    {
        "Question": "Relationships between the metabolites in each set and the disease",
        "Answer": "Hi there,\nRegarding the 44 metabolite sets related to disease signatures found in fecal samples, what's the relationship between the metabolites in each set and the disease. For instance, among the 93 metabolites in the set for IBS, which are positively correlated with IBS, and which are negatively correlated with IBS.  Same question for the other 43 metabolite sets and diereses. Thank you."
    },
    {
        "Question": "Relationships between the metabolites in each set and the disease",
        "Answer": "The metabolite sets are signatures curated base on literature - significant metabolites based on their p values (or other criteria reported by authors).  We don't have original data to re-compute them in a consistent way. You may get those details by clicking the \"View\" link of the metabolite sets to see if the authors have provided such information (see below).   \n\n![Screen Shot 2022-10-06 at 7.19.10 PM|690x221](upload://vj7LzWcsRjLOBjReTzw3DdamWOs.png)"
    },
    {
        "Question": "Relationships between the metabolites in each set and the disease",
        "Answer": "Thank you. It is in the Enrichment analysis, which \"44 metabolite sets reported in human feces.\" can be chosen.\nA table will be obtained in the result ,such as \n\nMetabolite Set\tTotal\tHits\tExpect\tP value\tHolm P\tFDR\t\nIrritable Bowel Syndrome 93 11 1.1 2.01E-10 8.63E-9 8.63E-9 \nUnclassified Ibd\t84\t9\t0.994\t5.87E-8\t2.47E-6\t8.54E-7\nMyalgic Encephalomyelitis/chronic Fatigue Syndrome\t22\t6\t0.26\t5.96E-8\t2.47E-6\t8.54E-7\n\nMy question is, for instance, for IBS, among the 93,  which are positively correlated with IBS, and which are negatively correlated with IBS. Same question for the other 43 metabolite sets and diereses."
    },
    {
        "Question": "Relationships between the metabolites in each set and the disease",
        "Answer": "Can you clarify which module you are using, and which steps you have taken? \n\nIt sounds like you might be referring to the network module, which contains a database relating metabolites, genes, and diseases. There are more details on the databases [here](https://omicsforum.ca/t/which-database-is-used-for-creating-the-gene-metabolite-disease-network/349)."
    },
    {
        "Question": "Pathway apparently missing from MSEA database",
        "Answer": "Hello, \n\nIn MSEA, we mainly use the metabolic pathways. Aminoacyl-tRNA biosynthesis is categorized to Genetic Information Processing.  It has contain two types of metabolites, either basic amino acids or their related aminoacyl-tRNA without exact molecular weight. The basic amino acids are quite common in the metabolic datasets. It would be more meaningful to use this pathway for gene/protein enrichment as the extensive existing amino acids could result in false positives.\n\nHope this helps!"
    },
    {
        "Question": "Pathway apparently missing from MSEA database",
        "Answer": "I ran some metabolomics results through MetaboAnalyst 5.0 a few months ago and the pathway analysis results included aminoacyl-tRNA biosynthesis. I ran them again after the update to 6.0, and aminoacyl-tRNA biosynthesis was not among the results. When I downloaded the databases from https://www.metaboanalyst.ca/docs/Databases.xhtml, and searched for the Pathway-related library for the string \"aminoacyl-tRNA\" in the Ontology field and in the Biological library, my searches did not return any results. \n\nIs accurate with respect to the underlying databases that support the current version of MSEA, and if so, is there a reason why aminoacyl-tRNA biosynthesis has been removed from these databases? \n\nThank you!"
    },
    {
        "Question": "Pathway apparently missing from MSEA database",
        "Answer": "Yes, this is to address a common critic (i.e.  the top pathway is not very informative) we received from several experts in the field."
    },
    {
        "Question": "Pathway apparently missing from MSEA database",
        "Answer": "Just to make sure I understand - this pathway, and possibly other pathways, that exist in the underlying database at its source (eg, KEGG), have been curated out of the database for purposes of MSEA? The rationale in this case is that this particular pathway has been deemed not appropriate to identify as an enriched pathway within a metabolomics dataset? \nThanks again!"
    },
    {
        "Question": "Enrichment or Pathway Analysis for 4 groups",
        "Answer": "Can you give us some more details? For example, a screen shot of what the error message looks like and more details on the format of your data."
    },
    {
        "Question": "Enrichment or Pathway Analysis for 4 groups",
        "Answer": "I would like to perform Enrichment and Pathway Analyses for my four experimental groups, but every time I try, I receive an error message. Is it possible to do these in MetaboAnalyst? Or is there any other tab that I could use?"
    },
    {
        "Question": "Enrichment or Pathway Analysis for 4 groups",
        "Answer": "Ok, this module is for one-column lists of compound names. You can click the example data to see what it should look like. You should have already done some statistical analysis to generate a list of metabolites of interest, and then you upload that here to see what pathways your list is enriched in. \n\nIf you have a different list for each experimental group, you can upload each list separately to get the enriched pathways for each. \n\nIf you still need to conduct statistical analysis (ie. identify metabolites of interest and then do enrichment analysis), you should start with the statistical analysis module in MetaboAnalyst and then upload your list here."
    },
    {
        "Question": "Enrichment or Pathway Analysis for 4 groups",
        "Answer": "The error message is informative here. In general, enrichment analysis is only defined for two-group comparison - **enrichment (or not) is always relative to a reference**. When you give 4 groups, the program does not know which is the reference.  \n\nYou can first perform ANOVA on four-group data (using Statistics Module), and then upload the significant metabolites (one column with one metabolite per row) for enrichment analysis here."
    },
    {
        "Question": "Enrichment or Pathway Analysis for 4 groups",
        "Answer": "Sure. I am attaching the screen shot of the error message. \n\n![Screen Shot 2022-08-10 at 2.36.39 PM|690x283](upload://iTZ8LjUWoKiCCTPXtyiiyiOMXz1.png)\n\nI have got 4 experimental groups (n is between 3 to 7 per group) with the area under curve values of the MS peaks for each sample. The sample IDs and groups are in the first two columns and metabolite or lipid names are on the rows. I have uploaded the data in the .csv format"
    },
    {
        "Question": "Analysis of paired data from a cross-over trial, incorporating one or more covariates",
        "Answer": "Hello,\n\nThank you for this wonderful software. I am a clinician-researcher interested in understanding whether I can use Metaboanalyst to find differential features under two conditions in a cross-over clinical trial, but incorporating a covariate.\n\nI have been able to do paired analysis, and I have been able to see how I could use a different input method to incorporate a covariate (but without paired analysis).\n\nIs this a way to incorporate a covariate (or more than one) in a paired-sample study design in Metaboanalyst?\n\nSincerely,\nBrian"
    },
    {
        "Question": "Analysis of paired data from a cross-over trial, incorporating one or more covariates",
        "Answer": "Yes, this is different from time-series. I suppose 4 columns in your metadata:\n\n**Sample IDs, Treatment, Subject IDs, Covariate**\n\nPair information is essentially \"Subject IDs\"."
    },
    {
        "Question": "Analysis of paired data from a cross-over trial, incorporating one or more covariates",
        "Answer": "Thank you very much. I have tried this approach, and I am finding that 1, -1, 2, -2, etc. pairing approach is not recognized as a valid blocking factor. The system assumes it's a continuous variable, and changing it to categorical or removing the minus signs to form two-item groups doesn't seem to work.\n\nPerhaps it requires that I recode the pairing variable somehow in the metadata sheet.\n\nSincerely,\nBrian"
    },
    {
        "Question": "Analysis of paired data from a cross-over trial, incorporating one or more covariates",
        "Answer": "Not sure if it will work for your data. Maybe you can try the linear models with three metadata factors\n\n* Treatment\n* Pair\n* Covariate \n\nSet Pair as \"blocking factor\"."
    },
    {
        "Question": "How to label features in PCA loading plot",
        "Answer": "This can be done manually if you just want to label a few key compounds\n\n1) Download the PNG image of the loading plot, and insert it into a Powerpoint slide\n2) On the web page showing the interactive loading plot, use the mouse to point to the data point of interest (or click on it) to find out its name\n3) Find the same data point in the PNG image and insert the text label. If you are familiar with R, you can download the coordinate file (\"pca_loadings.csv\") and do in R. "
    },
    {
        "Question": "Can I process my samples with only z-scores",
        "Answer": "You can uploading normalized / scaled data. \n\n* No filtering, no normalization\n* Volcano plot  (esp. fold change) will be affected as they are usually on original scale\n\nRegarding data format, please first go through [our detailed instructions on this](https://metaboanalyst.ca/docs/Format.xhtml)"
    },
    {
        "Question": "Can I analyze paired smaples for metabolomic pathway analysis",
        "Answer": "You can do this in two steps: 1) perform paired analysis using the statistical analysis module to identify significant compounds (or ranked peaks) generated from paired analysis; 2) using the significant compounds (targeted metabolomics) or ranked peaks (untargeted metabolomics) to perform pathway analysis."
    },
    {
        "Question": "Does Metaboanalyst admit negative numbers?",
        "Answer": "MetaboAnalyst performs analysis when the uploaded data are in its supported formats (see our many examples and tutorials). A small percentage of negative values can be tolerated. If the uploaded data are outside the intended scope of application, it is up to users to take the risk and interpret the results."
    },
    {
        "Question": "Can MetaboAnalyst perform GC-MS untargeted metabolomics",
        "Answer": "In theory, yes. However, MetaboAnalyst is developed and validated for LC-MS related spectral processing and functional analysis. For GC-MS spectra, the default parameters may not work well and you need to perform manual adjustment."
    },
    {
        "Question": "Can I integrate the lipids data with RNA seq data for joint pathway analysis",
        "Answer": "As far I see the metabolomics data along with fold change and RNA seq data with fold change can be used for joint pathway analysis\nI have lipid data and its foldchange and RNA seq genes and its fold change'\nIs there any way to use Metaboanalyst for integration"
    },
    {
        "Question": "Can i integrate the lipids data with RNA seq data for joint pathway analysis",
        "Answer": "This depends on the availability of lipid pathways. If your lipids are not recognized, no pathways are defined for them in our libraries."
    },
    {
        "Question": "How to use different spectral library for annotation",
        "Answer": "I want to use other spectral library (msp) for annotations than HMDB. \n\nMy samples are of plant origin, so HMDB hits doesn't make any sense."
    },
    {
        "Question": "Different paired fc result in MetaboAnalyst and excel",
        "Answer": "Please read our FC analysis for paired data at the FC page. If you are familiar with R, you can also take a look at our MetaboAnalystR code. There are several data processing steps including filtering, missing value estimation, normalization involved. This could have big impact on your FC computing especially for those features containing missing or very small values. You can refer to \"data_processed.csv\" to find whether this is the case for your features"
    },
    {
        "Question": "How can I perform PCA for repeated measures?",
        "Answer": "Code the repeats as a design factor and use the **Statistical Analysis [metadata table]** for analysis. Keep in mind that this is an exploratory analysis, you can do the following analyses and visualization\n\n* Univariate stats: Two-way ANOVA, linear modeling (there are some statistical consideration \"blocking factor\")\n* Unsupervised clustering: PCA, heatmap (visually examine the data dependency here)\n* Supervised analysis: Random Forest (require large sample size)"
    },
    {
        "Question": "Question on P-value and Adjusted p-value in the Feature Table from limma-based covariate analysis",
        "Answer": "P-value = raw p-value. Adjusted p-value = Benjamini-Hochberg method (as implemented in the limma package)."
    },
    {
        "Question": "How to choose p-value cutoff for functional analysis with multiple group data? ",
        "Answer": "Functional analysis is best understood in two-group settings. 1) You can always edit your peak intensity table to contain the two groups of interest; upload this table to Statistics Module to get p values using t-test. \n\n2) By default,  p-values will be calculated based on ANOVA (>2 groups). You can still use the p values for functional analysis, although it would be  difficult to interpret  - this is inherent in ANOVA."
    },
    {
        "Question": "Feature table mapping to metabolite/ annotations",
        "Answer": "Are you looking for compound annotation? Check the \"Other Utilities\" module => \"Compound ID Conversion\""
    },
    {
        "Question": "How to choose P-value cutoff for functional analysis in untargeted metabolomics (mummichog)",
        "Answer": "P-values, t-statistics or fold changes are commonly used to help select peaks that are changed or \"perturbed\" in functional analysis.  There are two main considerations here:\n\n**function** is a group behaviour. For instance, a pathways involve ~40 compounds could map to ~200 peaks. If we would like to have a good understanding of functions based on peaks, an empirical rule is 300~500 peaks for detecting different functions. \n\n**background** is the universe against which the enrichment is calculated. The assumption is that the majority (say, 90%) of the metabolome will remain stable, so that we can use random sampling (sample size the same as the significant list) from this universe to compute null distribution.  \n\nFrom the above estimation, the algorithm (i.e. mummichog) need ~5000 peaks as universe, 300~500 peaks as significant peaks to work robustly. This is usually the case in LC-MS untargeted metabolomics based on Orbitrap or TOF."
    },
    {
        "Question": "How to choose appropriate parameters for peak width during peak alignment in LC-MS spectra processing",
        "Answer": "If you are not sure about these parameters, you should choose \"Auto-optimized\" option for spectra processing, which is designed for such cases, and works well in our bench markings.  \n\nManual parameter tuning is mainly for those who are already familiar with these concepts.  I would suggest you to look for XCMS / MZmine / MS-DIAL user forums for better support."
    },
    {
        "Question": "How to make self defined metabolite sets for enrichment analysis",
        "Answer": "Based on your description, I would recommend using the web interface to upload the metabolite set library per our instruction (on the web page)."
    },
    {
        "Question": "How to obtain high-resolution pathway figures of Joint-Pathway Analysis Results",
        "Answer": "Click the \"link-out\" icon on the top-right corner of the pathway graph.  You will be able to re-generate the same pathway in full screen mode.  If you have a large and/or high-resolution screen, this image should provide sufficient resolution when print to A4 size. The resolution is calculated as number of pixels relative to the image size. The one you get is based on original screen size which is not useful in your case (as you use A4 size).  Keep in mind that high resolution means you still get high-quality view when you enlarge/zoom-in the original picture. This is exactly the case here."
    },
    {
        "Question": "Please suggest how to upload and process files larger than 200 MB",
        "Answer": "First make sure your data is in centroid mode as most spectra should be below this size. If it is indeed the case, you can either subscribe to the MetaboAnalyst-pro (which allows data upload via Google Drive), or try to learn to run MetaboAnalystR locally."
    },
    {
        "Question": "What role does clustering play in the univariate ROC analysis?",
        "Answer": "Our tool is primarily designed for developing multi-biomarker models. The cluster number indicates similarities of different biomarkers  (whether they are in the same clusters). You can use this information when you  manually build a multi-biomarker model. In general, you choose biomarkers that are complementary to each other (i.e. from different clusters)."
    },
    {
        "Question": "How to resolve mutliple hit of the same compound (for instance, choline) with a slight different at retention time in untargeted metabolomics",
        "Answer": "Run choline in your system to find out its correct retention time. Eventually, you need to develop your own in-house library for those compounds you would like to trace based on your own LC-MS system"
    },
    {
        "Question": "What is \"expected hits\" in enrichement analysis",
        "Answer": "Enrichment analysis uses null models to compute the theoretical number of hits by random chance (expected hits), and compare this number with what we actually observed based on the data (observed hits). \n\nAssuming you are talking about ORA, the model is hypergeometric model. In some cases, we don't want to specify a model, we can use permutations to estimate the expected hits. \n\nEnrichment Ratio is computed by Hits / Expected, where hits = observed hits; expected = expected hits\n\nwhat is \"expected hits\""
    },
    {
        "Question": "LC-MS Spectra Processing ERROR after 5 %",
        "Answer": "Are you seeing this message using our example data? If not, that means your data require resources beyond the free quota we set up for regular users at our public server. One option is to upgrade to pro version which doubles the resources by default."
    },
    {
        "Question": "How can I find the exact code or formula in MetaboAnalystR",
        "Answer": "If you are using MetaboAnalystR, just search the corresponding R command in our GitHub or your local R package. Note you can find the corresponding R commands using example data in the public web."
    },
    {
        "Question": "How can I download all results from the volcano analysis and Fold Change (FC) Analysis data",
        "Answer": "You can adjust thresholds to make all features significant"
    },
    {
        "Question": "What are the color codes for PCA and Feature Box plot",
        "Answer": "By default, the PCA score plot and feature box plot (or violin plot) use the same color schema. However, they may look slightly different, as the PCA plot applies transparency (alpha value) to deal with sample overlaps. \n\nIf your data contain less than 18 groups, the color codes are:\n\n`\"#e6194B\", \"#3cb44b\", \"#4363d8\", \"#42d4f4\", \"#f032e6\", \"#ffe119\", \"#911eb4\", \"#f58231\", \"#bfef45\",  \"#fabebe\", \"#469990\", \"#e6beff\", \"#9A6324\", \"#800000\", \"#aaffc3\", \"#808000\", \"#ffd8b1\", \"#000075\"`"
    },
    {
        "Question": "How should I prepare NMR spectra for MetaboAnalyst",
        "Answer": "MetaboAnalyst currently only supports raw data processing for LC-MS and MS/MS. All other input must be first processed into a table before uploading to MetaboAnalyst for statistical analysis. For NMR spectra, you need to phase the spectra and perform spectral binning. "
    },
    {
        "Question": "What are the main differences between Explorer ROC and Tester ROC in biomarker analysis module?",
        "Answer": "Explorer ROC and Tester ROC are for different purposes. Explorer ROC is more complex (double CV) in order to select features and to evaluate performance; while Tester just performs conventional CV (single CV) based on the given features. However, they will converge for very large sample (>500), in my experience.  \n\nPlease see below for more details:\nhttps://omicsforum.ca/t/how-are-important-features-selected-in-multivariate-roc-exploratory-analysis/309"
    },
    {
        "Question": "Does Volcano plot use corrected p-values or raw p-values?",
        "Answer": "It supports both options. If you choose FDR p-value, the p values will be FDR-adjusted instead of raw p values."
    },
    {
        "Question": "I cannot get the same results using Excel or R commands",
        "Answer": "In general, you should NOT compare results from Excel with those obtained from MetaboAnalyst, which is a comprehensive platform with many steps involved before actually computing the statistics. You can see the R command history to see the data processing and normalization steps in the R command history."
    },
    {
        "Question": "Can I perform statistical assessment of the separation patterns observed on PCA?",
        "Answer": "Yes, you can perform PERMANOVA on the PCA 2D Scores Plot in MetaboAnalyst (Statistical Analysis module). \n\nHope the information can add some quantitative reassurance to the visual inspection."
    },
    {
        "Question": "Interpretation of NES Values in GSEA",
        "Answer": "GSEA enrichment score can be positive or negative. Positive scores mean the pathway hits tend to be on the top half of the ranked list, while negative means the hits end to be at the bottom half. Note negative is not meaningful (interpretable) if you use p-values for ranking. \n\nPlease refer to [this post](https://omicsforum.ca/t/how-should-i-interpret-a-volcano-like-plot-from-gsea-analysis-functional-analysis-module/1097/3)"
    },
    {
        "Question": "Error in linear models with continuous variable as the primary factor",
        "Answer": "Unless otherwise explicitly stated, the tool does not support continuous variable as primary data at this stage."
    },
    {
        "Question": "Adding some advanced multivariate approaches (such as Anova Multiblock OPLS) on MetaboAnalyst",
        "Answer": "We are aware of many options when it comes to statistical analysis. The two main limiting factors are:\n\n* The computing resources - due to large user traffic, the public server (community version) is mainly for real-time computing (except raw spectra processing);\n* Our developers' time - we are mainly funded for research-related development. \n\nFor those features,  a more sensible way is to raise this request as a subscribed user, as the feature does not fit the public server.  We offer pro option which allows subscribed researchers to create and run a workflow --> generate reports and slides on separate cloud nodes. You can see [more details here](https://www.xialab.ca/protools.xhtml)."
    },
    {
        "Question": "Data (paired) upload unknown error",
        "Answer": "Please make sure to first read our instructions on paired data format?\n\n1) Example #5  in the same data upload page\n2) Detailed instructions in the [Data Format page](https://metaboanalyst.ca/docs/Format.xhtml)"
    },
    {
        "Question": "Where is the \"Batch effect correction\" tool?",
        "Answer": "On the Module View page, click \"Utilities\" or scroll down to see this feature."
    },
    {
        "Question": "Query mass in mummichog outputs not matching m.z inputs",
        "Answer": "The result \"....matched_compound_all.csv\" contains all matched compounds, you can search any \"Query.Mass\" from this table to see its match in your input. **But not the other way (as many peaks in your input will not have match).**"
    },
    {
        "Question": "Mismatch in name of feature in initial graph v name in Feature View when using t-test or Mann-Whitney",
        "Answer": "Please make sure that feature names do not contain **space, comma, dot**  - these are special characters used for other purposes. Computers are really not good at dealing with this."
    },
    {
        "Question": "The job link does not access the previous job",
        "Answer": "The job will be removed automatically after certain period (~1 month depending on the server space). If you have registered an account, it will be longer (up to 1 yr, again depending on our server resources).\n\nNote that the public server at the moment. For these advanced features, please take a look at our \"pro\" version (https://www.xialab.ca/pro/protools.xhtml)."
    },
    {
        "Question": "Error in LC-MS/Raw Spectral Data Run: Out of Memory",
        "Answer": "The message indicates the data processing requires larger memory than the allocated quota. This is the intended behaviour in order to keep the public server live and accessible to the community.  You can either subscribe to the pro version (with double memeory allocation) or  try to run the R package locally"
    },
    {
        "Question": "Downloading metabolite set details in bulk",
        "Answer": "This feature is available in the \"pro\" version. The public tool is designed to be \"lazy\" from day one - you need to click to get the information.  The main reason is computing cost when there are many users and large datasets.  \n\nWe are aware that there are many features that can be done automatically - this is the main reason to create \"pro\" tool, which is designed for productivity, workflow & automation."
    },
    {
        "Question": "Functional Analysis [LC-MS] .txt File Formatting Issue",
        "Answer": "For typical 3-col input, make sure the column headers are \"m.z\" \"p.value\" \"t.score\". \n\nCheck this out too: https://omicsforum.ca/t/what-are-the-inputs-for-functional-analysis-module/337?u=elerint"
    },
    {
        "Question": "Can I analyze unlabeled data?",
        "Answer": "There are several unsupervised methods (PCA, hierarchical clustering, SOM, K-means) that can be used to detect inherent patterns in unlabeled data. However you need to trick MetaboAnalyst to accept the data by providing dummy two-group labels . In this case, results from feature selection or supervised classification methods will be meaningless."
    },
    {
        "Question": "Reference metabolome based on analytical platform-error",
        "Answer": "The required format is a single column of **compound names** - it also gives an example data. HMDB or KEGG IDs are not compound names. \n\n![Screenshot 2024-06-23 at 9.51.59 PM|690x343, 75%](upload://1alwOqXFKqGXUFIooWCLL4Sj8d9.png)"
    },
    {
        "Question": "When performing Paired sample analysis, samples at baseline and at a second timepoint during follow-up. What is the statisitical module used by metaboanalyst?",
        "Answer": "Take a look at the \"Statistical Analysis [metadata table]\" module which provides some dedicated methods for time series data; particularly, the \" Linear models with covariate adjustments\" supports mixed effect analysis"
    },
    {
        "Question": "How can i run GSEA on a ranked list of annotated compounds?",
        "Answer": "In general, GSEA-based approach expects a complete (or very comprehensive) metabolome coverage - which is sort of OK for global or untargeted metabolomics. For untargeted metabolomics, ORA-based approach is more powerful than GSEA. See our comprehensive evaluation here. \n\nFor targeted metabolomics with ~100 metabolites, similar evaluation is needed before we can provide this option."
    },
    {
        "Question": "What does the columns (e.g. \"Total\", \"Expected\") of pathway result table mean?",
        "Answer": "**Total** is the total number of genes and/or metabolites in the corresponding pathway;\n **Expected** is a number of expected hits to a certain pathway. This value is calculated according to the query number from users' input. For a quick example, if the ratio of pathway A's total nodes in the whole database is α, and user's input is B, the expected hits of Pathway A is α*B;\n **Hits** is the number of hits of users' input towards a certain pathway;\n **Raw p** is raw p value of enrichment analysis; \n**-log10(p)** is log-transformed p value; \n**Holm adjust** and **FDR** are corrected p values with 'Holm method' and 'False Discovery Rate', respectively; \n**Impact** value is the result of topological analysis. The higher of the value mean more topological impact on the pathway."
    },
    {
        "Question": "What should I input for Joint Pathway Analysis?",
        "Answer": "**Gene List** input frame is required. You should input the Genes' ID (Entrez ID, Official Gene Name or Uniprot Protein ID) as the 1st column and the log fold change as the 2nd column (optional).\n\n**Compound List** input frame is also required. You should input the Compounds' ID (compound name, HMDB ID or KEGG ID) as the 1st column and the log fold change as the 2nd column (optional).\n\nNOTE: the log fold change is optional for gene list and compound list."
    },
    {
        "Question": "Network analysis enrichment table",
        "Answer": "For the network analysis enrichment table it generates, what does \"total expected hits Topology PVal.Z\" these column means? \n![Screen Shot 2024-07-04 at 11.01.11|582x294](upload://iCPxVS1QWZqtSKCNdUPETd8a5tH.png)"
    },
    {
        "Question": "What are the data input formats supported by enrichment analysis?",
        "Answer": "There are three types of inputs MSEA accepts:\n  * **A single column data contains a list of compound names** for over-representation analysis (ORA). For example, a list of important compounds identified by feature selection or clustering methods;\n  * **A two-column data separated by tab** - the first column contains compound name and the second column is their measured concentrations - for single sample profiling (SSP). This data is essentially a single profiled biological sample. The purpose is to compare the measured values to their reference values to see if some compound concentrations are very high or low. This input is limited to human biofluids (Blood, Urine, CSF) for which reference values exist;\n  * **A concentration table**. The data contains quantitative metabolomic data of multiple samples measured under different conditions. The data should be uploaded as a comma separated values (.csv) with the each sample per row and each metabolite concentration per column. The first column is sample names and the second column contains sample class labels (categorical or continuous). Users can now directly analyze named metabolite datasets from the Metabolomics Workbench."
    },
    {
        "Question": "How does MetaboAnalyst perform meta-analysis of MS peaks?",
        "Answer": "**High-resolution LC-MS** has become the dominant platform for global metabolomics. The typical LC-MS workflow starts with data acquisition, followed by data pre-processing, feature selection, compound identification and then pathway analysis. \n\nHowever, peak identification requires significant efforts and is a major challenge for downstream functional interpretation. One strategy is to completely bypass bottleneck of metabolite identification and directly infer functional activity from MS peaks by leveraging the collective knowledge of metabolic pathways and networks. This is the idea of the **mummichog algorithm**. Essentially what happens is that a list of significant peaks, for instance 169.0814 m/z is matched to the monoistopic mass of potential compounds considering different adducts/isotopes (e.g. Cysteic acid (169.0045) or Norepinephrine (169.0739)).\n\nThese putatively matched compounds are then mapped onto known biological pathways. If a list of truly significant features reflect biological activity, then the representation of these true metabolites would be enriched on functional structures (*Figure 1*), while false matches would be distributed at random (Figure 2). We have extended this idea to support the meta-analysis of untargeted metabolomics data.\n\n![mum_sig|690x255](upload://68ndgzZ024UFWQd8xGsKhOa0ihM.png)\n(*Figure 1. List of significant peaks mapped onto a metabolic network*.)\n\n\n![mum_random|690x250](upload://6fYB3g21d7YHzGwiEfbrLrGj3zv.png)\n(*Figure 2. List of randomly selected peaks mapped onto a metabolic network*.)\n\n\nOverall, the workflow supports meta-analysis of MS peaks at either a) the pathway level or b) the compound/empirical compound level. Each level of integration has their own merits, for instance at the pathway level, compounds do not have to be matched across all studies, whereas the compound-level integration is better at bringing out weaker signals. \n\nThe workflow also considers data heterogeneity, meaning that the accuracy of the LC-MS instrument and the MS ionization mode are all taken into account when performing putative metabolite annotation. Ultimately, the goal of this workflow is to enable the reuse/repurposong of multiple datasets to identify a robust meta-signature for the phenotype in question.\n\nOne of the bottlenecks for meta-analysis of untargeted metabolomics studies is the heterogeneity in the sample processing, instrumentation used, and even samples themselves that make it difficult to directly compare studies. \n\nAnother significant hurdle is that unlike targeted metabolomics where a single metabolite can be quantified, in untargeted metabolomics data each metabolite can be linked to multiple peaks, each with their own expression levels. \n\nThe approach we have adopted is to therefore combine p-values, effect sizes, or both from all peaks across all studies linked to that metabolite to obtain an overall significance level for that metabolite. The workflow supports the use of the original **mummichog** algorithm, the **GSEA** algorithm, or both (\"**integ**\") to perform the meta-analysis. The meta-analysis can be performed by combining the statistical significance of proposed metabolites before pathway analysis (compound/empirical compound level), or after individual pathway analysis."
    },
    {
        "Question": "How to interpret the metabolite set plot from QEA?",
        "Answer": "Metabolite set plot shows the detailed influence of individual compound to the total score of the metabolite set. The color of the bar indicates positive or negative association with the phenotype (continuous) or positive association with a particular phenotype (categorical). The reference line at bottom shows the expected influence if the compound was not associated with the phenotype. High bars indicate influential metabolites. The marks on the bars show the standard deviation (SD) of the bar under null hypothesis.\n\nA typical metabolite set plot is shown below. In this case, the phenotype is categorical with four groups. Among all possible comparisons between the data and null hypotheses, the nine amino acids are **most significantly** associated with either group 3 and 4 as the color indicated. Please note, if you are interested in the comparison between a particular two groups, you should edit and upload your data with samples from only these two groups.\n![msea_mset|431x499](upload://2LTSnZi1gSkwNBxekN6ShPBimfz.png)"
    },
    {
        "Question": "Which effect-size combination method to use?",
        "Answer": "The **effect size** is a way to quantify the strength of the difference of phenotype in question between two groups. One of the most recommended methods for calculating the effect size is the Hedge's g. This method controls for bias in small studies to overestimate the effect. Cohen's d. To combine the effect sizes across the studies, there are two possible methods: 1) the fixed effects model or 2) the random effects model.\n\n* The **fixed effects model** is a linear model that assumes that the different studies share an underlying common true effect and that observed differences are due to sampling error. This model should therefore be used when the datasets are rather homogeneous (e.g. samples come from the same population).\n\n* The **random effects model** assumes that the true effect size follows a distribution, and hence is different between different studies. The random effects model is more commonly used as data are more likely to be heterogeneous (e.g. different LC-MS platform used or batch effects). A fixed effects model will select genes with the strongest effects amongst the studies, while random effects models will select genes with the strongest average effect across the studies."
    },
    {
        "Question": "What is joint pathway analysis?",
        "Answer": "Joint Pathway Analysis is a sort of integration of multi-omics (usually transcriptomics and metabolomics) datasets against the backdrop of the existing biological knowledge (e.g. Library of pathways).\n\nThe main impetus for data integration is to improve the understanding of the underlying biological sense from different systematical layers, as well as to be better able to gain further insight into mechanistic details of the system."
    },
    {
        "Question": "Why do I get different enrichment results between \"All Pathways\" and \"Metabolic Pathways\"?",
        "Answer": "\"All Pathways\" is based on all the regular pathway libraries from KEGG (545 pathways in total), whereas the \"Metabolic Pathways\" contains only the pathways associated with metabolic reactions. Therefore, you may get difference enrichment results between \"All Pathways\" and \"Metabolic Pathways\"."
    },
    {
        "Question": "Why the ranks of important features identified by different methods are different?",
        "Answer": "Different methods use different criteria for ranking the features. The choice of method used can greatly affect the set of features that are identified. This can be illustrated in the simple cases such as fold change v.s. t-tests, in which the former is interested in absolute change in concentrations/intensities, while the latter focuses on changes relative to the underlying noises. PLS-DA is based on linear regression; SAM and EBAM usually produce similar results since they are all based on t statistics; both random forests and SVM are quite distinctive from all other methods by using an ensemble of classification trees or projections to hyperplanes, respectively. Therefore, these methods tend to generate different results."
    },
    {
        "Question": "How to use Random Forest?",
        "Answer": "This implementation of random forest can only be used for classification, thus the primary metadata must be categorical. Predictors in the model, including both metabolites and other metadata, can include both categorical and numeric variables. Using the random forest tool is simple - just select a categorical primary meta-data, choose any other meta-data to use as predictors, and click \"Update\". Since random forest uses some random processes, turning randomness off means that the results will be the same each time that you run the tool. This can be better for reproducibility, but is not necessary."
    },
    {
        "Question": "How to use and interpret two-way heatmap?",
        "Answer": "The two-way heatmap displays the data in the form of matrix with cells colored according to their values. It provides an intuitive overview of the overall data points. To facilitate pattern discovery, MetaboAnalyst also performs clustering on the variables. The samples are sorted by their factor labels.\n\nUsers can change the clustering algorithms, the color schema, as well as the order of the samples to suit their preferences. When there are too many samples or variables, the high-resolution image can be used in order to get a clear view of the results."
    },
    {
        "Question": "What is the smart-matching algorithm used to match lipid names?",
        "Answer": "MetaboAnalyst now implements a \"smart-matching\" algorithm to help map user's lipid names to our internal compound database. The algorithm considers common lipid synonyms (gathered from PubChem, HMDB and LIPID MAPS), lipid abbreviations (LIPID MAPS), as well as different punctuation/symbols commonly used instead of slashes in lipid names. This step has significantly enhanced the ability of our tool to support lipidomics data for enrichment analysis."
    },
    {
        "Question": "What is compound-level meta-analysis of MS peaks?",
        "Answer": "Using the **compound or empirical compound meta-analysis**, it will first perform the putative peak annotation on each individual study. Next, the peak annotations are united by default, meaning that only the compounds/empirical compounds found across all studies are kept. \n\nFollowing this step, the list of significant features are updated (see Figure below).\n\n![compound_integration|690x215](upload://iw0DAwEa7g38AOXUAYHBpkNFiXq.png)\n(*Workflow for compound or empirical compound-level meta-analysis*.)\n\n\n\nFor the mummichog algorithm and \"**integ**\" options, a list of significant features are required. Therefore the next step is to combine m/z level statistics across all studies for each compound/empirical compound to obtain the unified list of significant features. Users can either integrate p-values (as if from a T-test), effect sizes, or both to select which m/z features should be used as input (See Figure below). This list is then used as input for pathway activity prediction.\n\n![sig_feats_metamum|690x350](upload://icAnBmYN8CvSETiLyzFHazlTD0b.png)\n(*Workflow for how the unified list of significant features are created*.)"
    },
    {
        "Question": "When to use compound or pathway-level meta-analysis?",
        "Answer": "**Pathway-level integration** should be used when the studies are independent of eachother - meaning they were performed using different LC-MS instruments, using different extraction methods etc. \n\nThis is because while lists of features from multiple independent studies looking at the same disease often have little overlap, the use of pathway analysis improves the biological consistency across studies (PMID: 20410053). \n\n**Towards this**, the Pathway-level integration does not require that compounds be matched across all studies. In comparison, the Compound or Empirical-Compound level integration should be used when the data are more homogeneous, for instance data comes from the same lab but different batches or different columns on the same samples and the same instrument. \n\nBy default, the algorithm will keep only compounds that match across all studies - for instance if the datasets were all the same column, same phenotype in question, same instrument, we would only want to focus on compounds that are merried by all datasets. However, if we had different columns but the same samples, then we would want to keep all putative compounds/empirical compounds for **predicting pathway activity**."
    },
    {
        "Question": "What are the important factors that affect the power?",
        "Answer": "There are three major factors:\n\n1. Effect size which is usually defined as the difference of two group means divided by the pooled standard deviation. When all others are equal, a larger the effect size will lead to more power;\n\n2. Degree of confidence which is usually the p value cutoff (alpha) for statistical significance. When all others are equal, there will be reduced power if we require a very high degree of confidence;\n\n3. The sample size - more samples will in general increase power. In many cases, the sample size is our interest for a given power (i.e. 0.8)."
    },
    {
        "Question": "What versions of the mummichog algorithm are included in MetaboAnalyst?",
        "Answer": "Currently, **MetaboAnalyst** supports *mummichog* version 1.0 and version 2.0.  Version 2.0 will use retention-time in the analysis."
    },
    {
        "Question": "What is the output of functional analysis module?",
        "Answer": "The output of functional analysis module mainly includes three parts:\n\n* The first one is a plot summarizing the pathway analysis results. Below the plot consists of a table identifying the top-pathways that are enriched in your m/z data. The table is ordered from the most significant to the least significant pathways and contains the number of hits and calculated statistics.\n\n* The second table is available for downloading as a link that contains a list of matched metabolites from the user’s uploaded list of m/z features.\n\n* The third output is the metabolic network visualization, which is based on the KEGG global metabolic network (ko01100)."
    },
    {
        "Question": "What is the acceptable name format for lipids?",
        "Answer": "MetaboAnalyst accepts common names, synonyms and systematic names of lipids as obtained from [LIPID MAPS](https://www.lipidmaps.org/), [RefMet](https://www.metabolomicsworkbench.org/databases/refmet/index.php), and [HMDB](https://hmdb.ca/)."
    },
    {
        "Question": "How can I obtain more information about some sigificant metabolite sets?",
        "Answer": "Each metabolite set will have an associated source (Database links, PubMed ID, etc) to help users further track down the original source of the information.\n\nThe SNP-associated metabolite sets were downloaded from the published journal websites, Only metabolites with p values less than 1e-3 were retained to reduce false positives. For any given SNP ID, users can visit the [NCBI SNP database](http://www.ncbi.nlm.nih.gov/projects/SNP/) to get detailed information about each SNP."
    },
    {
        "Question": "What are the different marks in the boxplot based on?",
        "Answer": "In a boxplot, the bottom and top of the box are always the 25th and 75th percentile (the lower and upper quartiles, or Q1 and Q3, respectively), and the band near the middle of the box is always the 50th percentile (the median or Q2). The upper whisker is located at the smaller of the maximum x value and Q3 + 1.5*IQR (Interquantile Range), whereas the lower whisker is located at the larger of the smallest x value and Q1 - 1.5*IQR."
    }
]
