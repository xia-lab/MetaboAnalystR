---
title: "Batch Effect Correction"
author: "Zhiqiang Pang and Jeff Xia"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{m). Batch_effect_correction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

The batch effect correction analysis module performs an automatic or specific correction on the peak data table generated by peak picking step. Multiple correction methods have been embeded inside. They include combat, WaveICA, EigenMS, ANCOVA, RUV_random, RUV_2, RUVseq series (RUV_s, RUV_r and RUV_g), NOMIS, CCMN. The detailed limitation and mathmatic mechanism of different methods have been illustrated in our [manuscript](). Here, two cases will be provided to show users a step to step workflow for this moduel.

## 2. Data preparation

The peak table generated by *FormatPeakList* function needs to be manually prepared by hand to supplements the corresponding information below.

·1st column The samples name;

·2nd column Sample groups/classes information, if there are any QC samples, please mark them as *QC*;

·3rd column Sample injection order, if no related information, please leave them empty;

·4th column Batch information, please provide consistent characters within the same batch;

·other column Features' intensity should be provided. If any internal standards, please mark the feature with "IS".

·NOTE: Please provide as more information as possible. If some information ommitted, please leave the columns empty.

###### Here is an example table.

```{r,echo=F}
library(knitr)
d<-kable(read.csv("vignette_figures/bc.csv",header = T))
d
```


## 3. Case 1 - A simulated sample

#### 3.1 Data Downloading

```{r, eval=FALSE,echo=T}
# Use Google API for data downloading here. 
# Please "install.packages('googledrive')" and "install.packages('httpuv')"first.
library(googledrive);
temp <- tempfile(fileext = ".csv")
# Please authorize your google account to access the data
dl <- drive_download(
  as_id("1vObn7HfgtZ2E6tPOyQyxRLineUZB1zeG"), path = temp, overwrite = TRUE)

```

```{r,echo=F}
cat('Waiting for authentication in browser...
Press Esc/Ctrl + C to abort
Authentication complete.
File downloaded:
  * BC_example.csv
Saved locally as:
  * /tmp/RtmpUJXtO5/file191a54109249.csv')
```


#### 3.2 Library Package

```{r, eval=FALSE}
# Load the MetaboAnalystR package
library("MetaboAnalystR")
```


#### 3.3 Initializing mSet Object

```{r,eval=F}
mSet <- InitDataObjects("pktable", "utils", FALSE)
```

```{r,echo=F}
cat('[1] "MetaboAnalyst R objects initialized ..."')
```


#### 3.4 Data Reading

```{r,eval=F}
## we set samples in "row" according to the table format. If your samples are in column, set it as "col".
mSet <- Read.BatchDataTB(mSet, dl$local_path, "row")
```


#### 3.5 Automatic Correction


```{r,eval=F}
mSet <- PerformBatchCorrection(mSet)
```

```{r, echo=F}
cat('[1] "Correcting using the Automatically method !"
[1] "Correcting with Combat..."
Standardizing Data across genes
[1] "Correcting with WaveICA..."
[1] "Correcting with EigenMS..."
[1] "Correcting with ANCOVA..."
[1] "Correcting with RUV-random..."
[1] "Correcting with RUV-2..."
[1] "Correcting with RUVs..."
[1] "Correcting with RUVr..."
Loading required package: edgeR
Loading required package: limma
[1] "Correcting with RUVg..."
[1] "Correcting with NOMIS..."
[1] "Correcting with CCMN..."
[1] "Best results generated by  combat  !"')
```

```{r, eval=F}
# Show the distances between batches
# The first item "table" refers to the original data
mSet$dataSet$interbatch_dis
```

```{r,echo=F}
cat('           table     combat_edata    WaveICA_edata    EigenMS_edata     ANCOVA_edata 
       10.978753         9.367183        10.099356        13.105851        11.470403 
RUV_random_edata      RUV_2_edata      RUV_s_edata      RUV_r_edata      RUV_g_edata 
       10.163140        10.842479        22.628060        11.146660        11.018191 
     NOMIS_edata       CCMN_edata 
       11.196554        11.103817')
```

```{r,echo=F, fig.align="center"}
knitr::include_graphics("vignette_figures/image_BCdpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/image_BC Trenddpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/image_BC distdpi72.png",dpi = 120)
```


## 4. Case 2 - IBD Benchmark Data

This Benchmark data is a large batch data with over 600 samples. The data file size is over 70 MB. This part is designed for repeating our published [results](). Running of this part may take over 30min to finish. You are strongly recommonded to use your own data instead of this large file to avoid the consuming of patience.

#### 4.1 Data Downloading and Preparation

```{r, eval=FALSE,echo=T}
# Use Google API for data downloading peak feature data generated by FormatPeakList here. 
# Please "install.packages('googledrive')" and "install.packages('httpuv')"first.
library(googledrive);
temp <- tempfile(fileext = ".csv")
# Please authorize your google account to access the data
dl1 <- drive_download(
  as_id("1wEh2P81J_xFWJs5y4mq98-FsjxJ5wmBO"), path = temp, overwrite = TRUE)

```

```{r, eval=FALSE,echo=T}
# Use Google API for data downloading meta data here. 
# Please "install.packages('googledrive')" and "install.packages('httpuv')"first.
library(googledrive);
temp <- tempfile(fileext = ".csv")
# Please authorize your google account to access the data
dl2 <- drive_download(
  as_id("1IOF2pCYrd0sbmFt3x9XOcwYj6XEA2z1n"), path = temp, overwrite = TRUE)

```

```{r,echo=F}
cat('File downloaded:
  * metaboanalyst_input.csv
Saved locally as:
  * /tmp/RtmpIBzO2x/file11c64ad429b2.csv')
```

```{r,echo=F}
cat('File downloaded:
  * meta_data.csv
Saved locally as:
  * /tmp/Rtmp3haVCa/file90a5282e7b0.csv')
```

```{r, eval=FALSE}
# Data preparation - read data in & transpose.
# This is a reference example for user to prepare their data. 
# Please prepare your data table according to your data format.
MetaboAna_Data <- t(read.csv(dl1$local_path,header = T));
colnames(MetaboAna_Data) <- MetaboAna_Data[1,];
MetaboAna_Data <- MetaboAna_Data[-1,];
MetaboAna_Data <- MetaboAna_Data[order(rownames(MetaboAna_Data)),];

meta_data <- read.csv(dl2$local_path);
meta_data <- meta_data[order(meta_data[,1]),c(1,2,4)];

Prepared_Data <- cbind(meta_data,MetaboAna_Data)[,-4];
write.csv(Prepared_Data,file = "IBD_BC_correction.csv",row.names = F)
datapath <- paste0(getwd(),"/IBD_BC_correction.csv")
```

#### 4.2 Library Package

```{r, eval=FALSE}
# Load the MetaboAnalystR package
library("MetaboAnalystR")
```


#### 4.3 Data Filtering and Normalization

```{r,eval=F}
mSet<-InitDataObjects("pktable", "stat", FALSE)

```

```{r,echo=F}
cat('Starting Rserve:
 /usr/lib/R/bin/R CMD /home/qiang/R/x86_64-pc-linux-gnu-library/4.0/Rserve/libs//Rserve --no-save 


R version 4.0.0 (2020-04-24) -- "Arbor Day"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.',
"Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Rserv started in daemon mode.
[1]",' "MetaboAnalyst R objects initialized ..."')
```

```{r,eval=F}
mSet<-Read.TextData(mSet, dl1$local_path, "col", "disc")

```

```{r,eval=F}
mSet<-SanityCheckData(mSet)
mSet<-ReplaceMin(mSet);
mSet<-FilterVariable(mSet, "iqr", "F", 25)
mSet<-PreparePrenormData(mSet)
mSet<-Normalization(mSet, "MedianNorm", "LogNorm", "NULL", ratio=FALSE, ratioNum=20)
```

```{r,echo=F}
cat('[1] "Successfully passed sanity check!"                                                                    
 [2] "Samples are not paired."                                                                              
 [3] "4 groups were detected in samples."                                                                   
 [4] "Only English letters, numbers, underscore, hyphen and forward slash (/) are allowed."                 
 [5] "<font color=\"orange\">Other special characters or punctuations (if any) will be stripped off.</font>"
 [6] "All data values are numeric."                                                                         
 [7] "A total of 744120 (14.4%) missing values were detected."                                              
 [8] "<u>By default, these values will be replaced by a small value.</u>"                                   
 [9] "Click <b>Skip</b> button if you accept the default practice"                                          
[10] "Or click <b>Missing value imputation</b> to use other methods" ')
```

```{r,echo=F}
cat('[1] " Further feature filtering based on Interquantile Range Reduced to 5000 features based on Interquantile Range"
[1] " Further feature filtering based on Interquantile Range Reduced to 5000 features based on Interquantile Range"')
```

```{r,eval=F}
### Data Orgnization
normalized_set <- mSet[["dataSet"]][["norm"]]
ordered_normalized_set <- normalized_set[ order(row.names(normalized_set)), ]
### import metadata
meta_data <- read.csv(dl2$local_path)
new_normalized_set <- cbind(meta_data[,2:4], ordered_normalized_set)[,-2];
write.csv(new_normalized_set,file = "new_normalized_set.csv")
```

```{r,eval=F}
#perform PCA
mSet <- PCA.Anal(mSet)
mSet <- PlotPCAPairSummary(mSet, "pca_pair_0_", "png", 72, width=NA, 5)
mSet <- PlotPCAScree(mSet, "pca_scree_0_", "png", 72, width=NA, 5)
mSet <- PlotPCA2DScore(mSet, "pca_score2d_0_", "png", 72, width=NA,style = 2, 1,2,0.95,0,0)
rm(mSet)
```

```{r,echo=F, fig.align="center"}
knitr::include_graphics("vignette_figures/IBD_BC_pca_score2d_0_dpi72.png",dpi = 120)
```

#### 4.4 Initializing mSet Object

```{r,eval=F}
mSet <- InitDataObjects("pktable", "utils", FALSE)
```

```{r,echo=F}
cat('[1] "MetaboAnalyst R objects initialized ..."')
```

#### 4.5 Data Reading

```{r,eval=F}
## we set samples in "row" according to the table format. If your samples are in column, set it as "col".
mSet <- Read.BatchDataTB(mSet, "new_normalized_set.csv", "row")
```


#### 4.6 Automatic Correction


```{r,eval=F}
mSet <- PerformBatchCorrection(mSet)
getwd()
```


```{r, echo=F}
cat('[1] "Correcting using the Automatically method !"
[1] "Correcting with Combat..."
Standardizing Data across genes
[1] "Correcting with WaveICA..."
[1] "Correcting with EigenMS..."
[1] "Correcting with ANCOVA..."
[1] "Best results generated by  EigenMS  !"')
```

```{r, eval=F}
# Show the distances between batches
mSet$dataSet$interbatch_dis
```

```{r,echo=F}
cat('        table  combat_edata WaveICA_edata EigenMS_edata  ANCOVA_edata 
     38.49935      39.42686      38.32145      24.18179      38.38796 ')
```

```{r,echo=F, fig.align="center"}
knitr::include_graphics("vignette_figures/IBD_image_BCdpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/IBD_image_BC Trenddpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/IBD_image_BC distdpi72.png",dpi = 120)
```

#### 4.7 Data visualization - PCA plotting with groups

```{r, eval=F}
## remove the batch column in the corrected result
data_corrected <- read.csv("/home/xialab/Documents/MetaboAnalyst_batch_data.csv")
data_corrected_new <- data_corrected[,-3]
write.csv(data_corrected_new,file = "MetaboAnalyst_batch_data_stats.csv",row.names =  F)
```

```{r,eval=F}
mSet <- InitDataObjects("pktable", "stat", FALSE)
mSet <- Read.TextData(mSet, "MetaboAnalyst_batch_data_stats.csv", "row", "disc")
mSet <- SanityCheckData(mSet)
mSet <- ReplaceMin(mSet);
mSet <- FilterVariable(mSet, "iqr", "F", 25)
mSet <- PreparePrenormData(mSet)
mSet <- Normalization(mSet, "NULL", "NULL", "NULL", ratio=FALSE, ratioNum=20) # No need to normalize again
mSet <- PCA.Anal(mSet)
mSet <- PlotPCAPairSummary(mSet, "pca_pair_0_", "png", 72, width=NA, 5)
mSet <- PlotPCAScree(mSet, "pca_scree_0_", "png", 72, width=NA, 5)
mSet <- PlotPCA2DScore(mSet, "pca_score2d_0_", "png", 72, width=NA, style = 2, 1,2,0.95,0,0)
```


```{r,echo=F, fig.align="center"}
knitr::include_graphics("vignette_figures/IBD_BCfree_pca_score2d_0_dpi72.png",dpi = 120)
```

## 5. Case 3 - Different Batch Files

In some cases, researchers would correct the batch effect from different studies for further meta-analysis. In this case, the data files are usually seperated. From v3.0.1, we have adopted our pipeline to compatibilize this case. Here is a simulated example datasets provided to showcase how it works.

#### 5.1 Data Downloading and Preparation

```{r eval=FALSE,echo=T}
# Now, download the small example data for comparison between CD vs. nonIBD
temp <- tempfile(fileext = ".zip")
dl <- drive_download(
  as_id("10a_F3N1-GaaulF1V2t2TRH2cU4SgdrKc"), path = temp, overwrite = TRUE)
# Setting the date file folder
out <- unzip(temp, exdir = getwd())
# Date files for normal processing example are deposited below
out

```

```{r eval=FALSE,echo=T}
mSet<-InitDataObjects("NA", "utils", FALSE)
mSet<-Read.BatchDataBC(mSet, out[1], "col", "B1");
mSet<-Read.BatchDataBC(mSet, out[3], "col", "B2");
mSet<-Read.BatchDataBC(mSet, out[5], "col", "B3");
mSet<-PerformBatchCorrection(mSet, "batch_0_ ", "Automatically", "NULL")
```

```{r,echo=F}
cat('[1] "Correcting using the Automatically method !"
[1] "Correcting with Combat..."
[1] "Correcting with WaveICA..."
[1] "Correcting with EigenMS..."
[1] "Best results generated by  EigenMS  !"')
```

```{r,echo=F, fig.align="center"}
knitr::include_graphics("vignette_figures/batch_0_ dpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/batch_0_  Trenddpi72.png",dpi = 120)
knitr::include_graphics("vignette_figures/batch_0_  distdpi72.png",dpi = 120)
```

## 6. Case 4 - Signal Drift Correction

In addition of the batch effect, signal drift is also an important issue faced by metabolomics study. QC-RLSC can be used to correct both batch effect and signal drift. Here, we showcase an example for user to correct the signal drift with the IBD data in case 2.

#### 5.1 Data Downloading and Preparation


####### ============ END OF THIS VIGNETTE =============